{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #type: ignore\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from IPython.display import clear_output #type: ignore\n",
    "import tensorflow as tf #type: ignore\n",
    "from tensorflow.keras import layers, models, regularizers #type: ignore\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split #type: ignore\n",
    "import matplotlib.pyplot as plt #type: ignore\n",
    "from joblib import Parallel, delayed  # for parallelism\n",
    "import multiprocessing\n",
    "\n",
    "SEED = 22\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect Four and MCTS Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_board(board_temp,color,column):\n",
    "    board = board_temp.copy()\n",
    "    colsum = abs(board[0,column])+abs(board[1,column])+abs(board[2,column])+abs(board[3,column])+abs(board[4,column])+abs(board[5,column])\n",
    "    row = int(5-colsum)\n",
    "    if row > -0.5:\n",
    "        if color == 'plus':\n",
    "            board[row,column] = 1\n",
    "        else:\n",
    "            board[row,column] = -1\n",
    "    return board\n",
    "    \n",
    "def check_for_win_slow(board):\n",
    "    nrow = board.shape[0]\n",
    "    ncol = board.shape[1]\n",
    "    winner = 'nobody'\n",
    "    for col in range(ncol):\n",
    "        for row in reversed(range(nrow)):\n",
    "            if abs(board[row,col]) < 0.1:\n",
    "                break\n",
    "            # vertical\n",
    "            if row <= (nrow-4):\n",
    "                tempsum = board[row,col]+board[row+1,col]+board[row+2,col]+board[row+3,col]\n",
    "                if tempsum==4:\n",
    "                    winner = 'v-plus'\n",
    "                    return winner\n",
    "                elif tempsum==-4:\n",
    "                    winner = 'v-minus'\n",
    "                    return winner\n",
    "            # horizontal\n",
    "            if col <= (ncol-4):\n",
    "                tempsum = board[row,col]+board[row,col+1]+board[row,col+2]+board[row,col+3]\n",
    "                if tempsum==4:\n",
    "                    winner = 'h-plus'\n",
    "                    return winner\n",
    "                elif tempsum==-4:\n",
    "                    winner = 'h-minus'\n",
    "                    return winner\n",
    "            # diagonal down-right\n",
    "            if (row <= (nrow-4)) and (col <= (ncol-4)):\n",
    "                tempsum = board[row,col]+board[row+1,col+1]+board[row+2,col+2]+board[row+3,col+3]\n",
    "                if tempsum==4:\n",
    "                    winner = 'd-plus'\n",
    "                    return winner\n",
    "                elif tempsum==-4:\n",
    "                    winner = 'd-minus'\n",
    "                    return winner\n",
    "            # diagonal down-left\n",
    "            if (row <= (nrow-4)) and (col >= 3):\n",
    "                tempsum = board[row,col]+board[row+1,col-1]+board[row+2,col-2]+board[row+3,col-3]\n",
    "                if tempsum==4:\n",
    "                    winner = 'd-plus'\n",
    "                    return winner\n",
    "                elif tempsum==-4:\n",
    "                    winner = 'd-minus'\n",
    "                    return winner\n",
    "    return winner\n",
    "\n",
    "def check_for_win(board,col):\n",
    "    nrow = 6\n",
    "    # figure out what row was just placed\n",
    "    colsum = abs(board[0,col])+abs(board[1,col])+abs(board[2,col])+abs(board[3,col])+abs(board[4,col])+abs(board[5,col])\n",
    "    row = int(6-colsum)\n",
    "    # vertical check\n",
    "    if row+3<6:\n",
    "        vert = board[row,col] + board[row+1,col] + board[row+2,col] + board[row+3,col]\n",
    "        if vert == 4:\n",
    "            return 'v-plus'\n",
    "        elif vert == -4:\n",
    "            return 'v-minus'\n",
    "    # horizontal checks (there are several)\n",
    "    # segment 0-3\n",
    "    if col+3<7:\n",
    "        hor = board[row,col] + board[row,col+1] + board[row,col+2] + board[row,col+3]\n",
    "        if hor == 4:\n",
    "            return 'h-plus'\n",
    "        elif hor == -4:\n",
    "            return 'h-minus'\n",
    "    # segment -1..+2\n",
    "    if col-1>=0 and col+2<7:\n",
    "        hor = board[row,col-1] + board[row,col] + board[row,col+1] + board[row,col+2]\n",
    "        if hor == 4:\n",
    "            return 'h-plus'\n",
    "        elif hor == -4:\n",
    "            return 'h-minus'\n",
    "    # segment -2..+1\n",
    "    if col-2>=0 and col+1<7:\n",
    "        hor = board[row,col-2] + board[row,col-1] + board[row,col] + board[row,col+1]\n",
    "        if hor == 4:\n",
    "            return 'h-plus'\n",
    "        elif hor == -4:\n",
    "            return 'h-minus'\n",
    "    # segment -3..0\n",
    "    if col-3>=0:\n",
    "        hor = board[row,col-3] + board[row,col-2] + board[row,col-1] + board[row,col]\n",
    "        if hor == 4:\n",
    "            return 'h-plus'\n",
    "        elif hor == -4:\n",
    "            return 'h-minus'\n",
    "    # diagonals down-right\n",
    "    if row < 3 and col < 4:\n",
    "        DR = board[row,col] + board[row+1,col+1] + board[row+2,col+2] + board[row+3,col+3]\n",
    "        if DR == 4:\n",
    "            return 'd-plus'\n",
    "        elif DR == -4:\n",
    "            return 'd-minus'\n",
    "    if row-1>=0 and col-1>=0 and row+2<6 and col+2<7:\n",
    "        DR = board[row-1,col-1] + board[row,col] + board[row+1,col+1] + board[row+2,col+2]\n",
    "        if DR == 4:\n",
    "            return 'd-plus'\n",
    "        elif DR == -4:\n",
    "            return 'd-minus'\n",
    "    if row-2>=0 and col-2>=0 and row+1<6 and col+1<7:\n",
    "        DR = board[row-2,col-2] + board[row-1,col-1] + board[row,col] + board[row+1,col+1]\n",
    "        if DR == 4:\n",
    "            return 'd-plus'\n",
    "        elif DR == -4:\n",
    "            return 'd-minus'\n",
    "    if row-3>=0 and col-3>=0:\n",
    "        DR = board[row-3,col-3] + board[row-2,col-2] + board[row-1,col-1] + board[row,col]\n",
    "        if DR == 4:\n",
    "            return 'd-plus'\n",
    "        elif DR == -4:\n",
    "            return 'd-minus'\n",
    "    # diagonals down-left\n",
    "    if row+3<6 and col-3>=0:\n",
    "        DL = board[row,col] + board[row+1,col-1] + board[row+2,col-2] + board[row+3,col-3]\n",
    "        if DL == 4:\n",
    "            return 'd-plus'\n",
    "        elif DL == -4:\n",
    "            return 'd-minus'\n",
    "    if row-1>=0 and col+1<7 and row+2<6 and col-2>=0:\n",
    "        DL = board[row-1,col+1] + board[row,col] + board[row+1,col-1] + board[row+2,col-2]\n",
    "        if DL == 4:\n",
    "            return 'd-plus'\n",
    "        elif DL == -4:\n",
    "            return 'd-minus'\n",
    "    if row-2>=0 and col+2<7 and row+1<6 and col-1>=0:\n",
    "        DL = board[row-2,col+2] + board[row-1,col+1] + board[row,col] + board[row+1,col-1]\n",
    "        if DL == 4:\n",
    "            return 'd-plus'\n",
    "        elif DL == -4:\n",
    "            return 'd-minus'\n",
    "    if row-3>=0 and col+3<7:\n",
    "        DL = board[row-3,col+3] + board[row-2,col+2] + board[row-1,col+1] + board[row,col]\n",
    "        if DL == 4:\n",
    "            return 'd-plus'\n",
    "        elif DL == -4:\n",
    "            return 'd-minus'\n",
    "    return 'nobody'\n",
    "\n",
    "def find_legal(board):\n",
    "    return [i for i in range(7) if abs(board[0,i]) < 0.1]\n",
    "\n",
    "def look_for_win(board_,color):\n",
    "    board_ = board_.copy()\n",
    "    legal = find_legal(board_)\n",
    "    winner_col = -1\n",
    "    for m in legal:\n",
    "        bt = update_board(board_.copy(),color,m)\n",
    "        wi = check_for_win(bt,m)\n",
    "        if wi[2:] == color:\n",
    "            winner_col = m\n",
    "            break\n",
    "    return winner_col\n",
    "\n",
    "def find_all_nonlosers(board,color):\n",
    "    if color == 'plus':\n",
    "        opp = 'minus'\n",
    "    else:\n",
    "        opp = 'plus'\n",
    "    legal = find_legal(board)\n",
    "    poss_boards = [update_board(board,color,l) for l in legal]\n",
    "    poss_legal = [find_legal(b) for b in poss_boards]\n",
    "    allowed = []\n",
    "    for i in range(len(legal)):\n",
    "        # if the opponent can immediately win after we move in col=legal[i], skip it\n",
    "        wins = [j for j in poss_legal[i] \n",
    "                if check_for_win(update_board(poss_boards[i],opp,j),j) != 'nobody']\n",
    "        if len(wins) == 0:\n",
    "            allowed.append(legal[i])\n",
    "    return allowed\n",
    "\n",
    "def back_prop(winner,path,color0,md):\n",
    "    for i, board_tuple in enumerate(path):\n",
    "        md[board_tuple][0] += 1\n",
    "        if winner[2] == color0[0]:\n",
    "            if i % 2 == 1:\n",
    "                md[board_tuple][1] += 1\n",
    "            else:\n",
    "                md[board_tuple][1] -= 1\n",
    "        elif winner[2] == 'e':\n",
    "            # tie => no change\n",
    "            pass\n",
    "        else:\n",
    "            if i % 2 == 1:\n",
    "                md[board_tuple][1] -= 1\n",
    "            else:\n",
    "                md[board_tuple][1] += 1\n",
    "\n",
    "def rollout(board,next_player):\n",
    "    winner = 'nobody'\n",
    "    player = next_player\n",
    "    while winner == 'nobody':\n",
    "        legal = find_legal(board)\n",
    "        if len(legal) == 0:\n",
    "            return 'tie'\n",
    "        move = random.choice(legal)\n",
    "        board = update_board(board,player,move)\n",
    "        winner = check_for_win(board,move)\n",
    "        # switch player\n",
    "        if player == 'plus':\n",
    "            player = 'minus'\n",
    "        else:\n",
    "            player = 'plus'\n",
    "    return winner\n",
    "        \n",
    "def mcts(board_temp,color0,nsteps):\n",
    "    # Traditional MCTS, plus small improvements:\n",
    "    board = board_temp.copy()\n",
    "    # 1. If there's an immediate winning move, use it\n",
    "    win_col = look_for_win(board,color0)\n",
    "    if win_col != -1:\n",
    "        return win_col\n",
    "    # 2. Look for any moves that avoid an immediate losing position\n",
    "    legal0 = find_all_nonlosers(board,color0)\n",
    "    if len(legal0) == 0:\n",
    "        # if no way to avoid opponent's immediate threat, use all legal moves\n",
    "        legal0 = find_legal(board)\n",
    "    \n",
    "    mcts_dict = {tuple(board.ravel()):[0,0]}\n",
    "    for _ in range(nsteps):\n",
    "        color = color0\n",
    "        winner = 'nobody'\n",
    "        board_mcts = board.copy()\n",
    "        path = [tuple(board_mcts.ravel())]\n",
    "        \n",
    "        while winner == 'nobody':\n",
    "            legal = find_legal(board_mcts)\n",
    "            if len(legal) == 0:\n",
    "                winner = 'tie'\n",
    "                back_prop(winner,path,color0,mcts_dict)\n",
    "                break\n",
    "            # list of next possible boards\n",
    "            board_list = []\n",
    "            for col in legal:\n",
    "                b_next = update_board(board_mcts,color,col)\n",
    "                board_list.append(tuple(b_next.ravel()))\n",
    "                if tuple(b_next.ravel()) not in mcts_dict:\n",
    "                    mcts_dict[tuple(b_next.ravel())] = [0,0]\n",
    "            \n",
    "            # UCB1 \n",
    "            ucb1 = np.zeros(len(legal))\n",
    "            for i, bl in enumerate(board_list):\n",
    "                num_sims, total_value = mcts_dict[bl]\n",
    "                if num_sims == 0:\n",
    "                    # large priority for unvisited\n",
    "                    ucb1[i] = 10 * nsteps\n",
    "                else:\n",
    "                    parent_sims = mcts_dict[path[-1]][0]\n",
    "                    avg_val = total_value / num_sims\n",
    "                    explore = np.sqrt(np.log(parent_sims)/num_sims)\n",
    "                    ucb1[i] = avg_val + 2*explore\n",
    "            \n",
    "            chosen = np.argmax(ucb1)\n",
    "            board_mcts = update_board(board_mcts,color,legal[chosen])\n",
    "            path.append(tuple(board_mcts.ravel()))\n",
    "            # check winner\n",
    "            winner = check_for_win(board_mcts,legal[chosen])\n",
    "            if winner[2] == color[0]:\n",
    "                back_prop(winner,path,color0,mcts_dict)\n",
    "                break\n",
    "            \n",
    "            # switch player\n",
    "            color = 'minus' if (color=='plus') else 'plus'\n",
    "            \n",
    "            # if the new board has never been visited, do a rollout\n",
    "            if mcts_dict[tuple(board_mcts.ravel())][0] == 0:\n",
    "                winner_roll = rollout(board_mcts,color)\n",
    "                back_prop(winner_roll,path,color0,mcts_dict)\n",
    "                break\n",
    "    \n",
    "    # pick the move with best average reward\n",
    "    best_col = -1\n",
    "    max_score = -np.inf\n",
    "    for col in legal0:\n",
    "        new_board = tuple(update_board(board,color0,col).ravel())\n",
    "        num_sims, total_val = mcts_dict[new_board]\n",
    "        if num_sims == 0:\n",
    "            # means we never visited it\n",
    "            score = -np.inf\n",
    "        else:\n",
    "            score = total_val/num_sims\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            best_col = col\n",
    "\n",
    "    return best_col\n",
    "\n",
    "\n",
    "def board_to_6x7x2(board_2d):\n",
    "    \"\"\"\n",
    "    Convert a 6x7 board with +1, -1, 0 \n",
    "    into a 6x7x2 one-hot style representation:\n",
    "       channel 0 => +1 positions\n",
    "       channel 1 => -1 positions\n",
    "    \"\"\"\n",
    "    X = np.zeros((6,7,2), dtype=np.float32)\n",
    "    for i in range(6):\n",
    "        for j in range(7):\n",
    "            if board_2d[i,j] == 1:\n",
    "                X[i,j,0] = 1\n",
    "            elif board_2d[i,j] == -1:\n",
    "                X[i,j,1] = 1\n",
    "    return X\n",
    "\n",
    "def minus_to_plus(board_6x7x2):\n",
    "    \"\"\"\n",
    "    Flip a (6,7,2) board from 'minus perspective' to 'plus perspective'\n",
    "    by swapping channels 0 and 1.\n",
    "      channel 0 => +1 squares\n",
    "      channel 1 => -1 squares\n",
    "    If originally channel 1 was the 'minus' squares, \n",
    "    after swap, that becomes the 'plus' squares, etc.\n",
    "    \"\"\"\n",
    "    flipped = board_6x7x2.copy()\n",
    "    flipped[..., 0], flipped[..., 1] = board_6x7x2[..., 1], board_6x7x2[..., 0]\n",
    "    return flipped\n",
    "\n",
    "def add_symmetric_flips(board_6x7x2, best_move):\n",
    "    \"\"\"\n",
    "    Given a (6,7,2) board and an integer best_move in [0..6],\n",
    "    return a list of:\n",
    "      [(original_board_6x7x2, best_move),\n",
    "       (flipped_board_6x7x2, flipped_move)].\n",
    "    The flipped version is mirrored left-to-right (column j -> 6-j).\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    \n",
    "    # 1) Original\n",
    "    out.append((board_6x7x2, best_move))\n",
    "    \n",
    "    # 2) Flipped left-right\n",
    "    flipped_board = board_6x7x2[:, ::-1, :].copy()\n",
    "    flipped_col = 6 - best_move\n",
    "    out.append((flipped_board, flipped_col))\n",
    "    \n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_one_game(plus_mcts_steps=800,\n",
    "                  minus_mcts_steps=800,\n",
    "                  random_openings=2):\n",
    "    \"\"\"\n",
    "    Returns a list of (board_6x7x2, best_move, skill_level),\n",
    "    where 'skill_level' is whichever MCTS steps were used.\n",
    "    For 'minus', we also flip the board to plus perspective.\n",
    "    We do NOT store random moves.\n",
    "    \"\"\"\n",
    "    data_this_game = []\n",
    "    board = np.zeros((6, 7), dtype=np.float32)\n",
    "    winner = 'nobody'\n",
    "    player = 'plus'\n",
    "    move_count = 0\n",
    "\n",
    "    while winner == 'nobody':\n",
    "        legal = find_legal(board)\n",
    "        if len(legal) == 0:\n",
    "            break  # tie\n",
    "\n",
    "        use_random = False\n",
    "        if move_count < 2 * random_openings:\n",
    "            use_random = True\n",
    "\n",
    "        if use_random:\n",
    "            col = random.choice(legal)\n",
    "            skill_used = 0  # skill=0 for random (we won't store these anyway)\n",
    "        else:\n",
    "            if player == 'plus':\n",
    "                col = mcts(board, 'plus', plus_mcts_steps)\n",
    "                skill_used = plus_mcts_steps\n",
    "            else:\n",
    "                col = mcts(board, 'minus', minus_mcts_steps)\n",
    "                skill_used = minus_mcts_steps\n",
    "\n",
    "        old_board = board.copy()\n",
    "        board = update_board(board, player, col)\n",
    "        winner = check_for_win(board, col)\n",
    "\n",
    "        if not use_random:\n",
    "            if player == 'plus':\n",
    "                board_6x7x2 = board_to_6x7x2(old_board)\n",
    "                # store (board, move, skill)\n",
    "                data_this_game.append((board_6x7x2, col, skill_used))\n",
    "            else:\n",
    "                board_6x7x2_minus = board_to_6x7x2(old_board)\n",
    "                board_6x7x2_plus = minus_to_plus(board_6x7x2_minus)\n",
    "                data_this_game.append((board_6x7x2_plus, col, skill_used))\n",
    "\n",
    "        player = 'minus' if (player == 'plus') else 'plus'\n",
    "        move_count += 1\n",
    "\n",
    "    return data_this_game\n",
    "\n",
    "def play_one_game_random_params():\n",
    "    \"\"\"\n",
    "    Roll random settings for plus/minus MCTS [500..5000],\n",
    "    and random_openings [1..15].\n",
    "    Return list of (board_6x7x2, best_move, skill).\n",
    "    \"\"\"\n",
    "    plus_mcts = random.randint(500, 5000)\n",
    "    minus_mcts = random.randint(500, 5000)\n",
    "    openings = random.randint(1, 15)\n",
    "    game_data = play_one_game(\n",
    "        plus_mcts_steps=plus_mcts,\n",
    "        minus_mcts_steps=minus_mcts,\n",
    "        random_openings=openings\n",
    "    )\n",
    "    return game_data  # list of (board, move, skill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_build_dataset(num_games=25000):\n",
    "    \"\"\"\n",
    "    Use joblib to run 'play_one_game_random_params()' in parallel.\n",
    "\n",
    "    data_dict will map:\n",
    "      key = (6,7,2) board .tobytes()\n",
    "      => { 'best_skill': int,\n",
    "           'move_counts': { move: (count) } }\n",
    "\n",
    "    If a new skill > best_skill, override the entire move_counts with the new move.\n",
    "    If skill == best_skill, we increment counts for that move as usual.\n",
    "    If skill < best_skill, ignore it (we keep the higher skill's recommendation).\n",
    "    \"\"\"\n",
    "    print(f\"Building dataset with {num_games} games in parallel...\")\n",
    "\n",
    "    results = Parallel(n_jobs=-1, backend='loky')(\n",
    "        delayed(play_one_game_random_params)()\n",
    "        for _ in range(num_games)\n",
    "    )\n",
    "\n",
    "    # data_dict: \n",
    "    #   key -> {'best_skill': X,\n",
    "    #           'move_counts': {move -> count}}\n",
    "    data_dict = defaultdict(lambda: {\"best_skill\": 0, \"move_counts\": defaultdict(int)})\n",
    "\n",
    "    print(\"Aggregating results & handling collisions with skill priority...\")\n",
    "\n",
    "    for game_data in results:\n",
    "        # game_data is list of (board_6x7x2, best_move, skill)\n",
    "        for (board_6x7x2, best_move, skill_used) in game_data:\n",
    "            # augment with symmetry\n",
    "            augmented = add_symmetric_flips(board_6x7x2, best_move)\n",
    "\n",
    "            for (b_aug, m_aug) in augmented:\n",
    "                key = b_aug.tobytes()\n",
    "                entry = data_dict[key]\n",
    "\n",
    "                current_best_skill = entry[\"best_skill\"]\n",
    "                move_counts = entry[\"move_counts\"]\n",
    "\n",
    "                if skill_used > current_best_skill:\n",
    "                    # override entire dictionary with new skill\n",
    "                    # and reset move_counts\n",
    "                    entry[\"best_skill\"] = skill_used\n",
    "                    entry[\"move_counts\"] = defaultdict(int)\n",
    "                    entry[\"move_counts\"][m_aug] = 1\n",
    "                elif skill_used == current_best_skill:\n",
    "                    # same skill -> just increment\n",
    "                    entry[\"move_counts\"][m_aug] += 1\n",
    "                else:\n",
    "                    # skill_used < current_best_skill => ignore\n",
    "                    pass\n",
    "\n",
    "    # Now resolve collisions by picking the move with the highest count\n",
    "    # for each board. We already only store moves from the highest skill.\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    for key, val in data_dict.items():\n",
    "        move_dict = val[\"move_counts\"]\n",
    "        # pick move with max count\n",
    "        if len(move_dict) == 0:\n",
    "            # might happen if skill=0 or something unexpected\n",
    "            continue\n",
    "        best_move = max(move_dict, key=move_dict.get)\n",
    "        arr = np.frombuffer(key, dtype=np.float32).reshape(6,7,2)\n",
    "        X_list.append(arr)\n",
    "        y_list.append(best_move)\n",
    "\n",
    "    X = np.stack(X_list, axis=0)\n",
    "    y = np.array(y_list, dtype=np.int32)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    NUM_GAMES = 50000\n",
    "    X, y = parallel_build_dataset(num_games=NUM_GAMES)\n",
    "    print(\"Finished building dataset!\")\n",
    "    print(\"X shape:\", X.shape)\n",
    "    print(\"y shape:\", y.shape)\n",
    "    print(\"Unique moves in y:\", np.unique(y))\n",
    "\n",
    "    # Save to disk\n",
    "    np.save(\"X_dataset_ethan3.npy\", X)\n",
    "    np.save(\"y_dataset_ethan3.npy\", y)\n",
    "    print(\"Dataset saved to X_dataset_ethan3.npy and y_dataset_ethan3.npy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before concatenation:\n",
      "  Dataset 1: (457185, 6, 7, 2) (457185,)\n",
      "  Dataset 2: (465707, 6, 7, 2) (465707,)\n",
      "After concatenation: (922892, 6, 7, 2) (922892,)\n",
      "Saved merged dataset to X_dataset_merged.npy, y_dataset_merged.npy.\n"
     ]
    }
   ],
   "source": [
    "# Append dataset code\n",
    "\n",
    "def append_datasets(file1_X, file1_y, file2_X, file2_y, out_X, out_y):\n",
    "    \"\"\"\n",
    "    Load two Connect4 datasets (X1,y1) and (X2,y2),\n",
    "    concatenate them along axis=0,\n",
    "    then save as (out_X, out_y).\n",
    "    \"\"\"\n",
    "    X1 = np.load(file1_X)\n",
    "    y1 = np.load(file1_y)\n",
    "    X2 = np.load(file2_X)\n",
    "    y2 = np.load(file2_y)\n",
    "\n",
    "    print(\"Before concatenation:\")\n",
    "    print(\"  Dataset 1:\", X1.shape, y1.shape)\n",
    "    print(\"  Dataset 2:\", X2.shape, y2.shape)\n",
    "\n",
    "    X_merged = np.concatenate([X1, X2], axis=0)\n",
    "    y_merged = np.concatenate([y1, y2], axis=0)\n",
    "\n",
    "    print(\"After concatenation:\", X_merged.shape, y_merged.shape)\n",
    "\n",
    "    np.save(out_X, X_merged)\n",
    "    np.save(out_y, y_merged)\n",
    "    print(f\"Saved merged dataset to {out_X}, {out_y}.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    append_datasets(\n",
    "        file1_X=\"X_dataset_ethan.npy\",\n",
    "        file1_y=\"y_dataset_ethan.npy\",\n",
    "        file2_X=\"X_dataset_ethan2.npy\",\n",
    "        file2_y=\"y_dataset_ethan2.npy\",\n",
    "        out_X=\"X_dataset_merged.npy\",\n",
    "        out_y=\"y_dataset_merged.npy\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes:\n",
      "X: (900019, 6, 7, 2)\n",
      "y: (900019,)\n",
      "Unique moves in y: [0 1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "X_file = \"X_dataset_ethan3.npy\"\n",
    "y_file = \"y_dataset_ethan3.npy\"\n",
    "\n",
    "X = np.load(X_file)  # shape (N, 6, 7, 2)\n",
    "y = np.load(y_file)  # shape (N,)\n",
    "\n",
    "print(\"Data shapes:\")\n",
    "print(\"X:\", X.shape)\n",
    "print(\"y:\", y.shape)\n",
    "unique_moves = np.unique(y)\n",
    "print(\"Unique moves in y:\", unique_moves)  # should be [0..6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 720015\n",
      "Validation set size: 180004\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.2, \n",
    "    random_state=22, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(\"Training set size:\", X_train.shape[0])\n",
    "print(\"Validation set size:\", X_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAvailable GPUs:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNetBigger\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 6, 7, 2)]    0           []                               \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 6, 7, 64)     1216        ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 6, 7, 64)    256         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_24 (ReLU)                (None, 6, 7, 64)     0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_24[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 6, 7, 64)    256         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_25 (ReLU)                (None, 6, 7, 64)     0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_25[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 6, 7, 64)    256         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_26 (ReLU)                (None, 6, 7, 64)     0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_26[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 6, 7, 64)    256         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 6, 7, 64)     0           ['re_lu_25[0][0]',               \n",
      "                                                                  'batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_27 (ReLU)                (None, 6, 7, 64)     0           ['add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_27[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 6, 7, 64)    256         ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_28 (ReLU)                (None, 6, 7, 64)     0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_28[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 6, 7, 64)    256         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 6, 7, 64)     0           ['re_lu_27[0][0]',               \n",
      "                                                                  'batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_29 (ReLU)                (None, 6, 7, 64)     0           ['add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_29[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 6, 7, 64)    256         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_30 (ReLU)                (None, 6, 7, 64)     0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_30[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 6, 7, 64)    256         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 6, 7, 64)     0           ['re_lu_29[0][0]',               \n",
      "                                                                  'batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_31 (ReLU)                (None, 6, 7, 64)     0           ['add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 3, 3, 64)    0           ['re_lu_31[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 3, 3, 128)    8320        ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 3, 3, 128)   512         ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_32 (ReLU)                (None, 3, 3, 128)    0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 3, 3, 128)    147584      ['re_lu_32[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 3, 3, 128)   512         ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_33 (ReLU)                (None, 3, 3, 128)    0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 3, 3, 128)    147584      ['re_lu_33[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 3, 3, 128)   512         ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 3, 3, 128)    0           ['re_lu_32[0][0]',               \n",
      "                                                                  'batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_34 (ReLU)                (None, 3, 3, 128)    0           ['add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 3, 3, 128)    147584      ['re_lu_34[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 3, 3, 128)   512         ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_35 (ReLU)                (None, 3, 3, 128)    0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 3, 3, 128)    147584      ['re_lu_35[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 3, 3, 128)   512         ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 3, 3, 128)    0           ['re_lu_34[0][0]',               \n",
      "                                                                  'batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_36 (ReLU)                (None, 3, 3, 128)    0           ['add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 128)   0           ['re_lu_36[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 1, 1, 128)    147584      ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 1, 1, 128)   512         ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_37 (ReLU)                (None, 1, 1, 128)    0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 1, 1, 128)    147584      ['re_lu_37[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 1, 1, 128)   512         ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 1, 1, 128)    0           ['max_pooling2d_3[0][0]',        \n",
      "                                                                  'batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_38 (ReLU)                (None, 1, 1, 128)    0           ['add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 1, 1, 128)    147584      ['re_lu_38[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 1, 1, 128)   512         ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_39 (ReLU)                (None, 1, 1, 128)    0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 1, 1, 128)    147584      ['re_lu_39[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 1, 1, 128)   512         ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 1, 1, 128)    0           ['re_lu_38[0][0]',               \n",
      "                                                                  'batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_40 (ReLU)                (None, 1, 1, 128)    0           ['add_15[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 1, 1, 256)    33024       ['re_lu_40[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 1, 1, 256)   1024        ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_41 (ReLU)                (None, 1, 1, 256)    0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 1, 1, 256)    590080      ['re_lu_41[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 1, 1, 256)   1024        ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_42 (ReLU)                (None, 1, 1, 256)    0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 1, 1, 256)    590080      ['re_lu_42[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 1, 1, 256)   1024        ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 1, 1, 256)    0           ['re_lu_41[0][0]',               \n",
      "                                                                  'batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_43 (ReLU)                (None, 1, 1, 256)    0           ['add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 1, 1, 256)    590080      ['re_lu_43[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 1, 1, 256)   1024        ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_44 (ReLU)                (None, 1, 1, 256)    0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 1, 1, 256)    590080      ['re_lu_44[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 1, 1, 256)   1024        ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 1, 1, 256)    0           ['re_lu_43[0][0]',               \n",
      "                                                                  'batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_45 (ReLU)                (None, 1, 1, 256)    0           ['add_17[0][0]']                 \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 256)          0           ['re_lu_45[0][0]']               \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1024)         263168      ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 1024)        4096        ['dense_3[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_46 (ReLU)                (None, 1024)         0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 1024)         0           ['re_lu_46[0][0]']               \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 512)          524800      ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 512)         2048        ['dense_4[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_47 (ReLU)                (None, 512)          0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 512)          0           ['re_lu_47[0][0]']               \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 7)            3591        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,651,527\n",
      "Trainable params: 4,642,567\n",
      "Non-trainable params: 8,960\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def residual_block(x, filters, kernel_size=(3,3), l2_reg=1e-6):\n",
    "    \"\"\"\n",
    "    A basic ResNet-style block:\n",
    "      - 3x3 Conv -> BN -> ReLU\n",
    "      - 3x3 Conv -> BN\n",
    "      - skip connection\n",
    "      - final ReLU\n",
    "    \"\"\"\n",
    "    shortcut = x\n",
    "\n",
    "    # 1st conv\n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same',\n",
    "                      kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 2nd conv\n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same',\n",
    "                      kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # skip connection\n",
    "    x = layers.Add()([shortcut, x])\n",
    "    x = layers.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "def build_resnet_bigger(\n",
    "    input_shape=(6,7,2),\n",
    "    num_classes=7,\n",
    "    l2_reg=1e-6,\n",
    "    dropout_rate=0.05\n",
    "):\n",
    "    \"\"\"\n",
    "    A bigger ResNet CNN for Connect 4.\n",
    "    Architecture:\n",
    "      1) Wide stem: conv(64)->(64) \n",
    "      2) 3 residual blocks at 64\n",
    "      3) MaxPool\n",
    "      4) Expand to 128\n",
    "      5) 2 residual blocks at 128\n",
    "      6) MaxPool\n",
    "      7) 2 residual blocks at 128\n",
    "      8) Expand to 256\n",
    "      9) 2 residual blocks at 256\n",
    "      10) Flatten\n",
    "      11) Dense(1024)->BN->ReLU->Dropout\n",
    "      12) Dense(512)->BN->ReLU->Dropout\n",
    "      13) Output(7, softmax)\n",
    "    \"\"\"\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # ==============\n",
    "    # 1. Wide Stem\n",
    "    # ==============\n",
    "    x = layers.Conv2D(64, (3,3), padding='same',\n",
    "                      kernel_regularizer=regularizers.l2(l2_reg))(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    x = layers.Conv2D(64, (3,3), padding='same',\n",
    "                      kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # ==============\n",
    "    # 2. 3 residual blocks at 64\n",
    "    # ==============\n",
    "    x = residual_block(x, filters=64,  l2_reg=l2_reg)\n",
    "    x = residual_block(x, filters=64,  l2_reg=l2_reg)\n",
    "    x = residual_block(x, filters=64,  l2_reg=l2_reg)\n",
    "\n",
    "    # 3. MaxPool\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), strides=2)(x)\n",
    "\n",
    "    # 4. Expand to 128\n",
    "    x = layers.Conv2D(128, (1,1), padding='same',\n",
    "                      kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 5. 2 residual blocks at 128\n",
    "    x = residual_block(x, filters=128, l2_reg=l2_reg)\n",
    "    x = residual_block(x, filters=128, l2_reg=l2_reg)\n",
    "\n",
    "    # 6. MaxPool\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), strides=2)(x)\n",
    "\n",
    "    # 7. 2 residual blocks at 128\n",
    "    x = residual_block(x, filters=128, l2_reg=l2_reg)\n",
    "    x = residual_block(x, filters=128, l2_reg=l2_reg)\n",
    "\n",
    "    # ==============\n",
    "    # 8. Expand to 256\n",
    "    # ==============\n",
    "    x = layers.Conv2D(256, (1,1), padding='same',\n",
    "                      kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 9. 2 residual blocks at 256\n",
    "    x = residual_block(x, filters=256, l2_reg=l2_reg)\n",
    "    x = residual_block(x, filters=256, l2_reg=l2_reg)\n",
    "\n",
    "    # flatten\n",
    "    x = layers.Flatten()(x)\n",
    "\n",
    "    # 11. Dense(1024)\n",
    "    x = layers.Dense(1024, kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    # 12. Dense(512)\n",
    "    x = layers.Dense(512, kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    # 13. Output\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs, outputs, name=\"ResNetBigger\")\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = build_resnet_bigger(\n",
    "        input_shape=(6,7,2),\n",
    "        num_classes=7,\n",
    "        l2_reg=1e-6,\n",
    "        dropout_rate=0.05\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.007),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11251/11251 [==============================] - 156s 14ms/step - loss: 1.2488 - accuracy: 0.5237 - val_loss: 0.9558 - val_accuracy: 0.6377 - lr: 0.0070\n",
      "Epoch 2/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.9407 - accuracy: 0.6488 - val_loss: 0.9086 - val_accuracy: 0.6640 - lr: 0.0070\n",
      "Epoch 3/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.8987 - accuracy: 0.6676 - val_loss: 0.8976 - val_accuracy: 0.6675 - lr: 0.0070\n",
      "Epoch 4/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.8787 - accuracy: 0.6762 - val_loss: 0.8829 - val_accuracy: 0.6742 - lr: 0.0070\n",
      "Epoch 5/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.8665 - accuracy: 0.6809 - val_loss: 0.8550 - val_accuracy: 0.6830 - lr: 0.0070\n",
      "Epoch 6/100\n",
      "11251/11251 [==============================] - 152s 14ms/step - loss: 0.8570 - accuracy: 0.6850 - val_loss: 0.8479 - val_accuracy: 0.6873 - lr: 0.0070\n",
      "Epoch 7/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.8493 - accuracy: 0.6879 - val_loss: 0.8489 - val_accuracy: 0.6825 - lr: 0.0070\n",
      "Epoch 8/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.8449 - accuracy: 0.6895 - val_loss: 0.8449 - val_accuracy: 0.6884 - lr: 0.0070\n",
      "Epoch 9/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.8393 - accuracy: 0.6920 - val_loss: 0.8395 - val_accuracy: 0.6933 - lr: 0.0070\n",
      "Epoch 10/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.8363 - accuracy: 0.6927 - val_loss: 0.8441 - val_accuracy: 0.6859 - lr: 0.0070\n",
      "Epoch 11/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.8329 - accuracy: 0.6943 - val_loss: 0.8424 - val_accuracy: 0.6921 - lr: 0.0070\n",
      "Epoch 12/100\n",
      "11250/11251 [============================>.] - ETA: 0s - loss: 0.8314 - accuracy: 0.6944\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0035000001080334187.\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.8314 - accuracy: 0.6944 - val_loss: 0.8295 - val_accuracy: 0.6921 - lr: 0.0070\n",
      "Epoch 13/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.7818 - accuracy: 0.7105 - val_loss: 0.7729 - val_accuracy: 0.7129 - lr: 0.0035\n",
      "Epoch 14/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.7678 - accuracy: 0.7146 - val_loss: 0.7721 - val_accuracy: 0.7114 - lr: 0.0035\n",
      "Epoch 15/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.7610 - accuracy: 0.7157 - val_loss: 0.7672 - val_accuracy: 0.7111 - lr: 0.0035\n",
      "Epoch 16/100\n",
      "11250/11251 [============================>.] - ETA: 0s - loss: 0.7569 - accuracy: 0.7167\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0017500000540167093.\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.7569 - accuracy: 0.7167 - val_loss: 0.7725 - val_accuracy: 0.7113 - lr: 0.0035\n",
      "Epoch 17/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.7247 - accuracy: 0.7283 - val_loss: 0.7442 - val_accuracy: 0.7188 - lr: 0.0018\n",
      "Epoch 18/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.7139 - accuracy: 0.7314 - val_loss: 0.7396 - val_accuracy: 0.7202 - lr: 0.0018\n",
      "Epoch 19/100\n",
      "11251/11251 [==============================] - 152s 14ms/step - loss: 0.7090 - accuracy: 0.7329 - val_loss: 0.7461 - val_accuracy: 0.7203 - lr: 0.0018\n",
      "Epoch 20/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.7051 - accuracy: 0.7341 - val_loss: 0.7412 - val_accuracy: 0.7203 - lr: 0.0018\n",
      "Epoch 21/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.7014 - accuracy: 0.7346 - val_loss: 0.7405 - val_accuracy: 0.7195 - lr: 0.0018\n",
      "Epoch 22/100\n",
      "11248/11251 [============================>.] - ETA: 0s - loss: 0.6977 - accuracy: 0.7361\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0008750000270083547.\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.6977 - accuracy: 0.7361 - val_loss: 0.7389 - val_accuracy: 0.7200 - lr: 0.0018\n",
      "Epoch 23/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.6752 - accuracy: 0.7447 - val_loss: 0.7331 - val_accuracy: 0.7245 - lr: 8.7500e-04\n",
      "Epoch 24/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.6682 - accuracy: 0.7471 - val_loss: 0.7359 - val_accuracy: 0.7229 - lr: 8.7500e-04\n",
      "Epoch 25/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.6647 - accuracy: 0.7478 - val_loss: 0.7342 - val_accuracy: 0.7240 - lr: 8.7500e-04\n",
      "Epoch 26/100\n",
      "11247/11251 [============================>.] - ETA: 0s - loss: 0.6609 - accuracy: 0.7490\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00043750001350417733.\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.6609 - accuracy: 0.7490 - val_loss: 0.7355 - val_accuracy: 0.7235 - lr: 8.7500e-04\n",
      "Epoch 27/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.6454 - accuracy: 0.7543 - val_loss: 0.7385 - val_accuracy: 0.7245 - lr: 4.3750e-04\n",
      "Epoch 28/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.6413 - accuracy: 0.7558 - val_loss: 0.7401 - val_accuracy: 0.7235 - lr: 4.3750e-04\n",
      "Epoch 29/100\n",
      "11248/11251 [============================>.] - ETA: 0s - loss: 0.6386 - accuracy: 0.7570\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00021875000675208867.\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.6386 - accuracy: 0.7570 - val_loss: 0.7418 - val_accuracy: 0.7230 - lr: 4.3750e-04\n",
      "Epoch 30/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.6295 - accuracy: 0.7603 - val_loss: 0.7452 - val_accuracy: 0.7237 - lr: 2.1875e-04\n",
      "Epoch 31/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.6270 - accuracy: 0.7610 - val_loss: 0.7448 - val_accuracy: 0.7237 - lr: 2.1875e-04\n",
      "Epoch 32/100\n",
      "11248/11251 [============================>.] - ETA: 0s - loss: 0.6254 - accuracy: 0.7612\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00010937500337604433.\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.6254 - accuracy: 0.7612 - val_loss: 0.7468 - val_accuracy: 0.7227 - lr: 2.1875e-04\n",
      "Epoch 33/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.6198 - accuracy: 0.7639 - val_loss: 0.7499 - val_accuracy: 0.7234 - lr: 1.0938e-04\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 64\n",
    "\n",
    "# Early stopping if val_accuracy doesnt improve for 7 epochs\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Reduce learning rate by factor of 0.5 if val_accuracy doesnt improve for 3 epochs\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 72.45%   (loss=0.7331)\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(f\"Validation accuracy: {val_acc*100:.2f}%   (loss={val_loss:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to cnn_connect4.h5.\n"
     ]
    }
   ],
   "source": [
    "#model.save(\"cnn_connect4.h5\")\n",
    "#print(\"Model saved to cnn_connect4.h5.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Plot loss\n",
    "axs[0].plot(history.history['loss'], label='train_loss')\n",
    "axs[0].plot(history.history['val_loss'], label='val_loss')\n",
    "axs[0].set_title(\"Loss\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "# Plot accuracy\n",
    "axs[1].plot(history.history['accuracy'], label='train_acc')\n",
    "axs[1].plot(history.history['val_accuracy'], label='val_acc')\n",
    "axs[1].set_title(\"Accuracy\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Accuracy\")\n",
    "axs[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalIndex(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Produces a position index [0..seq_len-1] for each\n",
    "    element in the batch, so we can embed positions.\n",
    "    \"\"\"\n",
    "    def call(self, x):\n",
    "        \"\"\"\n",
    "        x shape: (batch_size, seq_len, embed_dim)\n",
    "        returns: (batch_size, seq_len) of indices\n",
    "        \"\"\"\n",
    "        bs = tf.shape(x)[0]            # batch size\n",
    "        seq_len = tf.shape(x)[1]       # how many patches in the sequence\n",
    "        indices = tf.range(seq_len)    # [0..seq_len-1]\n",
    "        indices = tf.expand_dims(indices, 0)    # shape (1, seq_len)\n",
    "        return tf.tile(indices, [bs, 1])        # shape (bs, seq_len)\n",
    "\n",
    "class ClassTokenIndex(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Produces a single index (0) for each batch to embed\n",
    "    a class token. We'll embed that index with a separate embedding.\n",
    "    \"\"\"\n",
    "    def call(self, x):\n",
    "        \"\"\"\n",
    "        x shape: (batch_size, seq_len, embed_dim)\n",
    "        returns: (batch_size, 1)\n",
    "        \"\"\"\n",
    "        bs = tf.shape(x)[0]\n",
    "        # just a single index [0]\n",
    "        idx = tf.zeros((1,1), dtype=tf.int32)   # shape (1,1)\n",
    "        return tf.tile(idx, [bs, 1])           # shape (bs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transformer_connect4_overlapping(\n",
    "    input_shape=(6,7,2),\n",
    "    hidden_dim=256,\n",
    "    num_layers=8,\n",
    "    num_heads=8,\n",
    "    key_dim=None,\n",
    "    mlp_dim=None,\n",
    "    dropout_rate=0.15,\n",
    "    num_classes=7,\n",
    "    l2_reg=1e-4\n",
    "):\n",
    "    \"\"\"\n",
    "    A deeper Transformer for Connect4 with overlapping patches.\n",
    "\n",
    "    Steps:\n",
    "      1) Conv2D with kernel_size=3, stride=1 => overlapping patches:\n",
    "         output shape => (4,5, hidden_dim) => 20 patches\n",
    "      2) Flatten to (20, hidden_dim)\n",
    "      3) Learn positional embedding for positions [0..19]\n",
    "      4) Class token appended => total 21 tokens\n",
    "      5) 8 Transformer blocks (Multi-head attention + MLP)\n",
    "      6) Output on class token => Dense(7, softmax)\n",
    "\n",
    "    Returns: compiled tf.keras.Model\n",
    "    \"\"\"\n",
    "    if key_dim is None:\n",
    "        key_dim = hidden_dim // num_heads\n",
    "    if mlp_dim is None:\n",
    "        mlp_dim = hidden_dim * 4  # typical factor of 4\n",
    "\n",
    "    # 1) Overlapping patch embedding\n",
    "    inputs = layers.Input(shape=input_shape)  # (None,6,7,2)\n",
    "    # conv with stride=1 => shape => ((6-3+1)=4, (7-3+1)=5) => 4x5=20 patches\n",
    "    patch_embed = layers.Conv2D(\n",
    "        filters=hidden_dim,\n",
    "        kernel_size=3,\n",
    "        strides=1,\n",
    "        padding='valid',\n",
    "        kernel_regularizer=regularizers.l2(l2_reg)\n",
    "    )(inputs)  # shape => (None,4,5, hidden_dim)\n",
    "    # flatten => shape => (None, 20, hidden_dim)\n",
    "    seq = layers.Reshape((-1, hidden_dim))(patch_embed)\n",
    "\n",
    "    # 2) Positional embedding\n",
    "    pos_indices = PositionalIndex()(seq)  # shape (bs, 20)\n",
    "    pos_embed = layers.Embedding(\n",
    "        input_dim=20,     # up to 20 patch positions\n",
    "        output_dim=hidden_dim,\n",
    "        embeddings_regularizer=regularizers.l2(l2_reg)\n",
    "    )(pos_indices)        # (bs, 20, hidden_dim)\n",
    "\n",
    "    x = layers.Add()([seq, pos_embed])  # shape => (bs,20,hidden_dim)\n",
    "\n",
    "    # 3) Class token\n",
    "    cls_idx = ClassTokenIndex()(x)  # shape => (bs,1)\n",
    "    cls_token = layers.Embedding(\n",
    "        input_dim=1,\n",
    "        output_dim=hidden_dim,\n",
    "        embeddings_regularizer=regularizers.l2(l2_reg)\n",
    "    )(cls_idx)  # => (bs,1,hidden_dim)\n",
    "\n",
    "    # concat => shape => (bs,21,hidden_dim)\n",
    "    x = layers.Concatenate(axis=1)([cls_token, x])\n",
    "\n",
    "    # 4) Stacked Transformer blocks\n",
    "    for _ in range(num_layers):\n",
    "        # LN + MHA\n",
    "        ln1 = layers.LayerNormalization()(x)\n",
    "        attn_out = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=key_dim,\n",
    "            dropout=dropout_rate,\n",
    "            kernel_regularizer=regularizers.l2(l2_reg),\n",
    "            bias_regularizer=regularizers.l2(l2_reg),\n",
    "        )(ln1, ln1, ln1)  # self-attention\n",
    "        x = layers.Add()([x, attn_out])  # residual\n",
    "\n",
    "        # LN + Feed-forward\n",
    "        ln2 = layers.LayerNormalization()(x)\n",
    "        ff = layers.Dense(\n",
    "            mlp_dim, activation='gelu',\n",
    "            kernel_regularizer=regularizers.l2(l2_reg)\n",
    "        )(ln2)\n",
    "        ff = layers.Dropout(dropout_rate)(ff)\n",
    "        ff = layers.Dense(\n",
    "            hidden_dim,\n",
    "            kernel_regularizer=regularizers.l2(l2_reg)\n",
    "        )(ff)\n",
    "        ff = layers.Dropout(dropout_rate)(ff)\n",
    "        x = layers.Add()([x, ff])  # residual\n",
    "\n",
    "    # 5) Final classification on class token => x[:,0,:]\n",
    "    cls_vec = x[:, 0, :]  # shape (bs, hidden_dim)\n",
    "    ln = layers.LayerNormalization()(cls_vec)\n",
    "    logits = layers.Dense(\n",
    "        num_classes, activation='softmax',\n",
    "        kernel_regularizer=regularizers.l2(l2_reg)\n",
    "    )(ln)\n",
    "\n",
    "    # compile\n",
    "    model = models.Model(inputs, logits, name=\"ViT_Connect4_Overlapping\")\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.003),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building an Overlapping-Patch Transformer for Connect4 shape (6,7,2)...\n",
      "Model: \"ViT_Connect4_Overlapping\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 6, 7, 2)]    0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 4, 5, 284)    5396        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 20, 284)      0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " positional_index (PositionalIn  (None, 20)          0           ['reshape[0][0]']                \n",
      " dex)                                                                                             \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 20, 284)      5680        ['positional_index[0][0]']       \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 20, 284)      0           ['reshape[0][0]',                \n",
      "                                                                  'embedding[0][0]']              \n",
      "                                                                                                  \n",
      " class_token_index (ClassTokenI  (None, 1)           0           ['add[0][0]']                    \n",
      " ndex)                                                                                            \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 1, 284)       284         ['class_token_index[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 21, 284)      0           ['embedding_1[0][0]',            \n",
      "                                                                  'add[0][0]']                    \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 21, 284)     568         ['concatenate[0][0]']            \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 21, 284)     437660      ['layer_normalization[0][0]',    \n",
      " dAttention)                                                      'layer_normalization[0][0]',    \n",
      "                                                                  'layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 21, 284)      0           ['concatenate[0][0]',            \n",
      "                                                                  'multi_head_attention[0][0]']   \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 21, 284)     568         ['add_1[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 21, 384)      109440      ['layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 21, 384)      0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 21, 284)      109340      ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 21, 284)      0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 21, 284)      0           ['add_1[0][0]',                  \n",
      "                                                                  'dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 21, 284)     568         ['add_2[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 21, 284)     437660      ['layer_normalization_2[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_2[0][0]',  \n",
      "                                                                  'layer_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 21, 284)      0           ['add_2[0][0]',                  \n",
      "                                                                  'multi_head_attention_1[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 21, 284)     568         ['add_3[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 21, 384)      109440      ['layer_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 21, 384)      0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 21, 284)      109340      ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 21, 284)      0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 21, 284)      0           ['add_3[0][0]',                  \n",
      "                                                                  'dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 21, 284)     568         ['add_4[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 21, 284)     437660      ['layer_normalization_4[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_4[0][0]',  \n",
      "                                                                  'layer_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 21, 284)      0           ['add_4[0][0]',                  \n",
      "                                                                  'multi_head_attention_2[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 21, 284)     568         ['add_5[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 21, 384)      109440      ['layer_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 21, 384)      0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 21, 284)      109340      ['dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 21, 284)      0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 21, 284)      0           ['add_5[0][0]',                  \n",
      "                                                                  'dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 21, 284)     568         ['add_6[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 21, 284)     437660      ['layer_normalization_6[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_6[0][0]',  \n",
      "                                                                  'layer_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 21, 284)      0           ['add_6[0][0]',                  \n",
      "                                                                  'multi_head_attention_3[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 21, 284)     568         ['add_7[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 21, 384)      109440      ['layer_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 21, 384)      0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 21, 284)      109340      ['dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 21, 284)      0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 21, 284)      0           ['add_7[0][0]',                  \n",
      "                                                                  'dropout_15[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_8 (LayerNo  (None, 21, 284)     568         ['add_8[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_4 (MultiH  (None, 21, 284)     437660      ['layer_normalization_8[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_8[0][0]',  \n",
      "                                                                  'layer_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 21, 284)      0           ['add_8[0][0]',                  \n",
      "                                                                  'multi_head_attention_4[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_9 (LayerNo  (None, 21, 284)     568         ['add_9[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 21, 384)      109440      ['layer_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 21, 384)      0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 21, 284)      109340      ['dropout_16[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 21, 284)      0           ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 21, 284)      0           ['add_9[0][0]',                  \n",
      "                                                                  'dropout_17[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_10 (LayerN  (None, 21, 284)     568         ['add_10[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (MultiH  (None, 21, 284)     437660      ['layer_normalization_10[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_10[0][0]', \n",
      "                                                                  'layer_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 21, 284)      0           ['add_10[0][0]',                 \n",
      "                                                                  'multi_head_attention_5[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_11 (LayerN  (None, 21, 284)     568         ['add_11[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 21, 384)      109440      ['layer_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)           (None, 21, 384)      0           ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 21, 284)      109340      ['dropout_18[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)           (None, 21, 284)      0           ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 21, 284)      0           ['add_11[0][0]',                 \n",
      "                                                                  'dropout_19[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_12 (LayerN  (None, 21, 284)     568         ['add_12[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_6 (MultiH  (None, 21, 284)     437660      ['layer_normalization_12[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_12[0][0]', \n",
      "                                                                  'layer_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 21, 284)      0           ['add_12[0][0]',                 \n",
      "                                                                  'multi_head_attention_6[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_13 (LayerN  (None, 21, 284)     568         ['add_13[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 21, 384)      109440      ['layer_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)           (None, 21, 384)      0           ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 21, 284)      109340      ['dropout_20[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_21 (Dropout)           (None, 21, 284)      0           ['dense_13[0][0]']               \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 21, 284)      0           ['add_13[0][0]',                 \n",
      "                                                                  'dropout_21[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_14 (LayerN  (None, 21, 284)     568         ['add_14[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_7 (MultiH  (None, 21, 284)     437660      ['layer_normalization_14[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_14[0][0]', \n",
      "                                                                  'layer_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 21, 284)      0           ['add_14[0][0]',                 \n",
      "                                                                  'multi_head_attention_7[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_15 (LayerN  (None, 21, 284)     568         ['add_15[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 21, 384)      109440      ['layer_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_22 (Dropout)           (None, 21, 384)      0           ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 21, 284)      109340      ['dropout_22[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_23 (Dropout)           (None, 21, 284)      0           ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 21, 284)      0           ['add_15[0][0]',                 \n",
      "                                                                  'dropout_23[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_16 (LayerN  (None, 21, 284)     568         ['add_16[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_8 (MultiH  (None, 21, 284)     437660      ['layer_normalization_16[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_16[0][0]', \n",
      "                                                                  'layer_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 21, 284)      0           ['add_16[0][0]',                 \n",
      "                                                                  'multi_head_attention_8[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_17 (LayerN  (None, 21, 284)     568         ['add_17[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 21, 384)      109440      ['layer_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_24 (Dropout)           (None, 21, 384)      0           ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 21, 284)      109340      ['dropout_24[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_25 (Dropout)           (None, 21, 284)      0           ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, 21, 284)      0           ['add_17[0][0]',                 \n",
      "                                                                  'dropout_25[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_18 (LayerN  (None, 21, 284)     568         ['add_18[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_9 (MultiH  (None, 21, 284)     437660      ['layer_normalization_18[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_18[0][0]', \n",
      "                                                                  'layer_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " add_19 (Add)                   (None, 21, 284)      0           ['add_18[0][0]',                 \n",
      "                                                                  'multi_head_attention_9[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_19 (LayerN  (None, 21, 284)     568         ['add_19[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 21, 384)      109440      ['layer_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_26 (Dropout)           (None, 21, 384)      0           ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 21, 284)      109340      ['dropout_26[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_27 (Dropout)           (None, 21, 284)      0           ['dense_19[0][0]']               \n",
      "                                                                                                  \n",
      " add_20 (Add)                   (None, 21, 284)      0           ['add_19[0][0]',                 \n",
      "                                                                  'dropout_27[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1 (Sl  (None, 284)         0           ['add_20[0][0]']                 \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " layer_normalization_20 (LayerN  (None, 284)         568         ['tf.__operators__.getitem_1[0][0\n",
      " ormalization)                                                   ]']                              \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 7)            1995        ['layer_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6,589,683\n",
      "Trainable params: 6,589,683\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Building an Overlapping-Patch Transformer for Connect4 shape (6,7,2)...\")\n",
    "    # You can tweak hidden_dim, num_layers, etc. further\n",
    "    transformer_model = build_transformer_connect4_overlapping(\n",
    "        input_shape=(6,7,2),\n",
    "        hidden_dim=284,\n",
    "        num_layers=10,\n",
    "        num_heads=8,\n",
    "        key_dim=48,     # defaults to hidden_dim//num_heads\n",
    "        mlp_dim=384,     # defaults to 4*hidden_dim\n",
    "        dropout_rate=0.1,\n",
    "        num_classes=7,\n",
    "        l2_reg=1e-4\n",
    "    )\n",
    "\n",
    "    transformer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5626/5626 [==============================] - 204s 35ms/step - loss: 1.8665 - accuracy: 0.2623 - val_loss: 1.6676 - val_accuracy: 0.3326 - lr: 0.0030\n",
      "Epoch 2/200\n",
      "5626/5626 [==============================] - 194s 35ms/step - loss: 1.6114 - accuracy: 0.3584 - val_loss: 1.5311 - val_accuracy: 0.4022 - lr: 0.0030\n",
      "Epoch 3/200\n",
      "5626/5626 [==============================] - 195s 35ms/step - loss: 1.5205 - accuracy: 0.4090 - val_loss: 1.4757 - val_accuracy: 0.4298 - lr: 0.0030\n",
      "Epoch 4/200\n",
      "5626/5626 [==============================] - 195s 35ms/step - loss: 1.4795 - accuracy: 0.4294 - val_loss: 1.4580 - val_accuracy: 0.4397 - lr: 0.0030\n",
      "Epoch 5/200\n",
      "5626/5626 [==============================] - 195s 35ms/step - loss: 1.4544 - accuracy: 0.4397 - val_loss: 1.4384 - val_accuracy: 0.4452 - lr: 0.0030\n",
      "Epoch 6/200\n",
      "5626/5626 [==============================] - 195s 35ms/step - loss: 1.4412 - accuracy: 0.4453 - val_loss: 1.4225 - val_accuracy: 0.4547 - lr: 0.0030\n",
      "Epoch 7/200\n",
      "5626/5626 [==============================] - 195s 35ms/step - loss: 1.4332 - accuracy: 0.4494 - val_loss: 1.4321 - val_accuracy: 0.4481 - lr: 0.0030\n",
      "Epoch 8/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.4268 - accuracy: 0.4526 - val_loss: 1.4159 - val_accuracy: 0.4550 - lr: 0.0030\n",
      "Epoch 9/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.4230 - accuracy: 0.4541 - val_loss: 1.3959 - val_accuracy: 0.4666 - lr: 0.0030\n",
      "Epoch 10/200\n",
      "5626/5626 [==============================] - 195s 35ms/step - loss: 1.4196 - accuracy: 0.4562 - val_loss: 1.3918 - val_accuracy: 0.4688 - lr: 0.0030\n",
      "Epoch 11/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.4168 - accuracy: 0.4579 - val_loss: 1.3963 - val_accuracy: 0.4661 - lr: 0.0030\n",
      "Epoch 12/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.4142 - accuracy: 0.4586 - val_loss: 1.4132 - val_accuracy: 0.4611 - lr: 0.0030\n",
      "Epoch 13/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.4106 - accuracy: 0.4609 - val_loss: 1.3922 - val_accuracy: 0.4697 - lr: 0.0030\n",
      "Epoch 14/200\n",
      "5626/5626 [==============================] - 195s 35ms/step - loss: 1.4068 - accuracy: 0.4628 - val_loss: 1.3844 - val_accuracy: 0.4722 - lr: 0.0030\n",
      "Epoch 15/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.4032 - accuracy: 0.4641 - val_loss: 1.3777 - val_accuracy: 0.4749 - lr: 0.0030\n",
      "Epoch 16/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.3996 - accuracy: 0.4664 - val_loss: 1.3813 - val_accuracy: 0.4734 - lr: 0.0030\n",
      "Epoch 17/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.3966 - accuracy: 0.4676 - val_loss: 1.3802 - val_accuracy: 0.4753 - lr: 0.0030\n",
      "Epoch 18/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.3939 - accuracy: 0.4694 - val_loss: 1.3831 - val_accuracy: 0.4733 - lr: 0.0030\n",
      "Epoch 19/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.3904 - accuracy: 0.4723 - val_loss: 1.3609 - val_accuracy: 0.4832 - lr: 0.0030\n",
      "Epoch 20/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.3861 - accuracy: 0.4743 - val_loss: 1.3735 - val_accuracy: 0.4808 - lr: 0.0030\n",
      "Epoch 21/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.3835 - accuracy: 0.4764 - val_loss: 1.3741 - val_accuracy: 0.4799 - lr: 0.0030\n",
      "Epoch 22/200\n",
      "5625/5626 [============================>.] - ETA: 0s - loss: 1.3795 - accuracy: 0.4781\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.001500000013038516.\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.3795 - accuracy: 0.4781 - val_loss: 1.4074 - val_accuracy: 0.4655 - lr: 0.0030\n",
      "Epoch 23/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.3320 - accuracy: 0.4968 - val_loss: 1.3005 - val_accuracy: 0.5083 - lr: 0.0015\n",
      "Epoch 24/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.3211 - accuracy: 0.4997 - val_loss: 1.2983 - val_accuracy: 0.5079 - lr: 0.0015\n",
      "Epoch 25/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.3153 - accuracy: 0.5015 - val_loss: 1.3039 - val_accuracy: 0.5033 - lr: 0.0015\n",
      "Epoch 26/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.3107 - accuracy: 0.5032 - val_loss: 1.2913 - val_accuracy: 0.5117 - lr: 0.0015\n",
      "Epoch 27/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.3067 - accuracy: 0.5049 - val_loss: 1.2780 - val_accuracy: 0.5170 - lr: 0.0015\n",
      "Epoch 28/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.3032 - accuracy: 0.5065 - val_loss: 1.2816 - val_accuracy: 0.5147 - lr: 0.0015\n",
      "Epoch 29/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.3004 - accuracy: 0.5080 - val_loss: 1.2759 - val_accuracy: 0.5160 - lr: 0.0015\n",
      "Epoch 30/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.2975 - accuracy: 0.5095 - val_loss: 1.2707 - val_accuracy: 0.5197 - lr: 0.0015\n",
      "Epoch 31/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.2960 - accuracy: 0.5102 - val_loss: 1.2790 - val_accuracy: 0.5178 - lr: 0.0015\n",
      "Epoch 32/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.2949 - accuracy: 0.5111 - val_loss: 1.2650 - val_accuracy: 0.5240 - lr: 0.0015\n",
      "Epoch 33/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.2934 - accuracy: 0.5115 - val_loss: 1.2722 - val_accuracy: 0.5200 - lr: 0.0015\n",
      "Epoch 34/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.2927 - accuracy: 0.5118 - val_loss: 1.2793 - val_accuracy: 0.5161 - lr: 0.0015\n",
      "Epoch 35/200\n",
      "5625/5626 [============================>.] - ETA: 0s - loss: 1.2915 - accuracy: 0.5122\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.000750000006519258.\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.2914 - accuracy: 0.5122 - val_loss: 1.2689 - val_accuracy: 0.5217 - lr: 0.0015\n",
      "Epoch 36/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.2573 - accuracy: 0.5244 - val_loss: 1.2166 - val_accuracy: 0.5407 - lr: 7.5000e-04\n",
      "Epoch 37/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.2503 - accuracy: 0.5271 - val_loss: 1.2174 - val_accuracy: 0.5395 - lr: 7.5000e-04\n",
      "Epoch 38/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.2461 - accuracy: 0.5283 - val_loss: 1.2190 - val_accuracy: 0.5386 - lr: 7.5000e-04\n",
      "Epoch 39/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.2435 - accuracy: 0.5298 - val_loss: 1.2067 - val_accuracy: 0.5433 - lr: 7.5000e-04\n",
      "Epoch 40/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.2403 - accuracy: 0.5302 - val_loss: 1.2067 - val_accuracy: 0.5423 - lr: 7.5000e-04\n",
      "Epoch 41/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.2371 - accuracy: 0.5324 - val_loss: 1.2033 - val_accuracy: 0.5452 - lr: 7.5000e-04\n",
      "Epoch 42/200\n",
      "5626/5626 [==============================] - 205s 36ms/step - loss: 1.2341 - accuracy: 0.5334 - val_loss: 1.1997 - val_accuracy: 0.5465 - lr: 7.5000e-04\n",
      "Epoch 43/200\n",
      "5626/5626 [==============================] - 205s 37ms/step - loss: 1.2316 - accuracy: 0.5344 - val_loss: 1.1891 - val_accuracy: 0.5492 - lr: 7.5000e-04\n",
      "Epoch 44/200\n",
      "5626/5626 [==============================] - 213s 38ms/step - loss: 1.2281 - accuracy: 0.5355 - val_loss: 1.1935 - val_accuracy: 0.5489 - lr: 7.5000e-04\n",
      "Epoch 45/200\n",
      "5626/5626 [==============================] - 217s 39ms/step - loss: 1.2263 - accuracy: 0.5365 - val_loss: 1.1961 - val_accuracy: 0.5481 - lr: 7.5000e-04\n",
      "Epoch 46/200\n",
      "5625/5626 [============================>.] - ETA: 0s - loss: 1.2242 - accuracy: 0.5379\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.000375000003259629.\n",
      "5626/5626 [==============================] - 215s 38ms/step - loss: 1.2242 - accuracy: 0.5379 - val_loss: 1.1943 - val_accuracy: 0.5491 - lr: 7.5000e-04\n",
      "Epoch 47/200\n",
      "5626/5626 [==============================] - 216s 38ms/step - loss: 1.1988 - accuracy: 0.5466 - val_loss: 1.1633 - val_accuracy: 0.5610 - lr: 3.7500e-04\n",
      "Epoch 48/200\n",
      "5626/5626 [==============================] - 195s 35ms/step - loss: 1.1943 - accuracy: 0.5488 - val_loss: 1.1623 - val_accuracy: 0.5597 - lr: 3.7500e-04\n",
      "Epoch 49/200\n",
      "5626/5626 [==============================] - 197s 35ms/step - loss: 1.1914 - accuracy: 0.5498 - val_loss: 1.1556 - val_accuracy: 0.5630 - lr: 3.7500e-04\n",
      "Epoch 50/200\n",
      "5626/5626 [==============================] - 197s 35ms/step - loss: 1.1890 - accuracy: 0.5505 - val_loss: 1.1579 - val_accuracy: 0.5609 - lr: 3.7500e-04\n",
      "Epoch 51/200\n",
      "5626/5626 [==============================] - 197s 35ms/step - loss: 1.1870 - accuracy: 0.5508 - val_loss: 1.1490 - val_accuracy: 0.5639 - lr: 3.7500e-04\n",
      "Epoch 52/200\n",
      "5626/5626 [==============================] - 197s 35ms/step - loss: 1.1847 - accuracy: 0.5512 - val_loss: 1.1450 - val_accuracy: 0.5661 - lr: 3.7500e-04\n",
      "Epoch 53/200\n",
      "5626/5626 [==============================] - 197s 35ms/step - loss: 1.1818 - accuracy: 0.5524 - val_loss: 1.1607 - val_accuracy: 0.5611 - lr: 3.7500e-04\n",
      "Epoch 54/200\n",
      "5626/5626 [==============================] - 197s 35ms/step - loss: 1.1799 - accuracy: 0.5529 - val_loss: 1.1437 - val_accuracy: 0.5664 - lr: 3.7500e-04\n",
      "Epoch 55/200\n",
      "5626/5626 [==============================] - 197s 35ms/step - loss: 1.1774 - accuracy: 0.5537 - val_loss: 1.1461 - val_accuracy: 0.5674 - lr: 3.7500e-04\n",
      "Epoch 56/200\n",
      "5626/5626 [==============================] - 197s 35ms/step - loss: 1.1749 - accuracy: 0.5550 - val_loss: 1.1382 - val_accuracy: 0.5670 - lr: 3.7500e-04\n",
      "Epoch 57/200\n",
      "5626/5626 [==============================] - 197s 35ms/step - loss: 1.1715 - accuracy: 0.5553 - val_loss: 1.1312 - val_accuracy: 0.5705 - lr: 3.7500e-04\n",
      "Epoch 58/200\n",
      "5626/5626 [==============================] - 197s 35ms/step - loss: 1.1698 - accuracy: 0.5563 - val_loss: 1.1246 - val_accuracy: 0.5725 - lr: 3.7500e-04\n",
      "Epoch 59/200\n",
      "5626/5626 [==============================] - 197s 35ms/step - loss: 1.1672 - accuracy: 0.5580 - val_loss: 1.1317 - val_accuracy: 0.5680 - lr: 3.7500e-04\n",
      "Epoch 60/200\n",
      "5626/5626 [==============================] - 197s 35ms/step - loss: 1.1651 - accuracy: 0.5591 - val_loss: 1.1211 - val_accuracy: 0.5747 - lr: 3.7500e-04\n",
      "Epoch 61/200\n",
      "5626/5626 [==============================] - 197s 35ms/step - loss: 1.1619 - accuracy: 0.5599 - val_loss: 1.1255 - val_accuracy: 0.5739 - lr: 3.7500e-04\n",
      "Epoch 62/200\n",
      "5626/5626 [==============================] - 197s 35ms/step - loss: 1.1594 - accuracy: 0.5603 - val_loss: 1.1192 - val_accuracy: 0.5766 - lr: 3.7500e-04\n",
      "Epoch 63/200\n",
      "5626/5626 [==============================] - 198s 35ms/step - loss: 1.1569 - accuracy: 0.5613 - val_loss: 1.1307 - val_accuracy: 0.5703 - lr: 3.7500e-04\n",
      "Epoch 64/200\n",
      "5626/5626 [==============================] - 198s 35ms/step - loss: 1.1560 - accuracy: 0.5613 - val_loss: 1.1170 - val_accuracy: 0.5764 - lr: 3.7500e-04\n",
      "Epoch 65/200\n",
      "5626/5626 [==============================] - 197s 35ms/step - loss: 1.1544 - accuracy: 0.5621 - val_loss: 1.1156 - val_accuracy: 0.5773 - lr: 3.7500e-04\n",
      "Epoch 66/200\n",
      "5626/5626 [==============================] - 198s 35ms/step - loss: 1.1528 - accuracy: 0.5627 - val_loss: 1.1121 - val_accuracy: 0.5785 - lr: 3.7500e-04\n",
      "Epoch 67/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.1507 - accuracy: 0.5635 - val_loss: 1.1055 - val_accuracy: 0.5805 - lr: 3.7500e-04\n",
      "Epoch 68/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.1492 - accuracy: 0.5644 - val_loss: 1.1030 - val_accuracy: 0.5801 - lr: 3.7500e-04\n",
      "Epoch 69/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.1485 - accuracy: 0.5644 - val_loss: 1.1045 - val_accuracy: 0.5802 - lr: 3.7500e-04\n",
      "Epoch 70/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.1468 - accuracy: 0.5651 - val_loss: 1.1020 - val_accuracy: 0.5816 - lr: 3.7500e-04\n",
      "Epoch 71/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.1452 - accuracy: 0.5656 - val_loss: 1.0989 - val_accuracy: 0.5830 - lr: 3.7500e-04\n",
      "Epoch 72/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.1444 - accuracy: 0.5670 - val_loss: 1.0994 - val_accuracy: 0.5830 - lr: 3.7500e-04\n",
      "Epoch 73/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.1431 - accuracy: 0.5665 - val_loss: 1.1011 - val_accuracy: 0.5818 - lr: 3.7500e-04\n",
      "Epoch 74/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.1420 - accuracy: 0.5673 - val_loss: 1.0962 - val_accuracy: 0.5846 - lr: 3.7500e-04\n",
      "Epoch 75/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.1415 - accuracy: 0.5674 - val_loss: 1.0971 - val_accuracy: 0.5844 - lr: 3.7500e-04\n",
      "Epoch 76/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.1401 - accuracy: 0.5678 - val_loss: 1.0993 - val_accuracy: 0.5832 - lr: 3.7500e-04\n",
      "Epoch 77/200\n",
      "5625/5626 [============================>.] - ETA: 0s - loss: 1.1403 - accuracy: 0.5684\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 0.0001875000016298145.\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.1403 - accuracy: 0.5684 - val_loss: 1.0946 - val_accuracy: 0.5837 - lr: 3.7500e-04\n",
      "Epoch 78/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.1206 - accuracy: 0.5754 - val_loss: 1.0779 - val_accuracy: 0.5909 - lr: 1.8750e-04\n",
      "Epoch 79/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.1178 - accuracy: 0.5765 - val_loss: 1.0728 - val_accuracy: 0.5923 - lr: 1.8750e-04\n",
      "Epoch 80/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.1163 - accuracy: 0.5767 - val_loss: 1.0730 - val_accuracy: 0.5923 - lr: 1.8750e-04\n",
      "Epoch 81/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.1147 - accuracy: 0.5767 - val_loss: 1.0731 - val_accuracy: 0.5924 - lr: 1.8750e-04\n",
      "Epoch 82/200\n",
      "5626/5626 [==============================] - 195s 35ms/step - loss: 1.1144 - accuracy: 0.5774 - val_loss: 1.0711 - val_accuracy: 0.5933 - lr: 1.8750e-04\n",
      "Epoch 83/200\n",
      "5626/5626 [==============================] - 195s 35ms/step - loss: 1.1131 - accuracy: 0.5777 - val_loss: 1.0722 - val_accuracy: 0.5913 - lr: 1.8750e-04\n",
      "Epoch 84/200\n",
      "5626/5626 [==============================] - 195s 35ms/step - loss: 1.1128 - accuracy: 0.5782 - val_loss: 1.0692 - val_accuracy: 0.5937 - lr: 1.8750e-04\n",
      "Epoch 85/200\n",
      "5626/5626 [==============================] - 195s 35ms/step - loss: 1.1122 - accuracy: 0.5777 - val_loss: 1.0673 - val_accuracy: 0.5946 - lr: 1.8750e-04\n",
      "Epoch 86/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.1119 - accuracy: 0.5783 - val_loss: 1.0777 - val_accuracy: 0.5906 - lr: 1.8750e-04\n",
      "Epoch 87/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.1106 - accuracy: 0.5784 - val_loss: 1.0676 - val_accuracy: 0.5935 - lr: 1.8750e-04\n",
      "Epoch 88/200\n",
      "5625/5626 [============================>.] - ETA: 0s - loss: 1.1098 - accuracy: 0.5787\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 9.375000081490725e-05.\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.1098 - accuracy: 0.5787 - val_loss: 1.0726 - val_accuracy: 0.5918 - lr: 1.8750e-04\n",
      "Epoch 89/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.0990 - accuracy: 0.5828 - val_loss: 1.0573 - val_accuracy: 0.5973 - lr: 9.3750e-05\n",
      "Epoch 90/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.0963 - accuracy: 0.5839 - val_loss: 1.0528 - val_accuracy: 0.5994 - lr: 9.3750e-05\n",
      "Epoch 91/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.0972 - accuracy: 0.5831 - val_loss: 1.0564 - val_accuracy: 0.5984 - lr: 9.3750e-05\n",
      "Epoch 92/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.0953 - accuracy: 0.5838 - val_loss: 1.0533 - val_accuracy: 0.5997 - lr: 9.3750e-05\n",
      "Epoch 93/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.0941 - accuracy: 0.5842 - val_loss: 1.0535 - val_accuracy: 0.5994 - lr: 9.3750e-05\n",
      "Epoch 94/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.0951 - accuracy: 0.5837 - val_loss: 1.0524 - val_accuracy: 0.6008 - lr: 9.3750e-05\n",
      "Epoch 95/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.0944 - accuracy: 0.5844 - val_loss: 1.0529 - val_accuracy: 0.5995 - lr: 9.3750e-05\n",
      "Epoch 96/200\n",
      "5626/5626 [==============================] - 197s 35ms/step - loss: 1.0936 - accuracy: 0.5846 - val_loss: 1.0549 - val_accuracy: 0.5981 - lr: 9.3750e-05\n",
      "Epoch 97/200\n",
      "5625/5626 [============================>.] - ETA: 0s - loss: 1.0933 - accuracy: 0.5845\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 4.6875000407453626e-05.\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.0933 - accuracy: 0.5845 - val_loss: 1.0501 - val_accuracy: 0.6006 - lr: 9.3750e-05\n",
      "Epoch 98/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.0864 - accuracy: 0.5871 - val_loss: 1.0464 - val_accuracy: 0.6012 - lr: 4.6875e-05\n",
      "Epoch 99/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.0859 - accuracy: 0.5875 - val_loss: 1.0448 - val_accuracy: 0.6025 - lr: 4.6875e-05\n",
      "Epoch 100/200\n",
      "5626/5626 [==============================] - 197s 35ms/step - loss: 1.0848 - accuracy: 0.5879 - val_loss: 1.0451 - val_accuracy: 0.6018 - lr: 4.6875e-05\n",
      "Epoch 101/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.0852 - accuracy: 0.5876 - val_loss: 1.0440 - val_accuracy: 0.6031 - lr: 4.6875e-05\n",
      "Epoch 102/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.0839 - accuracy: 0.5890 - val_loss: 1.0447 - val_accuracy: 0.6022 - lr: 4.6875e-05\n",
      "Epoch 103/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.0844 - accuracy: 0.5879 - val_loss: 1.0438 - val_accuracy: 0.6031 - lr: 4.6875e-05\n",
      "Epoch 104/200\n",
      "5625/5626 [============================>.] - ETA: 0s - loss: 1.0841 - accuracy: 0.5881\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 2.3437500203726813e-05.\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.0841 - accuracy: 0.5881 - val_loss: 1.0436 - val_accuracy: 0.6029 - lr: 4.6875e-05\n",
      "Epoch 105/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.0803 - accuracy: 0.5895 - val_loss: 1.0409 - val_accuracy: 0.6036 - lr: 2.3438e-05\n",
      "Epoch 106/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.0796 - accuracy: 0.5900 - val_loss: 1.0399 - val_accuracy: 0.6044 - lr: 2.3438e-05\n",
      "Epoch 107/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.0796 - accuracy: 0.5898 - val_loss: 1.0407 - val_accuracy: 0.6038 - lr: 2.3438e-05\n",
      "Epoch 108/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.0787 - accuracy: 0.5908 - val_loss: 1.0396 - val_accuracy: 0.6045 - lr: 2.3438e-05\n",
      "Epoch 109/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.0794 - accuracy: 0.5897 - val_loss: 1.0401 - val_accuracy: 0.6043 - lr: 2.3438e-05\n",
      "Epoch 110/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.0785 - accuracy: 0.5904 - val_loss: 1.0394 - val_accuracy: 0.6053 - lr: 2.3438e-05\n",
      "Epoch 111/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.0776 - accuracy: 0.5906 - val_loss: 1.0383 - val_accuracy: 0.6048 - lr: 2.3438e-05\n",
      "Epoch 112/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.0785 - accuracy: 0.5903 - val_loss: 1.0392 - val_accuracy: 0.6046 - lr: 2.3438e-05\n",
      "Epoch 113/200\n",
      "5625/5626 [============================>.] - ETA: 0s - loss: 1.0774 - accuracy: 0.5912\n",
      "Epoch 113: ReduceLROnPlateau reducing learning rate to 1.1718750101863407e-05.\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.0774 - accuracy: 0.5912 - val_loss: 1.0387 - val_accuracy: 0.6045 - lr: 2.3438e-05\n",
      "Epoch 114/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.0760 - accuracy: 0.5915 - val_loss: 1.0372 - val_accuracy: 0.6055 - lr: 1.1719e-05\n",
      "Epoch 115/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.0757 - accuracy: 0.5914 - val_loss: 1.0366 - val_accuracy: 0.6061 - lr: 1.1719e-05\n",
      "Epoch 116/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.0759 - accuracy: 0.5916 - val_loss: 1.0378 - val_accuracy: 0.6054 - lr: 1.1719e-05\n",
      "Epoch 117/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.0754 - accuracy: 0.5914 - val_loss: 1.0367 - val_accuracy: 0.6055 - lr: 1.1719e-05\n",
      "Epoch 118/200\n",
      "5625/5626 [============================>.] - ETA: 0s - loss: 1.0755 - accuracy: 0.5916\n",
      "Epoch 118: ReduceLROnPlateau reducing learning rate to 5.859375050931703e-06.\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.0755 - accuracy: 0.5916 - val_loss: 1.0370 - val_accuracy: 0.6054 - lr: 1.1719e-05\n",
      "Epoch 119/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.0737 - accuracy: 0.5922 - val_loss: 1.0361 - val_accuracy: 0.6060 - lr: 5.8594e-06\n",
      "Epoch 120/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.0744 - accuracy: 0.5918 - val_loss: 1.0362 - val_accuracy: 0.6058 - lr: 5.8594e-06\n",
      "Epoch 121/200\n",
      "5625/5626 [============================>.] - ETA: 0s - loss: 1.0747 - accuracy: 0.5921\n",
      "Epoch 121: ReduceLROnPlateau reducing learning rate to 2.9296875254658516e-06.\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.0747 - accuracy: 0.5921 - val_loss: 1.0359 - val_accuracy: 0.6059 - lr: 5.8594e-06\n",
      "Epoch 122/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.0732 - accuracy: 0.5927 - val_loss: 1.0360 - val_accuracy: 0.6059 - lr: 2.9297e-06\n",
      "Epoch 123/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.0740 - accuracy: 0.5920 - val_loss: 1.0360 - val_accuracy: 0.6057 - lr: 2.9297e-06\n",
      "Epoch 124/200\n",
      "5625/5626 [============================>.] - ETA: 0s - loss: 1.0734 - accuracy: 0.5928\n",
      "Epoch 124: ReduceLROnPlateau reducing learning rate to 1.4648437627329258e-06.\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.0734 - accuracy: 0.5928 - val_loss: 1.0357 - val_accuracy: 0.6058 - lr: 2.9297e-06\n",
      "Epoch 125/200\n",
      "5626/5626 [==============================] - 196s 35ms/step - loss: 1.0731 - accuracy: 0.5926 - val_loss: 1.0356 - val_accuracy: 0.6056 - lr: 1.4648e-06\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "batch_size = 128 #64\n",
    "\n",
    "# Early stopping if val_accuracy doesnt improve for 7 epochs\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Reduce learning rate by factor of 0.5 if val_accuracy doesnt improve for 3 epochs\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "history = transformer_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 60.61%   (loss=1.0366)\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = transformer_model.evaluate(X_val, y_val, verbose=0)\n",
    "print(f\"Validation accuracy: {val_acc*100:.2f}%   (loss={val_loss:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Plot loss\n",
    "axs[0].plot(history.history['loss'], label='train_loss')\n",
    "axs[0].plot(history.history['val_loss'], label='val_loss')\n",
    "axs[0].set_title(\"Loss\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "# Plot accuracy\n",
    "axs[1].plot(history.history['accuracy'], label='train_acc')\n",
    "axs[1].plot(history.history['val_accuracy'], label='val_acc')\n",
    "axs[1].set_title(\"Accuracy\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Accuracy\")\n",
    "axs[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to ViT_Connect4_final.h5\n"
     ]
    }
   ],
   "source": [
    "transformer_model.save(\"ViT_Connect4_final.h5\")\n",
    "print(\"Saved to ViT_Connect4_final.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing CNN and Transformer vs MCTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalIndex(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Produces a position index [0..seq_len-1] for each element in the batch,\n",
    "    to embed positions.\n",
    "    \"\"\"\n",
    "    def call(self, x):\n",
    "        \"\"\"\n",
    "        x shape: (batch, seq_len, embed_dim)\n",
    "        returns: (batch, seq_len) of indices\n",
    "        \"\"\"\n",
    "        bs       = tf.shape(x)[0]\n",
    "        seq_len  = tf.shape(x)[1]\n",
    "        indices  = tf.range(seq_len)            # shape (seq_len,)\n",
    "        indices  = tf.expand_dims(indices, 0)   # shape (1, seq_len)\n",
    "        indices  = tf.tile(indices, [bs, 1])    # shape (bs, seq_len)\n",
    "        return indices  # int32 by default\n",
    "\n",
    "class ClassTokenIndex(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Produces a single index (0) for each batch to embed a class token.\n",
    "    \"\"\"\n",
    "    def call(self, x):\n",
    "        \"\"\"\n",
    "        x shape: (batch, seq_len, embed_dim)\n",
    "        returns: (batch, 1)\n",
    "        \"\"\"\n",
    "        bs = tf.shape(x)[0]\n",
    "        idx = tf.zeros((1,1), dtype=tf.int32)  # shape (1,1)\n",
    "        return tf.tile(idx, [bs, 1])           # shape (bs, 1)\n",
    "\n",
    "def build_transformer_connect4_overlapping(\n",
    "    input_shape=(6,7,2),\n",
    "    hidden_dim=256,\n",
    "    num_layers=8,\n",
    "    num_heads=8,\n",
    "    key_dim=None,\n",
    "    mlp_dim=None,\n",
    "    dropout_rate=0.15,\n",
    "    num_classes=7,\n",
    "    l2_reg=1e-4\n",
    "):\n",
    "    \"\"\"\n",
    "    A deeper Transformer for Connect4 with overlapping patches.\n",
    "    ...\n",
    "    [Same code you posted]\n",
    "    \"\"\"\n",
    "    if key_dim is None:\n",
    "        key_dim = hidden_dim // num_heads\n",
    "    if mlp_dim is None:\n",
    "        mlp_dim = hidden_dim * 4  # typical factor of 4\n",
    "\n",
    "    # 1) Overlapping patch embedding via Conv2D with stride=1 => shape => (4,5,hidden_dim)\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    patch_embed = layers.Conv2D(\n",
    "        filters=hidden_dim,\n",
    "        kernel_size=3,\n",
    "        strides=1,\n",
    "        padding='valid',\n",
    "        kernel_regularizer=regularizers.l2(l2_reg)\n",
    "    )(inputs)  # => (None,4,5,hidden_dim)\n",
    "    seq = layers.Reshape((-1, hidden_dim))(patch_embed)  # => (None,20,hidden_dim)\n",
    "\n",
    "    # 2) Positional embedding\n",
    "    pos_indices = PositionalIndex()(seq)  # => (batch,20)\n",
    "    pos_embed = layers.Embedding(\n",
    "        input_dim=20,\n",
    "        output_dim=hidden_dim,\n",
    "        embeddings_regularizer=regularizers.l2(l2_reg)\n",
    "    )(pos_indices)  # => (batch,20,hidden_dim)\n",
    "    x = layers.Add()([seq, pos_embed])    # => (batch,20,hidden_dim)\n",
    "\n",
    "    # 3) Class token\n",
    "    cls_idx = ClassTokenIndex()(x)  # => (batch,1)\n",
    "    cls_token = layers.Embedding(\n",
    "        input_dim=1,\n",
    "        output_dim=hidden_dim,\n",
    "        embeddings_regularizer=regularizers.l2(l2_reg)\n",
    "    )(cls_idx)   # => (batch,1,hidden_dim)\n",
    "    x = layers.Concatenate(axis=1)([cls_token, x])  # => (batch,21,hidden_dim)\n",
    "\n",
    "    # 4) Stacked Transformer blocks\n",
    "    for _ in range(num_layers):\n",
    "        # LN + MHA\n",
    "        ln1 = layers.LayerNormalization()(x)\n",
    "        attn_out = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=key_dim,\n",
    "            dropout=dropout_rate,\n",
    "            kernel_regularizer=regularizers.l2(l2_reg),\n",
    "            bias_regularizer=regularizers.l2(l2_reg)\n",
    "        )(ln1, ln1, ln1)\n",
    "        x = layers.Add()([x, attn_out])\n",
    "\n",
    "        # LN + Feed-forward\n",
    "        ln2 = layers.LayerNormalization()(x)\n",
    "        ff = layers.Dense(\n",
    "            mlp_dim, activation='gelu',\n",
    "            kernel_regularizer=regularizers.l2(l2_reg)\n",
    "        )(ln2)\n",
    "        ff = layers.Dropout(dropout_rate)(ff)\n",
    "        ff = layers.Dense(\n",
    "            hidden_dim,\n",
    "            kernel_regularizer=regularizers.l2(l2_reg)\n",
    "        )(ff)\n",
    "        ff = layers.Dropout(dropout_rate)(ff)\n",
    "        x = layers.Add()([x, ff])\n",
    "\n",
    "    # 5) Final classification (class token => x[:,0,:])\n",
    "    cls_vec = x[:,0,:]  # => (batch, hidden_dim)\n",
    "    ln = layers.LayerNormalization()(cls_vec)\n",
    "    logits = layers.Dense(\n",
    "        num_classes, activation='softmax',\n",
    "        kernel_regularizer=regularizers.l2(l2_reg)\n",
    "    )(ln)\n",
    "\n",
    "    model = models.Model(inputs, logits, name=\"ViT_Connect4_Overlapping\")\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.007),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = tf.keras.models.load_model(\"cnn_connect4.h5\")  # Adjust filename as needed\n",
    "\n",
    "# Load the transformer model with custom objects\n",
    "custom_objects = {\n",
    "\t'PositionalIndex': PositionalIndex,\n",
    "\t'ClassTokenIndex': ClassTokenIndex\n",
    "}\n",
    "transformer_model = tf.keras.models.load_model(\"ViT_Connect4_final.h5\", custom_objects=custom_objects)  # Adjust filename as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_pick_move(board_2d, model, color='plus'):\n",
    "    \"\"\"\n",
    "    Given a 6x7 board (board_2d) and a trained CNN model,\n",
    "    pick the column with the highest predicted probability that is legal.\n",
    "    \"\"\"\n",
    "    # Convert board to 6x7x2 representation\n",
    "    from_board = board_to_6x7x2(board_2d)\n",
    "    \n",
    "    if color == 'minus':\n",
    "        # Flip to plus perspective\n",
    "        from_board = minus_to_plus(from_board)\n",
    "\n",
    "    # Model expects shape (N, 6, 7, 2). So expand dims.\n",
    "    input_for_model = np.expand_dims(from_board, axis=0)  # (1,6,7,2)\n",
    "    \n",
    "    # Predict probabilities for each column\n",
    "    pred_probs = model.predict(input_for_model, verbose=0)[0]  # (7,)\n",
    "    \n",
    "    # Sort columns by descending probability\n",
    "    columns_ranked = np.argsort(pred_probs)[::-1]  # highest -> lowest\n",
    "    \n",
    "    # Find a legal column among the top predictions\n",
    "    legal_cols = find_legal(board_2d)\n",
    "    for col in columns_ranked:\n",
    "        if col in legal_cols:\n",
    "            return col\n",
    "    \n",
    "    # Fallback: pick a random legal column\n",
    "    if len(legal_cols) > 0:\n",
    "        return random.choice(legal_cols)\n",
    "    else:\n",
    "        return 0  # If no columns are legal, default to column 0\n",
    "\n",
    "def transformer_pick_move(board_2d, model, color='plus'):\n",
    "    \"\"\"\n",
    "    Given a 6x7 board (board_2d) and a trained Transformer model,\n",
    "    pick the column with the highest predicted probability that is legal.\n",
    "    \"\"\"\n",
    "    # Convert board to 6x7x2 representation\n",
    "    from_board = board_to_6x7x2(board_2d)\n",
    "    \n",
    "    if color == 'minus':\n",
    "        # Flip to plus perspective\n",
    "        from_board = minus_to_plus(from_board)\n",
    "\n",
    "    # Model expects shape (N, 6, 7, 2). So expand dims.\n",
    "    input_for_model = np.expand_dims(from_board, axis=0)  # (1,6,7,2)\n",
    "    \n",
    "    # Predict probabilities for each column\n",
    "    pred_probs = model.predict(input_for_model, verbose=0)[0]  # (7,)\n",
    "    \n",
    "    # Sort columns by descending probability\n",
    "    columns_ranked = np.argsort(pred_probs)[::-1]  # highest -> lowest\n",
    "    \n",
    "    # Find a legal column among the top predictions\n",
    "    legal_cols = find_legal(board_2d)\n",
    "    for col in columns_ranked:\n",
    "        if col in legal_cols:\n",
    "            return col\n",
    "    \n",
    "    # Fallback: pick a random legal column\n",
    "    if len(legal_cols) > 0:\n",
    "        return random.choice(legal_cols)\n",
    "    else:\n",
    "        return 0  # If no columns are legal, default to column 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_one_game(model_pick_move, model_type='CNN', mcts_steps_minus=300, verbose=False):\n",
    "    \"\"\"\n",
    "    Let either the CNN or Transformer play as 'plus' against MCTS as 'minus'.\n",
    "    \n",
    "    Parameters:\n",
    "    - model_pick_move: function to pick moves using the model (cnn_pick_move or transformer_pick_move)\n",
    "    - model_type: 'CNN' or 'Transformer' (for reporting purposes)\n",
    "    - mcts_steps_minus: number of MCTS steps for the 'minus' player\n",
    "    - verbose: if True, print each move\n",
    "    \n",
    "    Returns:\n",
    "    - winner: 'plus', 'minus', or 'tie'\n",
    "    - move_count: number of moves made in the game\n",
    "    \"\"\"\n",
    "    board = np.zeros((6,7), dtype=np.float32)\n",
    "    winner = 'nobody'\n",
    "    player = 'plus'\n",
    "    move_count = 0\n",
    "\n",
    "    while winner == 'nobody':\n",
    "        legal = find_legal(board)\n",
    "        if len(legal) == 0:\n",
    "            # Tie\n",
    "            break\n",
    "\n",
    "        if player == 'plus':\n",
    "            col = model_pick_move(board, model=cnn_model if model_type == 'CNN' else transformer_model, color='plus')\n",
    "        else:\n",
    "            col = mcts(board, 'minus', mcts_steps_minus)\n",
    "\n",
    "        board = update_board(board, player, col)\n",
    "        winner = check_for_win(board, col)\n",
    "        move_count += 1\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Move {move_count}, {player}, col={col}\")\n",
    "\n",
    "        # Switch player\n",
    "        player = 'minus' if player == 'plus' else 'plus'\n",
    "\n",
    "    # Determine outcome\n",
    "    if winner == 'nobody' or winner == 'tie':\n",
    "        return 'tie', move_count\n",
    "    elif winner.endswith('plus'):\n",
    "        return 'plus', move_count\n",
    "    elif winner.endswith('minus'):\n",
    "        return 'minus', move_count\n",
    "    else:\n",
    "        return 'tie', move_count  # Default to tie if unclear\n",
    "\n",
    "def test_model_vs_MCTS(model_pick_move, model_type='CNN', num_games=100, mcts_steps_minus=300, verbose=False):\n",
    "    \"\"\"\n",
    "    Play multiple games between the specified model and MCTS.\n",
    "    \n",
    "    Parameters:\n",
    "    - model_pick_move: function to pick moves using the model\n",
    "    - model_type: 'CNN' or 'Transformer'\n",
    "    - num_games: number of games to play\n",
    "    - mcts_steps_minus: number of MCTS steps for the 'minus' player\n",
    "    - verbose: if True, print game outcomes\n",
    "    \n",
    "    Returns:\n",
    "    - results: dict with counts of 'plus_wins', 'minus_wins', 'ties', 'avg_moves'\n",
    "    \"\"\"\n",
    "    plus_wins = 0\n",
    "    minus_wins = 0\n",
    "    ties = 0\n",
    "    total_moves = 0\n",
    "\n",
    "    for g in range(1, num_games + 1):\n",
    "        winner, moves = play_one_game(model_pick_move, model_type, mcts_steps_minus, verbose)\n",
    "        total_moves += moves\n",
    "\n",
    "        if winner == 'plus':\n",
    "            plus_wins += 1\n",
    "        elif winner == 'minus':\n",
    "            minus_wins += 1\n",
    "        else:\n",
    "            ties += 1\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Game {g}: Winner = {winner}, Moves = {moves}\")\n",
    "\n",
    "    avg_moves = total_moves / num_games if num_games > 0 else 0\n",
    "\n",
    "    results = {\n",
    "        'plus_wins': plus_wins,\n",
    "        'minus_wins': minus_wins,\n",
    "        'ties': ties,\n",
    "        'avg_moves': avg_moves\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating CNN vs MCTS...\n",
      "Out of 50 games vs. MCTS(1000 steps):\n",
      "  CNN (plus) wins:  36\n",
      "  MCTS (minus) wins: 14\n",
      "  Ties: 0\n",
      "  Average number of moves per game: 30.2\n",
      "\n",
      "Evaluating Transformer vs MCTS...\n",
      "Out of 50 games vs. MCTS(1000 steps):\n",
      "  Transformer (plus) wins:  13\n",
      "  MCTS (minus) wins:        35\n",
      "  Ties:                     2\n",
      "  Average number of moves per game: 33.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Define evaluation parameters\n",
    "    num_games = 50\n",
    "    mcts_steps = 1000  # Number of MCTS steps for the 'minus' player\n",
    "\n",
    "    # Evaluate CNN vs MCTS\n",
    "    print(\"Evaluating CNN vs MCTS...\")\n",
    "    results_cnn = test_model_vs_MCTS(\n",
    "        model_pick_move=cnn_pick_move,      # function to pick CNN moves\n",
    "        model_type='CNN',                  # label for logging\n",
    "        num_games=num_games,\n",
    "        mcts_steps_minus=mcts_steps,\n",
    "        verbose=False\n",
    "    )\n",
    "    print(f\"Out of {num_games} games vs. MCTS({mcts_steps} steps):\")\n",
    "    print(f\"  CNN (plus) wins:  {results_cnn['plus_wins']}\")\n",
    "    print(f\"  MCTS (minus) wins: {results_cnn['minus_wins']}\")\n",
    "    print(f\"  Ties: {results_cnn['ties']}\")\n",
    "    print(f\"  Average number of moves per game: {results_cnn['avg_moves']:.1f}\\n\")\n",
    "\n",
    "    # Evaluate Transformer vs MCTS\n",
    "    print(\"Evaluating Transformer vs MCTS...\")\n",
    "    results_transformer = test_model_vs_MCTS(\n",
    "        model_pick_move=transformer_pick_move,  # function to pick Transformer moves\n",
    "        model_type='Transformer',               # label for logging\n",
    "        num_games=num_games,\n",
    "        mcts_steps_minus=mcts_steps,\n",
    "        verbose=False\n",
    "    )\n",
    "    print(f\"Out of {num_games} games vs. MCTS({mcts_steps} steps):\")\n",
    "    print(f\"  Transformer (plus) wins:  {results_transformer['plus_wins']}\")\n",
    "    print(f\"  MCTS (minus) wins:        {results_transformer['minus_wins']}\")\n",
    "    print(f\"  Ties:                     {results_transformer['ties']}\")\n",
    "    print(f\"  Average number of moves per game: {results_transformer['avg_moves']:.1f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
