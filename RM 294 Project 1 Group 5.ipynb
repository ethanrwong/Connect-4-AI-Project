{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #type: ignore\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from IPython.display import clear_output #type: ignore\n",
    "import tensorflow as tf #type: ignore\n",
    "from tensorflow.keras import layers, models, regularizers #type: ignore\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split #type: ignore\n",
    "import matplotlib.pyplot as plt #type: ignore\n",
    "from joblib import Parallel, delayed  # for parallelism\n",
    "import multiprocessing\n",
    "\n",
    "SEED = 22\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect Four and MCTS Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_board(board_temp,color,column):\n",
    "    board = board_temp.copy()\n",
    "    colsum = abs(board[0,column])+abs(board[1,column])+abs(board[2,column])+abs(board[3,column])+abs(board[4,column])+abs(board[5,column])\n",
    "    row = int(5-colsum)\n",
    "    if row > -0.5:\n",
    "        if color == 'plus':\n",
    "            board[row,column] = 1\n",
    "        else:\n",
    "            board[row,column] = -1\n",
    "    return board\n",
    "    \n",
    "def check_for_win_slow(board):\n",
    "    nrow = board.shape[0]\n",
    "    ncol = board.shape[1]\n",
    "    winner = 'nobody'\n",
    "    for col in range(ncol):\n",
    "        for row in reversed(range(nrow)):\n",
    "            if abs(board[row,col]) < 0.1:\n",
    "                break\n",
    "            # vertical\n",
    "            if row <= (nrow-4):\n",
    "                tempsum = board[row,col]+board[row+1,col]+board[row+2,col]+board[row+3,col]\n",
    "                if tempsum==4:\n",
    "                    winner = 'v-plus'\n",
    "                    return winner\n",
    "                elif tempsum==-4:\n",
    "                    winner = 'v-minus'\n",
    "                    return winner\n",
    "            # horizontal\n",
    "            if col <= (ncol-4):\n",
    "                tempsum = board[row,col]+board[row,col+1]+board[row,col+2]+board[row,col+3]\n",
    "                if tempsum==4:\n",
    "                    winner = 'h-plus'\n",
    "                    return winner\n",
    "                elif tempsum==-4:\n",
    "                    winner = 'h-minus'\n",
    "                    return winner\n",
    "            # diagonal down-right\n",
    "            if (row <= (nrow-4)) and (col <= (ncol-4)):\n",
    "                tempsum = board[row,col]+board[row+1,col+1]+board[row+2,col+2]+board[row+3,col+3]\n",
    "                if tempsum==4:\n",
    "                    winner = 'd-plus'\n",
    "                    return winner\n",
    "                elif tempsum==-4:\n",
    "                    winner = 'd-minus'\n",
    "                    return winner\n",
    "            # diagonal down-left\n",
    "            if (row <= (nrow-4)) and (col >= 3):\n",
    "                tempsum = board[row,col]+board[row+1,col-1]+board[row+2,col-2]+board[row+3,col-3]\n",
    "                if tempsum==4:\n",
    "                    winner = 'd-plus'\n",
    "                    return winner\n",
    "                elif tempsum==-4:\n",
    "                    winner = 'd-minus'\n",
    "                    return winner\n",
    "    return winner\n",
    "\n",
    "def check_for_win(board,col):\n",
    "    nrow = 6\n",
    "    # figure out what row was just placed\n",
    "    colsum = abs(board[0,col])+abs(board[1,col])+abs(board[2,col])+abs(board[3,col])+abs(board[4,col])+abs(board[5,col])\n",
    "    row = int(6-colsum)\n",
    "    # vertical check\n",
    "    if row+3<6:\n",
    "        vert = board[row,col] + board[row+1,col] + board[row+2,col] + board[row+3,col]\n",
    "        if vert == 4:\n",
    "            return 'v-plus'\n",
    "        elif vert == -4:\n",
    "            return 'v-minus'\n",
    "    # horizontal checks (there are several)\n",
    "    # segment 0-3\n",
    "    if col+3<7:\n",
    "        hor = board[row,col] + board[row,col+1] + board[row,col+2] + board[row,col+3]\n",
    "        if hor == 4:\n",
    "            return 'h-plus'\n",
    "        elif hor == -4:\n",
    "            return 'h-minus'\n",
    "    # segment -1..+2\n",
    "    if col-1>=0 and col+2<7:\n",
    "        hor = board[row,col-1] + board[row,col] + board[row,col+1] + board[row,col+2]\n",
    "        if hor == 4:\n",
    "            return 'h-plus'\n",
    "        elif hor == -4:\n",
    "            return 'h-minus'\n",
    "    # segment -2..+1\n",
    "    if col-2>=0 and col+1<7:\n",
    "        hor = board[row,col-2] + board[row,col-1] + board[row,col] + board[row,col+1]\n",
    "        if hor == 4:\n",
    "            return 'h-plus'\n",
    "        elif hor == -4:\n",
    "            return 'h-minus'\n",
    "    # segment -3..0\n",
    "    if col-3>=0:\n",
    "        hor = board[row,col-3] + board[row,col-2] + board[row,col-1] + board[row,col]\n",
    "        if hor == 4:\n",
    "            return 'h-plus'\n",
    "        elif hor == -4:\n",
    "            return 'h-minus'\n",
    "    # diagonals down-right\n",
    "    if row < 3 and col < 4:\n",
    "        DR = board[row,col] + board[row+1,col+1] + board[row+2,col+2] + board[row+3,col+3]\n",
    "        if DR == 4:\n",
    "            return 'd-plus'\n",
    "        elif DR == -4:\n",
    "            return 'd-minus'\n",
    "    if row-1>=0 and col-1>=0 and row+2<6 and col+2<7:\n",
    "        DR = board[row-1,col-1] + board[row,col] + board[row+1,col+1] + board[row+2,col+2]\n",
    "        if DR == 4:\n",
    "            return 'd-plus'\n",
    "        elif DR == -4:\n",
    "            return 'd-minus'\n",
    "    if row-2>=0 and col-2>=0 and row+1<6 and col+1<7:\n",
    "        DR = board[row-2,col-2] + board[row-1,col-1] + board[row,col] + board[row+1,col+1]\n",
    "        if DR == 4:\n",
    "            return 'd-plus'\n",
    "        elif DR == -4:\n",
    "            return 'd-minus'\n",
    "    if row-3>=0 and col-3>=0:\n",
    "        DR = board[row-3,col-3] + board[row-2,col-2] + board[row-1,col-1] + board[row,col]\n",
    "        if DR == 4:\n",
    "            return 'd-plus'\n",
    "        elif DR == -4:\n",
    "            return 'd-minus'\n",
    "    # diagonals down-left\n",
    "    if row+3<6 and col-3>=0:\n",
    "        DL = board[row,col] + board[row+1,col-1] + board[row+2,col-2] + board[row+3,col-3]\n",
    "        if DL == 4:\n",
    "            return 'd-plus'\n",
    "        elif DL == -4:\n",
    "            return 'd-minus'\n",
    "    if row-1>=0 and col+1<7 and row+2<6 and col-2>=0:\n",
    "        DL = board[row-1,col+1] + board[row,col] + board[row+1,col-1] + board[row+2,col-2]\n",
    "        if DL == 4:\n",
    "            return 'd-plus'\n",
    "        elif DL == -4:\n",
    "            return 'd-minus'\n",
    "    if row-2>=0 and col+2<7 and row+1<6 and col-1>=0:\n",
    "        DL = board[row-2,col+2] + board[row-1,col+1] + board[row,col] + board[row+1,col-1]\n",
    "        if DL == 4:\n",
    "            return 'd-plus'\n",
    "        elif DL == -4:\n",
    "            return 'd-minus'\n",
    "    if row-3>=0 and col+3<7:\n",
    "        DL = board[row-3,col+3] + board[row-2,col+2] + board[row-1,col+1] + board[row,col]\n",
    "        if DL == 4:\n",
    "            return 'd-plus'\n",
    "        elif DL == -4:\n",
    "            return 'd-minus'\n",
    "    return 'nobody'\n",
    "\n",
    "def find_legal(board):\n",
    "    return [i for i in range(7) if abs(board[0,i]) < 0.1]\n",
    "\n",
    "def look_for_win(board_,color):\n",
    "    board_ = board_.copy()\n",
    "    legal = find_legal(board_)\n",
    "    winner_col = -1\n",
    "    for m in legal:\n",
    "        bt = update_board(board_.copy(),color,m)\n",
    "        wi = check_for_win(bt,m)\n",
    "        if wi[2:] == color:\n",
    "            winner_col = m\n",
    "            break\n",
    "    return winner_col\n",
    "\n",
    "def find_all_nonlosers(board,color):\n",
    "    if color == 'plus':\n",
    "        opp = 'minus'\n",
    "    else:\n",
    "        opp = 'plus'\n",
    "    legal = find_legal(board)\n",
    "    poss_boards = [update_board(board,color,l) for l in legal]\n",
    "    poss_legal = [find_legal(b) for b in poss_boards]\n",
    "    allowed = []\n",
    "    for i in range(len(legal)):\n",
    "        # if the opponent can immediately win after we move in col=legal[i], skip it\n",
    "        wins = [j for j in poss_legal[i] \n",
    "                if check_for_win(update_board(poss_boards[i],opp,j),j) != 'nobody']\n",
    "        if len(wins) == 0:\n",
    "            allowed.append(legal[i])\n",
    "    return allowed\n",
    "\n",
    "def back_prop(winner,path,color0,md):\n",
    "    for i, board_tuple in enumerate(path):\n",
    "        md[board_tuple][0] += 1\n",
    "        if winner[2] == color0[0]:\n",
    "            if i % 2 == 1:\n",
    "                md[board_tuple][1] += 1\n",
    "            else:\n",
    "                md[board_tuple][1] -= 1\n",
    "        elif winner[2] == 'e':\n",
    "            # tie => no change\n",
    "            pass\n",
    "        else:\n",
    "            if i % 2 == 1:\n",
    "                md[board_tuple][1] -= 1\n",
    "            else:\n",
    "                md[board_tuple][1] += 1\n",
    "\n",
    "def rollout(board,next_player):\n",
    "    winner = 'nobody'\n",
    "    player = next_player\n",
    "    while winner == 'nobody':\n",
    "        legal = find_legal(board)\n",
    "        if len(legal) == 0:\n",
    "            return 'tie'\n",
    "        move = random.choice(legal)\n",
    "        board = update_board(board,player,move)\n",
    "        winner = check_for_win(board,move)\n",
    "        # switch player\n",
    "        if player == 'plus':\n",
    "            player = 'minus'\n",
    "        else:\n",
    "            player = 'plus'\n",
    "    return winner\n",
    "        \n",
    "def mcts(board_temp,color0,nsteps):\n",
    "    # Traditional MCTS, plus small improvements:\n",
    "    board = board_temp.copy()\n",
    "    # 1. If there's an immediate winning move, use it\n",
    "    win_col = look_for_win(board,color0)\n",
    "    if win_col != -1:\n",
    "        return win_col\n",
    "    # 2. Look for any moves that avoid an immediate losing position\n",
    "    legal0 = find_all_nonlosers(board,color0)\n",
    "    if len(legal0) == 0:\n",
    "        # if no way to avoid opponent's immediate threat, use all legal moves\n",
    "        legal0 = find_legal(board)\n",
    "    \n",
    "    mcts_dict = {tuple(board.ravel()):[0,0]}\n",
    "    for _ in range(nsteps):\n",
    "        color = color0\n",
    "        winner = 'nobody'\n",
    "        board_mcts = board.copy()\n",
    "        path = [tuple(board_mcts.ravel())]\n",
    "        \n",
    "        while winner == 'nobody':\n",
    "            legal = find_legal(board_mcts)\n",
    "            if len(legal) == 0:\n",
    "                winner = 'tie'\n",
    "                back_prop(winner,path,color0,mcts_dict)\n",
    "                break\n",
    "            # list of next possible boards\n",
    "            board_list = []\n",
    "            for col in legal:\n",
    "                b_next = update_board(board_mcts,color,col)\n",
    "                board_list.append(tuple(b_next.ravel()))\n",
    "                if tuple(b_next.ravel()) not in mcts_dict:\n",
    "                    mcts_dict[tuple(b_next.ravel())] = [0,0]\n",
    "            \n",
    "            # UCB1 \n",
    "            ucb1 = np.zeros(len(legal))\n",
    "            for i, bl in enumerate(board_list):\n",
    "                num_sims, total_value = mcts_dict[bl]\n",
    "                if num_sims == 0:\n",
    "                    # large priority for unvisited\n",
    "                    ucb1[i] = 10 * nsteps\n",
    "                else:\n",
    "                    parent_sims = mcts_dict[path[-1]][0]\n",
    "                    avg_val = total_value / num_sims\n",
    "                    explore = np.sqrt(np.log(parent_sims)/num_sims)\n",
    "                    ucb1[i] = avg_val + 2*explore\n",
    "            \n",
    "            chosen = np.argmax(ucb1)\n",
    "            board_mcts = update_board(board_mcts,color,legal[chosen])\n",
    "            path.append(tuple(board_mcts.ravel()))\n",
    "            # check winner\n",
    "            winner = check_for_win(board_mcts,legal[chosen])\n",
    "            if winner[2] == color[0]:\n",
    "                back_prop(winner,path,color0,mcts_dict)\n",
    "                break\n",
    "            \n",
    "            # switch player\n",
    "            color = 'minus' if (color=='plus') else 'plus'\n",
    "            \n",
    "            # if the new board has never been visited, do a rollout\n",
    "            if mcts_dict[tuple(board_mcts.ravel())][0] == 0:\n",
    "                winner_roll = rollout(board_mcts,color)\n",
    "                back_prop(winner_roll,path,color0,mcts_dict)\n",
    "                break\n",
    "    \n",
    "    # pick the move with best average reward\n",
    "    best_col = -1\n",
    "    max_score = -np.inf\n",
    "    for col in legal0:\n",
    "        new_board = tuple(update_board(board,color0,col).ravel())\n",
    "        num_sims, total_val = mcts_dict[new_board]\n",
    "        if num_sims == 0:\n",
    "            # means we never visited it\n",
    "            score = -np.inf\n",
    "        else:\n",
    "            score = total_val/num_sims\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            best_col = col\n",
    "\n",
    "    return best_col\n",
    "\n",
    "\n",
    "def board_to_6x7x2(board_2d):\n",
    "    \"\"\"\n",
    "    Convert a 6x7 board with +1, -1, 0 \n",
    "    into a 6x7x2 one-hot style representation:\n",
    "       channel 0 => +1 positions\n",
    "       channel 1 => -1 positions\n",
    "    \"\"\"\n",
    "    X = np.zeros((6,7,2), dtype=np.float32)\n",
    "    for i in range(6):\n",
    "        for j in range(7):\n",
    "            if board_2d[i,j] == 1:\n",
    "                X[i,j,0] = 1\n",
    "            elif board_2d[i,j] == -1:\n",
    "                X[i,j,1] = 1\n",
    "    return X\n",
    "\n",
    "def minus_to_plus(board_6x7x2):\n",
    "    \"\"\"\n",
    "    Flip a (6,7,2) board from 'minus perspective' to 'plus perspective'\n",
    "    by swapping channels 0 and 1.\n",
    "      channel 0 => +1 squares\n",
    "      channel 1 => -1 squares\n",
    "    If originally channel 1 was the 'minus' squares, \n",
    "    after swap, that becomes the 'plus' squares, etc.\n",
    "    \"\"\"\n",
    "    flipped = board_6x7x2.copy()\n",
    "    flipped[..., 0], flipped[..., 1] = board_6x7x2[..., 1], board_6x7x2[..., 0]\n",
    "    return flipped\n",
    "\n",
    "def add_symmetric_flips(board_6x7x2, best_move):\n",
    "    \"\"\"\n",
    "    Given a (6,7,2) board and an integer best_move in [0..6],\n",
    "    return a list of:\n",
    "      [(original_board_6x7x2, best_move),\n",
    "       (flipped_board_6x7x2, flipped_move)].\n",
    "    The flipped version is mirrored left-to-right (column j -> 6-j).\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    \n",
    "    # 1) Original\n",
    "    out.append((board_6x7x2, best_move))\n",
    "    \n",
    "    # 2) Flipped left-right\n",
    "    flipped_board = board_6x7x2[:, ::-1, :].copy()\n",
    "    flipped_col = 6 - best_move\n",
    "    out.append((flipped_board, flipped_col))\n",
    "    \n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_one_game(\n",
    "    plus_mcts_steps=800, \n",
    "    minus_mcts_steps=800,\n",
    "    random_openings=2\n",
    "):\n",
    "    \"\"\"\n",
    "    Play one full game between plus & minus, each side using MCTS.\n",
    "    - random_openings => number of random moves each side does at the start.\n",
    "    - We'll capture BOTH plus and minus moves. \n",
    "      For minus, we flip the board to plus perspective before storing.\n",
    "    - We do NOT store random moves. \n",
    "    - Return a list of (board_6x7x2, best_move_col) for all MCTS-chosen moves \n",
    "      from the plus perspective.\n",
    "    \"\"\"\n",
    "    data_this_game = []\n",
    "    board = np.zeros((6,7), dtype=np.float32)\n",
    "    winner = 'nobody'\n",
    "    player = 'plus'\n",
    "    move_count = 0\n",
    "    \n",
    "    while winner == 'nobody':\n",
    "        legal = find_legal(board)\n",
    "        if len(legal) == 0:\n",
    "            break  # tie\n",
    "\n",
    "        # Possibly do a random move in the opening\n",
    "        use_random = False\n",
    "        if move_count < 2*random_openings:\n",
    "            # e.g. first X moves in the entire game: random for plus & minus\n",
    "            use_random = True\n",
    "\n",
    "        if use_random:\n",
    "            col = random.choice(legal)\n",
    "        else:\n",
    "            # MCTS to pick best move\n",
    "            if player == 'plus':\n",
    "                col = mcts(board, 'plus', plus_mcts_steps)\n",
    "            else:\n",
    "                col = mcts(board, 'minus', minus_mcts_steps)\n",
    "\n",
    "        old_board = board.copy()  # board before the current move\n",
    "        board = update_board(board, player, col)\n",
    "        winner = check_for_win(board, col)\n",
    "\n",
    "        # Store the data if this move is MCTS-based (not random)\n",
    "        if not use_random:\n",
    "            if player == 'plus':\n",
    "                # plus perspective => straightforward\n",
    "                board_6x7x2 = board_to_6x7x2(old_board)\n",
    "                data_this_game.append((board_6x7x2, col))\n",
    "            else:\n",
    "                # minus perspective => flip channels to get plus perspective\n",
    "                board_6x7x2_minus = board_to_6x7x2(old_board)\n",
    "                board_6x7x2_plus = minus_to_plus(board_6x7x2_minus)\n",
    "                # The chosen column from minus's vantage is the same col index on the grid\n",
    "                data_this_game.append((board_6x7x2_plus, col))\n",
    "\n",
    "        # Switch player\n",
    "        player = 'minus' if (player == 'plus') else 'plus'\n",
    "        move_count += 1\n",
    "    \n",
    "    return data_this_game\n",
    "\n",
    "def play_one_game_random_params():\n",
    "    \"\"\"\n",
    "    Roll random settings:\n",
    "      plus_mcts_steps   in [500..5000]\n",
    "      minus_mcts_steps  in [500..5000]\n",
    "      random_openings   in [1..15]\n",
    "\n",
    "    Then call play_one_game(...) once.\n",
    "    Return the list of (board_6x7x2, best_move).\n",
    "    \"\"\"\n",
    "    plus_mcts = random.randint(500, 5000)\n",
    "    minus_mcts = random.randint(500, 5000)\n",
    "    openings   = random.randint(1, 15)\n",
    "    game_data = play_one_game(\n",
    "        plus_mcts_steps=plus_mcts,\n",
    "        minus_mcts_steps=minus_mcts,\n",
    "        random_openings=openings\n",
    "    )\n",
    "    return game_data  # list of (board_6x7x2, best_move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_build_dataset(num_games=25000):\n",
    "    \"\"\"\n",
    "    Use joblib to run 'play_one_game_random_params()' in parallel.\n",
    "\n",
    "    We store results in a collision dictionary (board -> {move->count}).\n",
    "    Then we do final collision resolution + stacking into X,y.\n",
    "\n",
    "    Returns X, y as np arrays:\n",
    "      X.shape = (N, 6, 7, 2)\n",
    "      y.shape = (N,)\n",
    "    \"\"\"\n",
    "    print(f\"Building dataset with {num_games} games in parallel...\")\n",
    "\n",
    "    # Step 1: run each game in parallel\n",
    "    results = Parallel(n_jobs=-1, backend='loky')(\n",
    "        delayed(play_one_game_random_params)()\n",
    "        for _ in range(num_games)\n",
    "    )\n",
    "\n",
    "    # 'results' is a list of lists. Each sub-list is the (board_6x7x2, best_move) pairs for one game.\n",
    "    # We'll store them with symmetrical flips & collisions.\n",
    "    data_dict = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    print(\"Aggregating results & handling collisions...\")\n",
    "\n",
    "    # Step 2: For each game’s data, do symmetry flips & increment collision dictionary\n",
    "    for game_data in results:\n",
    "        for (board_6x7x2, best_move) in game_data:\n",
    "            # augment\n",
    "            augmented = add_symmetric_flips(board_6x7x2, best_move)\n",
    "            for (b_aug, m_aug) in augmented:\n",
    "                key = b_aug.tobytes()\n",
    "                data_dict[key][m_aug] += 1\n",
    "\n",
    "    # Step 3: collision resolution\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    for key, move_counts in data_dict.items():\n",
    "        best_move = max(move_counts, key=move_counts.get)\n",
    "        arr = np.frombuffer(key, dtype=np.float32).reshape(6,7,2)\n",
    "        X_list.append(arr)\n",
    "        y_list.append(best_move)\n",
    "\n",
    "    X = np.stack(X_list, axis=0)\n",
    "    y = np.array(y_list, dtype=np.int32)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataset with 25000 games in parallel...\n",
      "Aggregating results & handling collisions...\n",
      "Finished building dataset!\n",
      "X shape: (465707, 6, 7, 2)\n",
      "y shape: (465707,)\n",
      "Unique moves in y: [0 1 2 3 4 5 6]\n",
      "Dataset saved to X_dataset_new.ethan2.npy and y_dataset_ethan2.npy.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    NUM_GAMES = 25000  \n",
    "    X, y = parallel_build_dataset(num_games=NUM_GAMES)\n",
    "    print(\"Finished building dataset!\")\n",
    "    print(\"X shape:\", X.shape)  # (N,6,7,2)\n",
    "    print(\"y shape:\", y.shape)\n",
    "    print(\"Unique moves in y:\", np.unique(y))\n",
    "\n",
    "    # Save to disk\n",
    "    np.save(\"X_dataset_ethan2.npy\", X) # change filename as needed\n",
    "    np.save(\"y_dataset_ethan2.npy\", y) # change filename as needed\n",
    "    print(\"Dataset saved to X_dataset_new.ethan2.npy and y_dataset_ethan2.npy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before concatenation:\n",
      "  Dataset 1: (457185, 6, 7, 2) (457185,)\n",
      "  Dataset 2: (465707, 6, 7, 2) (465707,)\n",
      "After concatenation: (922892, 6, 7, 2) (922892,)\n",
      "Saved merged dataset to X_dataset_merged.npy, y_dataset_merged.npy.\n"
     ]
    }
   ],
   "source": [
    "# Append dataset code\n",
    "\n",
    "def append_datasets(file1_X, file1_y, file2_X, file2_y, out_X, out_y):\n",
    "    \"\"\"\n",
    "    Load two Connect4 datasets (X1,y1) and (X2,y2),\n",
    "    concatenate them along axis=0,\n",
    "    then save as (out_X, out_y).\n",
    "    \"\"\"\n",
    "    X1 = np.load(file1_X)\n",
    "    y1 = np.load(file1_y)\n",
    "    X2 = np.load(file2_X)\n",
    "    y2 = np.load(file2_y)\n",
    "\n",
    "    print(\"Before concatenation:\")\n",
    "    print(\"  Dataset 1:\", X1.shape, y1.shape)\n",
    "    print(\"  Dataset 2:\", X2.shape, y2.shape)\n",
    "\n",
    "    X_merged = np.concatenate([X1, X2], axis=0)\n",
    "    y_merged = np.concatenate([y1, y2], axis=0)\n",
    "\n",
    "    print(\"After concatenation:\", X_merged.shape, y_merged.shape)\n",
    "\n",
    "    np.save(out_X, X_merged)\n",
    "    np.save(out_y, y_merged)\n",
    "    print(f\"Saved merged dataset to {out_X}, {out_y}.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    append_datasets(\n",
    "        file1_X=\"X_dataset_ethan.npy\",\n",
    "        file1_y=\"y_dataset_ethan.npy\",\n",
    "        file2_X=\"X_dataset_ethan2.npy\",\n",
    "        file2_y=\"y_dataset_ethan2.npy\",\n",
    "        out_X=\"X_dataset_merged.npy\",\n",
    "        out_y=\"y_dataset_merged.npy\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes:\n",
      "X: (922892, 6, 7, 2)\n",
      "y: (922892,)\n",
      "Unique moves in y: [0 1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "X_file = \"X_dataset_merged.npy\"\n",
    "y_file = \"y_dataset_merged.npy\"\n",
    "\n",
    "X = np.load(X_file)  # shape (N, 6, 7, 2)\n",
    "y = np.load(y_file)  # shape (N,)\n",
    "\n",
    "print(\"Data shapes:\")\n",
    "print(\"X:\", X.shape)\n",
    "print(\"y:\", y.shape)\n",
    "unique_moves = np.unique(y)\n",
    "print(\"Unique moves in y:\", unique_moves)  # should be [0..6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 738313\n",
      "Validation set size: 184579\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.2, \n",
    "    random_state=22, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(\"Training set size:\", X_train.shape[0])\n",
    "print(\"Validation set size:\", X_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAvailable GPUs:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Res-Net Style CNN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 6, 7, 2)]    0           []                               \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 6, 7, 64)     1216        ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 6, 7, 64)    256         ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_13 (ReLU)                (None, 6, 7, 64)     0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_13[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 6, 7, 64)    256         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_14 (ReLU)                (None, 6, 7, 64)     0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_14[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 6, 7, 64)    256         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 6, 7, 64)     0           ['re_lu_13[0][0]',               \n",
      "                                                                  'batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_15 (ReLU)                (None, 6, 7, 64)     0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_15[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 6, 7, 64)    256         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_16 (ReLU)                (None, 6, 7, 64)     0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_16[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 6, 7, 64)    256         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 6, 7, 64)     0           ['re_lu_15[0][0]',               \n",
      "                                                                  'batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_17 (ReLU)                (None, 6, 7, 64)     0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 3, 3, 64)    0           ['re_lu_17[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 3, 3, 128)    8320        ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 3, 3, 128)   512         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_18 (ReLU)                (None, 3, 3, 128)    0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 3, 3, 128)    147584      ['re_lu_18[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 3, 3, 128)   512         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_19 (ReLU)                (None, 3, 3, 128)    0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 3, 3, 128)    147584      ['re_lu_19[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 3, 3, 128)   512         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 3, 3, 128)    0           ['re_lu_18[0][0]',               \n",
      "                                                                  'batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_20 (ReLU)                (None, 3, 3, 128)    0           ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 128)   0           ['re_lu_20[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 1, 1, 256)    33024       ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 1, 1, 256)   1024        ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_21 (ReLU)                (None, 1, 1, 256)    0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 1, 1, 256)    590080      ['re_lu_21[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 1, 1, 256)   1024        ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_22 (ReLU)                (None, 1, 1, 256)    0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 1, 1, 256)    590080      ['re_lu_22[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 1, 1, 256)   1024        ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 1, 1, 256)    0           ['re_lu_21[0][0]',               \n",
      "                                                                  'batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_23 (ReLU)                (None, 1, 1, 256)    0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 256)          0           ['re_lu_23[0][0]']               \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 512)          131584      ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 512)         2048        ['dense_3[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_24 (ReLU)                (None, 512)          0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 512)          0           ['re_lu_24[0][0]']               \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 256)          131328      ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 256)         1024        ['dense_4[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_25 (ReLU)                (None, 256)          0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 256)          0           ['re_lu_25[0][0]']               \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 7)            1799        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,939,271\n",
      "Trainable params: 1,934,791\n",
      "Non-trainable params: 4,480\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Original ResNet-style CNN for Connect4\n",
    "def residual_block(x, filters, kernel_size=(3,3), l2_reg=5e-5):\n",
    "    \"\"\"\n",
    "    A basic ResNet-style block:\n",
    "      - 2D Convolution -> BN -> ReLU\n",
    "      - 2D Convolution -> BN\n",
    "      - Skip connection: add the input 'x' to the result\n",
    "      - Final ReLU activation\n",
    "    \"\"\"\n",
    "    # Save the input to add back later\n",
    "    shortcut = x\n",
    "\n",
    "    # First conv\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        filters, kernel_size, padding='same',\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(l2_reg)\n",
    "    )(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    # Second conv\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        filters, kernel_size, padding='same',\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(l2_reg)\n",
    "    )(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    # Add the shortcut (must have same shape)\n",
    "    x = tf.keras.layers.Add()([shortcut, x])\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def build_resnet_cnn(input_shape=(6,7,2), num_classes=7, l2_reg=5e-5, dropout_rate=0.3):\n",
    "    \"\"\"\n",
    "    A deeper ResNet-style CNN for Connect4.\n",
    "    - input_shape: (6,7,2)\n",
    "    - num_classes: 7 (one per column)\n",
    "    - l2_reg: L2 regularization factor\n",
    "    - dropout_rate: dropout ratio in dense layers\n",
    "    \"\"\"\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "\n",
    "    # Initial conv: (like a \"stem\" layer)\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        64, (3,3), padding='same',\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(l2_reg)\n",
    "    )(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    # --- Residual Block 1 (64 filters) ---\n",
    "    x = residual_block(x, filters=64, l2_reg=l2_reg)\n",
    "\n",
    "    # Do a second residual block at same (64) filters\n",
    "    x = residual_block(x, filters=64, l2_reg=l2_reg)\n",
    "\n",
    "    # MaxPool to reduce from (6,7) -> (3,3)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=2)(x)\n",
    "\n",
    "    # --- Residual Block 2 (128 filters) ---\n",
    "    x = tf.keras.layers.Conv2D(128, (1,1), strides=1,  # 1x1 to expand channels\n",
    "                               padding='same',\n",
    "                               kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    x = residual_block(x, filters=128, l2_reg=l2_reg)\n",
    "\n",
    "    # (3,3) -> (1,1) with maxpool\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=2)(x)\n",
    "\n",
    "    # --- Residual Block 3 (256 filters) ---\n",
    "    # 1x1 conv to expand from 128->256 channels\n",
    "    x = tf.keras.layers.Conv2D(256, (1,1), strides=1,\n",
    "                               padding='same',\n",
    "                               kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    x = residual_block(x, filters=256, l2_reg=l2_reg)\n",
    "\n",
    "    # Flatten\n",
    "    x = tf.keras.layers.Flatten()(x)  # shape ~ (256,)\n",
    "\n",
    "    # Dense block\n",
    "    x = tf.keras.layers.Dense(\n",
    "        512,\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(l2_reg)\n",
    "    )(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(\n",
    "        256,\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(l2_reg)\n",
    "    )(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    # Output\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = build_resnet_cnn(input_shape=(6,7,2), num_classes=7, l2_reg=5e-5, dropout_rate=0.3) # maybe change to 2e-5 and 0.2\n",
    "\n",
    "    # Compile\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.005),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    model.summary()\n",
    "\n",
    "# Need to improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNetSmall\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 6, 7, 2)]    0           []                               \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 6, 7, 64)     1216        ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 6, 7, 64)    256         ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_38 (ReLU)                (None, 6, 7, 64)     0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_38[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 6, 7, 64)    256         ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_39 (ReLU)                (None, 6, 7, 64)     0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_39[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 6, 7, 64)    256         ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 6, 7, 64)     0           ['re_lu_38[0][0]',               \n",
      "                                                                  'batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_40 (ReLU)                (None, 6, 7, 64)     0           ['add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_40[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 6, 7, 64)    256         ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_41 (ReLU)                (None, 6, 7, 64)     0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_41[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 6, 7, 64)    256         ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 6, 7, 64)     0           ['re_lu_40[0][0]',               \n",
      "                                                                  'batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_42 (ReLU)                (None, 6, 7, 64)     0           ['add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPooling2D)  (None, 3, 3, 64)    0           ['re_lu_42[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 3, 3, 128)    8320        ['max_pooling2d_6[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 3, 3, 128)   512         ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_43 (ReLU)                (None, 3, 3, 128)    0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 3, 3, 128)    147584      ['re_lu_43[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 3, 3, 128)   512         ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_44 (ReLU)                (None, 3, 3, 128)    0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 3, 3, 128)    147584      ['re_lu_44[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 3, 3, 128)   512         ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 3, 3, 128)    0           ['re_lu_43[0][0]',               \n",
      "                                                                  'batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_45 (ReLU)                (None, 3, 3, 128)    0           ['add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 3, 3, 128)    147584      ['re_lu_45[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 3, 3, 128)   512         ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_46 (ReLU)                (None, 3, 3, 128)    0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 3, 3, 128)    147584      ['re_lu_46[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 3, 3, 128)   512         ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 3, 3, 128)    0           ['re_lu_45[0][0]',               \n",
      "                                                                  'batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_47 (ReLU)                (None, 3, 3, 128)    0           ['add_15[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPooling2D)  (None, 1, 1, 128)   0           ['re_lu_47[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 128)          0           ['max_pooling2d_7[0][0]']        \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 512)          66048       ['flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 512)         2048        ['dense_9[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_48 (ReLU)                (None, 512)          0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 512)          0           ['re_lu_48[0][0]']               \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 256)          131328      ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 256)         1024        ['dense_10[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_49 (ReLU)                (None, 256)          0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 256)          0           ['re_lu_49[0][0]']               \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 7)            1799        ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 953,671\n",
      "Trainable params: 950,215\n",
      "Non-trainable params: 3,456\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Second ResNet-like CNN for Connect4 - Best Performer\n",
    "def residual_block(x, filters, kernel_size=(3,3), l2_reg=2e-5):\n",
    "    \"\"\"\n",
    "    A basic ResNet-style block:\n",
    "      - 1st 3x3 Conv -> BN -> ReLU\n",
    "      - 2nd 3x3 Conv -> BN\n",
    "      - skip connection (add input)\n",
    "      - final ReLU\n",
    "    \"\"\"\n",
    "    shortcut = x\n",
    "\n",
    "    # 1st conv\n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same',\n",
    "                      kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 2nd conv\n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same',\n",
    "                      kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # skip connection\n",
    "    x = layers.Add()([shortcut, x])\n",
    "    x = layers.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "def build_resnet_small(input_shape=(6,7,2), num_classes=7,\n",
    "                       l2_reg=2e-5, dropout_rate=0.2):\n",
    "    \"\"\"\n",
    "    A 'medium-depth' ResNet-like CNN for Connect 4:\n",
    "      - conv(64) 'stem'\n",
    "      - residual block(64) x2\n",
    "      - maxpool\n",
    "      - conv(128,1x1) \n",
    "      - residual block(128) x2\n",
    "      - maxpool\n",
    "      - flatten -> Dense(512)->(BN,ReLU,Dropout)\n",
    "      - Dense(256)->(BN,ReLU,Dropout)\n",
    "      - output(7,softmax)\n",
    "    \"\"\"\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Stem conv\n",
    "    x = layers.Conv2D(64, (3,3), padding='same',\n",
    "                      kernel_regularizer=regularizers.l2(l2_reg))(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 2 res blocks at 64\n",
    "    x = residual_block(x, filters=64, l2_reg=l2_reg)\n",
    "    x = residual_block(x, filters=64, l2_reg=l2_reg)\n",
    "\n",
    "    # pool\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), strides=2)(x)  # shape ~ (3,4,64)\n",
    "\n",
    "    # expand to 128 channels w/ 1x1\n",
    "    x = layers.Conv2D(128, (1,1), padding='same',\n",
    "                      kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 2 res blocks at 128\n",
    "    x = residual_block(x, filters=128, l2_reg=l2_reg)\n",
    "    x = residual_block(x, filters=128, l2_reg=l2_reg)\n",
    "\n",
    "    # pool again\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), strides=2)(x)\n",
    "    # shape ~ (1,2,128) => flatten => 256 features\n",
    "\n",
    "    x = layers.Flatten()(x)  # shape ~ (256,) or so\n",
    "\n",
    "    # Dense block\n",
    "    x = layers.Dense(512, kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    x = layers.Dense(256, kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs, outputs, name=\"ResNetSmall\")\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = build_resnet_small(\n",
    "        input_shape=(6,7,2),\n",
    "        num_classes=7,\n",
    "        l2_reg=2e-5, # 1e-6?\n",
    "        dropout_rate=0.2 # 0.15? \n",
    "    )\n",
    "\n",
    "    # compile\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), # 0.01?\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNetModified\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 6, 7, 2)]    0           []                               \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 6, 7, 64)     1216        ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 6, 7, 64)    256         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_19 (ReLU)                (None, 6, 7, 64)     0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_19[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 6, 7, 64)    256         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_20 (ReLU)                (None, 6, 7, 64)     0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_20[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 6, 7, 64)    256         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_21 (ReLU)                (None, 6, 7, 64)     0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_21[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 6, 7, 64)    256         ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 6, 7, 64)     0           ['re_lu_20[0][0]',               \n",
      "                                                                  'batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_22 (ReLU)                (None, 6, 7, 64)     0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_22[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 6, 7, 64)    256         ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_23 (ReLU)                (None, 6, 7, 64)     0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_23[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 6, 7, 64)    256         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 6, 7, 64)     0           ['re_lu_22[0][0]',               \n",
      "                                                                  'batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_24 (ReLU)                (None, 6, 7, 64)     0           ['add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_24[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 6, 7, 64)    256         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_25 (ReLU)                (None, 6, 7, 64)     0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_25[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 6, 7, 64)    256         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 6, 7, 64)     0           ['re_lu_24[0][0]',               \n",
      "                                                                  'batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_26 (ReLU)                (None, 6, 7, 64)     0           ['add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 3, 3, 64)    0           ['re_lu_26[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 3, 3, 128)    8320        ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 3, 3, 128)   512         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_27 (ReLU)                (None, 3, 3, 128)    0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 3, 3, 128)    147584      ['re_lu_27[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 3, 3, 128)   512         ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_28 (ReLU)                (None, 3, 3, 128)    0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 3, 3, 128)    147584      ['re_lu_28[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 3, 3, 128)   512         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 3, 3, 128)    0           ['re_lu_27[0][0]',               \n",
      "                                                                  'batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_29 (ReLU)                (None, 3, 3, 128)    0           ['add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 3, 3, 128)    147584      ['re_lu_29[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 3, 3, 128)   512         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_30 (ReLU)                (None, 3, 3, 128)    0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 3, 3, 128)    147584      ['re_lu_30[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 3, 3, 128)   512         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 3, 3, 128)    0           ['re_lu_29[0][0]',               \n",
      "                                                                  'batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_31 (ReLU)                (None, 3, 3, 128)    0           ['add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 128)   0           ['re_lu_31[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 1, 1, 128)    147584      ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 1, 1, 128)   512         ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_32 (ReLU)                (None, 1, 1, 128)    0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 1, 1, 128)    147584      ['re_lu_32[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 1, 1, 128)   512         ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 1, 1, 128)    0           ['max_pooling2d_3[0][0]',        \n",
      "                                                                  'batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_33 (ReLU)                (None, 1, 1, 128)    0           ['add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 1, 1, 128)    147584      ['re_lu_33[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 1, 1, 128)   512         ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_34 (ReLU)                (None, 1, 1, 128)    0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 1, 1, 128)    147584      ['re_lu_34[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 1, 1, 128)   512         ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 1, 1, 128)    0           ['re_lu_33[0][0]',               \n",
      "                                                                  'batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_35 (ReLU)                (None, 1, 1, 128)    0           ['add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 128)          0           ['re_lu_35[0][0]']               \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 768)          99072       ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 768)         3072        ['dense_3[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_36 (ReLU)                (None, 768)          0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 768)          0           ['re_lu_36[0][0]']               \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 256)          196864      ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 256)         1024        ['dense_4[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_37 (ReLU)                (None, 256)          0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 256)          0           ['re_lu_37[0][0]']               \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 7)            1799        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,757,191\n",
      "Trainable params: 1,751,815\n",
      "Non-trainable params: 5,376\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 3rd ResNet Iteration\n",
    "\n",
    "def residual_block(x, filters, kernel_size=(3,3), l2_reg=1e-5):\n",
    "    \"\"\"\n",
    "    A basic ResNet-style block:\n",
    "      - 3x3 Conv -> BN -> ReLU\n",
    "      - 3x3 Conv -> BN\n",
    "      - skip connection\n",
    "      - final ReLU\n",
    "    \"\"\"\n",
    "    shortcut = x\n",
    "\n",
    "    # 1st conv\n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same',\n",
    "                      kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 2nd conv\n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same',\n",
    "                      kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # skip connection\n",
    "    x = layers.Add()([shortcut, x])\n",
    "    x = layers.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "def build_resnet_mod(input_shape=(6,7,2), num_classes=7,\n",
    "                     l2_reg=1e-5, dropout_rate=0.15):\n",
    "    \"\"\"\n",
    "    A deeper ResNet-like CNN for Connect 4:\n",
    "    \n",
    "    Architecture:\n",
    "      1) \"Wide stem\": \n",
    "         - Conv(64, 3x3), BN, ReLU\n",
    "         - Conv(64, 3x3), BN, ReLU\n",
    "      2) 3 residual blocks at 64\n",
    "      3) MaxPool\n",
    "      4) Expand to 128\n",
    "      5) 2 residual blocks at 128\n",
    "      6) MaxPool\n",
    "      7) 2 more residual blocks at 128\n",
    "      8) Flatten -> Dense(768) -> BN -> ReLU -> Dropout\n",
    "      9) Dense(256) -> BN -> ReLU -> Dropout\n",
    "      10) Output(7, softmax)\n",
    "    \"\"\"\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # ==============\n",
    "    # 1. Wide Stem\n",
    "    # ==============\n",
    "    x = layers.Conv2D(64, (3,3), padding='same',\n",
    "                      kernel_regularizer=regularizers.l2(l2_reg))(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    x = layers.Conv2D(64, (3,3), padding='same',\n",
    "                      kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # ==============\n",
    "    # 2. 3 residual blocks at 64\n",
    "    # ==============\n",
    "    x = residual_block(x, filters=64, l2_reg=l2_reg)\n",
    "    x = residual_block(x, filters=64, l2_reg=l2_reg)\n",
    "    x = residual_block(x, filters=64, l2_reg=l2_reg)\n",
    "\n",
    "    # ==============\n",
    "    # 3. MaxPool\n",
    "    # ==============\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), strides=2)(x)  # shape ~ (3,4,64)\n",
    "\n",
    "    # ==============\n",
    "    # 4. Expand to 128\n",
    "    # ==============\n",
    "    x = layers.Conv2D(128, (1,1), padding='same',\n",
    "                      kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # ==============\n",
    "    # 5. 2 residual blocks at 128\n",
    "    # ==============\n",
    "    x = residual_block(x, filters=128, l2_reg=l2_reg)\n",
    "    x = residual_block(x, filters=128, l2_reg=l2_reg)\n",
    "\n",
    "    # ==============\n",
    "    # 6. MaxPool\n",
    "    # ==============\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), strides=2)(x)\n",
    "    # shape ~ (1,2,128)\n",
    "\n",
    "    # ==============\n",
    "    # 7. 2 more residual blocks at 128\n",
    "    # ==============\n",
    "    x = residual_block(x, filters=128, l2_reg=l2_reg)\n",
    "    x = residual_block(x, filters=128, l2_reg=l2_reg)\n",
    "\n",
    "    # flatten\n",
    "    x = layers.Flatten()(x)  # shape ~ (256) or (128*2)...\n",
    "\n",
    "    # ==============\n",
    "    # 8. Dense(768)\n",
    "    # ==============\n",
    "    x = layers.Dense(768, kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    # ==============\n",
    "    # 9. Dense(256)\n",
    "    # ==============\n",
    "    x = layers.Dense(256, kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    # ==============\n",
    "    # 10. Output\n",
    "    # ==============\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs, outputs, name=\"ResNetModified\")\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = build_resnet_mod(\n",
    "        input_shape=(6,7,2),\n",
    "        num_classes=7,\n",
    "        l2_reg=1e-6,       # less L2 regularization\n",
    "        dropout_rate=0.1  # slightly less dropout\n",
    "    )\n",
    "\n",
    "    # Compile\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.007),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23073/23073 [==============================] - 260s 11ms/step - loss: 0.6733 - accuracy: 0.7483 - val_loss: 0.7352 - val_accuracy: 0.7207 - lr: 1.0938e-04\n",
      "Epoch 2/100\n",
      "23073/23073 [==============================] - 264s 11ms/step - loss: 0.6681 - accuracy: 0.7495 - val_loss: 0.7363 - val_accuracy: 0.7204 - lr: 1.0938e-04\n",
      "Epoch 3/100\n",
      "23073/23073 [==============================] - 258s 11ms/step - loss: 0.6664 - accuracy: 0.7504 - val_loss: 0.7374 - val_accuracy: 0.7205 - lr: 1.0938e-04\n",
      "Epoch 4/100\n",
      "23071/23073 [============================>.] - ETA: 0s - loss: 0.6650 - accuracy: 0.7512\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 5.4687501688022166e-05.\n",
      "23073/23073 [==============================] - 258s 11ms/step - loss: 0.6650 - accuracy: 0.7512 - val_loss: 0.7383 - val_accuracy: 0.7203 - lr: 1.0938e-04\n",
      "Epoch 5/100\n",
      "23073/23073 [==============================] - 259s 11ms/step - loss: 0.6618 - accuracy: 0.7521 - val_loss: 0.7368 - val_accuracy: 0.7205 - lr: 5.4688e-05\n",
      "Epoch 6/100\n",
      "23073/23073 [==============================] - 259s 11ms/step - loss: 0.6607 - accuracy: 0.7526 - val_loss: 0.7386 - val_accuracy: 0.7206 - lr: 5.4688e-05\n",
      "Epoch 7/100\n",
      "23073/23073 [==============================] - ETA: 0s - loss: 0.6614 - accuracy: 0.7523\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 2.7343750844011083e-05.\n",
      "23073/23073 [==============================] - 265s 11ms/step - loss: 0.6614 - accuracy: 0.7523 - val_loss: 0.7375 - val_accuracy: 0.7204 - lr: 5.4688e-05\n",
      "Epoch 8/100\n",
      "23073/23073 [==============================] - 282s 12ms/step - loss: 0.6593 - accuracy: 0.7532 - val_loss: 0.7383 - val_accuracy: 0.7205 - lr: 2.7344e-05\n",
      "Epoch 9/100\n",
      "23073/23073 [==============================] - 276s 12ms/step - loss: 0.6585 - accuracy: 0.7533 - val_loss: 0.7388 - val_accuracy: 0.7203 - lr: 2.7344e-05\n",
      "Epoch 10/100\n",
      "23073/23073 [==============================] - ETA: 0s - loss: 0.6577 - accuracy: 0.7538\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.3671875422005542e-05.\n",
      "23073/23073 [==============================] - 269s 12ms/step - loss: 0.6577 - accuracy: 0.7538 - val_loss: 0.7394 - val_accuracy: 0.7204 - lr: 2.7344e-05\n",
      "Epoch 11/100\n",
      "23073/23073 [==============================] - 279s 12ms/step - loss: 0.6572 - accuracy: 0.7537 - val_loss: 0.7393 - val_accuracy: 0.7207 - lr: 1.3672e-05\n",
      "Epoch 12/100\n",
      "23073/23073 [==============================] - 273s 12ms/step - loss: 0.6576 - accuracy: 0.7537 - val_loss: 0.7398 - val_accuracy: 0.7206 - lr: 1.3672e-05\n",
      "Epoch 13/100\n",
      "23072/23073 [============================>.] - ETA: 0s - loss: 0.6569 - accuracy: 0.7541\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 6.835937711002771e-06.\n",
      "23073/23073 [==============================] - 261s 11ms/step - loss: 0.6569 - accuracy: 0.7541 - val_loss: 0.7390 - val_accuracy: 0.7206 - lr: 1.3672e-05\n",
      "Epoch 14/100\n",
      "23073/23073 [==============================] - 259s 11ms/step - loss: 0.6564 - accuracy: 0.7541 - val_loss: 0.7393 - val_accuracy: 0.7204 - lr: 6.8359e-06\n",
      "Epoch 15/100\n",
      "23073/23073 [==============================] - 257s 11ms/step - loss: 0.6568 - accuracy: 0.7536 - val_loss: 0.7385 - val_accuracy: 0.7206 - lr: 6.8359e-06\n",
      "Epoch 16/100\n",
      "23069/23073 [============================>.] - ETA: 0s - loss: 0.6558 - accuracy: 0.7538\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 3.4179688555013854e-06.\n",
      "23073/23073 [==============================] - 255s 11ms/step - loss: 0.6559 - accuracy: 0.7538 - val_loss: 0.7393 - val_accuracy: 0.7203 - lr: 6.8359e-06\n",
      "Epoch 17/100\n",
      "23073/23073 [==============================] - 255s 11ms/step - loss: 0.6556 - accuracy: 0.7539 - val_loss: 0.7397 - val_accuracy: 0.7206 - lr: 3.4180e-06\n",
      "Epoch 18/100\n",
      "23073/23073 [==============================] - 254s 11ms/step - loss: 0.6555 - accuracy: 0.7541 - val_loss: 0.7391 - val_accuracy: 0.7205 - lr: 3.4180e-06\n",
      "Epoch 19/100\n",
      "23069/23073 [============================>.] - ETA: 0s - loss: 0.6553 - accuracy: 0.7546\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 1.7089844277506927e-06.\n",
      "23073/23073 [==============================] - 254s 11ms/step - loss: 0.6553 - accuracy: 0.7546 - val_loss: 0.7396 - val_accuracy: 0.7205 - lr: 3.4180e-06\n",
      "Epoch 20/100\n",
      "23073/23073 [==============================] - 254s 11ms/step - loss: 0.6558 - accuracy: 0.7542 - val_loss: 0.7396 - val_accuracy: 0.7208 - lr: 1.7090e-06\n",
      "Epoch 21/100\n",
      "23073/23073 [==============================] - 254s 11ms/step - loss: 0.6558 - accuracy: 0.7539 - val_loss: 0.7400 - val_accuracy: 0.7205 - lr: 1.7090e-06\n",
      "Epoch 22/100\n",
      "23070/23073 [============================>.] - ETA: 0s - loss: 0.6559 - accuracy: 0.7543\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "23073/23073 [==============================] - 254s 11ms/step - loss: 0.6559 - accuracy: 0.7543 - val_loss: 0.7389 - val_accuracy: 0.7205 - lr: 1.7090e-06\n",
      "Epoch 23/100\n",
      "23073/23073 [==============================] - 254s 11ms/step - loss: 0.6560 - accuracy: 0.7541 - val_loss: 0.7394 - val_accuracy: 0.7204 - lr: 1.0000e-06\n",
      "Epoch 24/100\n",
      "23073/23073 [==============================] - 254s 11ms/step - loss: 0.6561 - accuracy: 0.7540 - val_loss: 0.7400 - val_accuracy: 0.7205 - lr: 1.0000e-06\n",
      "Epoch 25/100\n",
      "23073/23073 [==============================] - 254s 11ms/step - loss: 0.6559 - accuracy: 0.7542 - val_loss: 0.7393 - val_accuracy: 0.7205 - lr: 1.0000e-06\n",
      "Epoch 26/100\n",
      "23073/23073 [==============================] - 254s 11ms/step - loss: 0.6558 - accuracy: 0.7542 - val_loss: 0.7395 - val_accuracy: 0.7205 - lr: 1.0000e-06\n",
      "Epoch 27/100\n",
      "23073/23073 [==============================] - 254s 11ms/step - loss: 0.6556 - accuracy: 0.7541 - val_loss: 0.7388 - val_accuracy: 0.7206 - lr: 1.0000e-06\n",
      "Epoch 28/100\n",
      "23073/23073 [==============================] - 254s 11ms/step - loss: 0.6559 - accuracy: 0.7543 - val_loss: 0.7393 - val_accuracy: 0.7205 - lr: 1.0000e-06\n",
      "Epoch 29/100\n",
      "23073/23073 [==============================] - 254s 11ms/step - loss: 0.6556 - accuracy: 0.7545 - val_loss: 0.7396 - val_accuracy: 0.7207 - lr: 1.0000e-06\n",
      "Epoch 30/100\n",
      "23073/23073 [==============================] - 254s 11ms/step - loss: 0.6553 - accuracy: 0.7544 - val_loss: 0.7393 - val_accuracy: 0.7204 - lr: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "# Early stopping if val_accuracy doesn’t improve for 7 epochs\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Reduce learning rate by factor of 0.5 if val_accuracy doesn’t improve for 3 epochs\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 72.08%   (loss=0.7396)\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(f\"Validation accuracy: {val_acc*100:.2f}%   (loss={val_loss:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to cnn_connect4.h5.\n"
     ]
    }
   ],
   "source": [
    "model.save(\"cnn_connect4.h5\")\n",
    "print(\"Model saved to cnn_connect4.h5.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/QAAAGJCAYAAAAkBnhUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAACBHklEQVR4nO3dB3hUVfrH8TcdEkiBAKH3LoLSFisuKCqroliwLOgqKgr2ArsrKq5iWbusrGvd/6qwuOi6FkTBhiIgiIgC0nsLLZBA6vyf35nMMGkQQsJkku/neS537p2bmTs3E859z3nPOWEej8djAAAAAAAgpIQH+wQAAAAAAMCRI6AHAAAAACAEEdADAAAAABCCCOgBAAAAAAhBBPQAAAAAAIQgAnoAAAAAAEIQAT0AAAAAACGIgB4AAAAAgBBEQA8AAAAAQAgioAcAAAAAIAQR0AM4pNdff93CwsLs+++/D/apAACAQv72t7+5crp3797BPhUAQUBADwAAAISoN99801q0aGFz5861FStWBPt0ABxjBPQAAABACFq9erV9++239tRTT1m9evVccF8ZpaenB/sUgCqLgB7AUfvhhx/snHPOsfj4eKtVq5b169fPvvvuuwLHZGdn24MPPmht27a1GjVqWN26de2UU06xTz/91H/Mli1b7JprrrEmTZpYTEyMNWzY0C644AJbs2ZNED4VAACVmwL4pKQkGzhwoF188cXFBvS7d++222+/3bXiq2xVGTt06FBLTU31H3PgwAF74IEHrF27dq6MVvl70UUX2cqVK93zX3zxhUvr1zqQymftV/c8n6uvvtrdC+hnzz33XKtdu7ZdeeWV7rmvv/7aLrnkEmvWrJk7l6ZNm7pz279/f5HzXrp0qV166aWuoqJmzZrWvn17+9Of/uSe+/zzz937vvvuu0V+7q233nLPzZ49+6iuLRAqIoN9AgBC288//2ynnnqqC+bvuecei4qKsr///e/Wt29f+/LLL/19+nSjMH78eLvuuuusV69elpaW5vrlL1iwwM4880x3zODBg93rjRo1yt14bNu2zQX869atc9sAAOAgBfAKvKOjo+3yyy+3F1980ebNm2c9e/Z0z+/bt8+V0UuWLLE//OEPduKJJ7pA/v3337cNGzZYcnKy5ebm2u9+9zubMWOGDRkyxG699Vbbu3evK38XL15srVu3PuLzysnJsQEDBriK+7/+9a8WGxvr9k+ZMsUyMjJsxIgRrmJf3QSef/55dy56zmfRokXuvHVPcf3117t7AFUQ/O9//7OHH37Y3WOoMkCf/8ILLyxyTXTOffr0OerrC4QEDwAcwmuvvebRfxXz5s0r9vlBgwZ5oqOjPStXrvTv27Rpk6d27dqe0047zb+va9eunoEDB5b4Prt27XLv88QTT5TzJwAAoOr5/vvvXbn56aefuu28vDxPkyZNPLfeeqv/mLFjx7pjpk6dWuTndby8+uqr7pinnnqqxGM+//xzd4zWgVavXu32617BZ9iwYW7f6NGji7xeRkZGkX3jx4/3hIWFedauXevfp/sH3UcE7gs8HxkzZownJibGs3v3bv++bdu2eSIjIz33339/MVcMqJpIuQdQZqrVnz59ug0aNMhatWrl369UvSuuuMJmzZrlWuIlMTHRtb4vX7682NdSOp1aGJTOt2vXrmP2GQAACEVqiW7QoIGdccYZbltp5pdddplNmjTJlc/yn//8x7p27VqkFdt3vO8YtdQrO66kY8pCrfDFlfWB/eqVLXDSSSepgdF135Pt27fbV1995TIKlJpf0vmo20BmZqa98847/n2TJ0922QFXXXVVmc8bCDUE9ADKTIWuUufUr62wjh07Wl5enq1fv95tjxs3zvXjU/+8Ll262N133+1S6nzUl+6xxx6zjz/+2N2gnHbaafb444+7fvUAAOAgBewK3BXMa2A8jW6vRd3ctm7d6tLnRWnqxx133CFfS8eoHI+MLL+euHot9dUvTF3o1Me+Tp06rp+9+seffvrp7rk9e/a49apVq9z6cOfdoUMH17UgcNwAPf7Nb35jbdq0KbfPAlR2BPQAjgkF6LppePXVV10h/fLLL7u+fFr73Hbbbfbrr7+6vvYalOe+++5zFQO+WnsAAGA2c+ZM27x5swvqNdisb9EgclLeo92X1FLvywQoTJX04eHhRY7VmDkffvih3Xvvvfbee++5fvq+AfXUCHCk1Eqv8XrUB1/3GBqQl9Z5VDcMigegzFSzroFuli1bVuzotCrMNWiNj2rkNYq9Fg3UoyBfg+VpoDwfDWRz5513ukXp+d26dbMnn3zS/vWvfx2zzwUAQGWmgL1+/fo2YcKEIs9NnTrVjf4+ceJEV6ZqYLtD0TFz5sxxs9FoELriaCR9UaZdoLVr15b6nH/66SdXaf/GG2+4QNwncLYb8XXhO9x5iwbxu+OOO+ztt992I+Xr/NXtAKhOaKEHUGYRERF21lln2X//+98CU8sp3U/Txmh0W41+Lzt27Cjws0q1U0qc+r+JUvc1bU7hmwxNd+M7BgCA6k6Bq4J2jUyvqeoKLyNHjnSj1Gske80e8+OPPxY7vZv6rYuOUV/2F154ocRjmjdv7sp89W0P9Le//a3U562fD3xN3+Nnn322SGOBKvyV0acU/eLOx0d9/zVtrir9Vclx9tlnu31AdUILPYBSUcE6bdq0IvvVwq7adQXvN910k+s3p2nrFISrD7xPp06d3DQz3bt3dy31mrJOA9noxkNUa6/565UuqGP1OroBUeWAauABAIC5QF0B+/nnn1/s8+pDrqBYAa4q11XWau53DTKnMnjnzp3uNdSCrwHz1Fr+z3/+07V0axo5TRenAes+++wzV65fcMEFlpCQ4F5DU8wp/V4V7h988IGbXra01OddP3fXXXfZxo0bXYW/BuQrbiDc5557zt1XqGuepq1r2bKlazhQuv7ChQsLHKvzV0WGPPTQQ0d8PYGQF+xh9gGExrR1JS3r16/3LFiwwDNgwABPrVq1PLGxsZ4zzjjD8+233xZ4nb/85S+eXr16eRITEz01a9b0dOjQwfPwww97srKy3POpqamem2++2e2Pi4vzJCQkeHr37u3597//HaRPDgBA5XPeeed5atSo4UlPTy/xmKuvvtoTFRXlytYdO3Z4Ro4c6WncuLGbZlZT22lqOT0XOJ3cn/70J0/Lli3dz6WkpHguvvjiAlPSbt++3TN48GBXziclJXluuOEGz+LFi4udtk7leHF++eUXT//+/d39QnJysmf48OGeH3/8schriF77wgsvdPcN+rzt27f33HfffUVeMzMz052P7hv2799/xNcTCHVh+ifYlQoAAAAAcKQ0TV2jRo3svPPOs1deeSXYpwMcc/ShBwAAABCSNFq+ptENHGgPqE5ooQcAAAAQUjQy/6JFi1y/eQ2Et2DBgmCfEhAUtNADAAAACCkvvviijRgxwk3fp0H9gOqKFnoAAAAAAEIQLfQAAAAAAIQgAnoAAAAAAEJQZLBPoDLKy8uzTZs2We3atS0sLCzYpwMAgKmH3N69e930TOHh1McfLcp6AEBVKOsJ6IuhAr5p06bBPg0AAIpYv369NWnSJNinEfIo6wEAVaGsJ6AvhmrrfRcyPj4+2KcDAIClpaW5ANRXRuHoUNYDAKpCWU9AXwxf6p0KeAp5AEBlQnp4+aCsBwBUhbKeTngAAAAAAIQgAnoAAAAAAEIQAT0AAAAAACGIgB4AAAAAgBBEQA8AAI7KhAkTrEWLFlajRg3r3bu3zZ07t8Rj+/bt6wb7KbwMHDjQf8zVV19d5Pmzzz67wOvo/Qof8+ijj1bo5wQAoLJhlHsAAFBmkydPtjvuuMMmTpzogvlnnnnGBgwYYMuWLbP69esXOX7q1KmWlZXl396xY4d17drVLrnkkgLHKYB/7bXX/NsxMTFFXmvcuHE2fPhw/zZT+gEAqhsCegAAUGZPPfWUC6qvueYat63A/sMPP7RXX33VRo8eXeT4OnXqFNieNGmSxcbGFgnoFcCnpKQc8r0VwB/uGJ/MzEy3BM71CwBAqAuviql6gW688Ub3vFoMAABA+VFL+/z5861///7+feHh4W579uzZpXqNV155xYYMGWJxcXEF9n/xxReuhb99+/Y2YsQI15JfmFLs69atayeccII98cQTlpOTU+L7jB8/3hISEvxL06ZNj+izAgBQGYVXllS9+++/3xYsWODS7pSqt23btmKPV6re5s2b/cvixYstIiKiSM2+vPvuu/bdd99Zo0aNjsEnAQCgeklNTbXc3Fxr0KBBgf3a3rJly2F/XhX4Ksevu+66Iun2//znP23GjBn22GOP2ZdffmnnnHOOey+fW265xbXuf/7553bDDTfYI488Yvfcc0+J7zVmzBjbs2ePf1m/fn2ZPjMAAJVJZFVN1du4caONGjXKPvnkkxJb7wEgKDweswO7zdJTzdK3m2XvN2t0gllswf/fgn6O+7aZ7VxplnPArG4bs/gman4N9pmhClHrfJcuXaxXr14F9qvF3kfPH3/88da6dWvXat+vXz+3X40BPno+OjraBfZqiS+uv732FbcfQPXk8Xhs+bZ9tjM9y7o2SbSa0RHBPiUg9AJ6X6qeas3LM1UvLy/Pfv/739vdd99tnTt3Puxr0K8OlUZenlnaRrNdq812ri641nMNu5o1PsEb/DU4ziyyGtyc5uaYpW8z27vFu2TuNUtoYlanlVntFLOwsIo/B117T65ZXo5ZbrZ3nZe/7V/yt7PSzTLyA3W3BD72baea5WUXepMws4bHm7U8zazl6WbN+pjF1Kr4z5ax02zHSrMdK7zBux679SqzrL0Fj42KNUtua5bc3qxeu/x1e7OklmaR0ValqdJFv9uY+Kr/WY9AcnKyy5LbunVrgf3aPlzf9vT0dFcpr4HtDqdVq1buvVasWOEP6AtTlz2l3K9Zs8al6QNAYZk5ufbdqp02c8lWm7F0m23Ytd/tj44It+7Nk+zkNnXt5DbJ1qVxgkVGUIFd3RzIzrW0/dnmMbOI8DCL1BIR7ta+bXXlrmwiK2uq3tKlS0udqqegPpDS8yIjI106XmmoNv/BBx88wrNHtaRWy72bzVJ/Ndv+qzfQDgs3i6qZv8QWsy68r6Y3iCoctO9cZbZ7rVnuwdGfi9j6k9nCf3kfh0eZpRznDe4bnehd1+tgFhF59J/xWAXJ+xSkbz4YrGtx+wIWBcHuv9Zi6JoqsK/TMn8dsNRudOjW5ANpZmmbvBUobl3o8d5N3gBOQbonr2KuQUyCWVyy97GC6M0/epdvnzcLjzRr3MMb4Lc63axJz7JV4KgCQp9nzwbv53PftfwAXsG7MgVKFGaW2NQssqb3+5mdcfAcA+lcFdQruE9u510nNvd+l/Uzuo5aDvdYmQDxjc3qd/S+Rr2OZnVbm0VEWbnR9ztjh/e7tX9X/rIz4PEu79/n/t0Fn9O5+UTXMqtZxyw2KX9dx6xm4OPAdZJZbLJZjXiritQq3r17d5caP2jQIH+lurZHjhx5yJ+dMmWKq0y/6qqrDvs+GzZscH3oGzZsWOIxCxcudI0CxY2sD6D62r430z5fus1mLN1qXy9PtYysg113oiPDLbFmlG3bm2mzV+1wy1+n/2q1YyLtN63r2smt69opbZOtdb1alTKQQ8kUnKvCZldGlu3OyHbrPfnrXRnZtmd/lu1Kz7bd+7Ntt9uXZQeyD3+/FxEQ3GsdFRHu1qoU+mb0b61aptyXd6qeWvyfffZZ1x+/tH94yhAITN1TCz2D5VRzOZneAEaBu1uWH1xn7avY91agntjMG6QqSPKtFdRuWmi2aYHZxgXeQGPTD97FXj0Y4KYc7w3uG5/oDYqyD3iDNgUoB/aU8Dh/W4/1+fT+ygZwSzdvy3Gto7hJVuu1rp8CQX2GzQvNtvxU+msZFmFWq4FZ7QbeYGrPerPd67yB4NbF3qWwiJj8QL+19/OoZT8wYC/c+lwWOi8Fs1oi8tcKfhWkx9XLXwIfB24nFwzQFWCu/tps9ZfeRZ9v/Xfe5avHzSJrmDX7jbf1Xot+N6pMUvbCHn2uDd6gvfDjfVtLrhDxUeWHAmctul7ucRuzpBYHz1EVA7vWmG1fZpa6zFuh5fv70O9xx3LvctTmmf3y3sFNXVOdiyqrShPo52R5f8/u868/uN7te7zBLMfbIlNm+rxa9qwr3fEtTjW7+gOrqlR+Dhs2zHr06OHKYw1Cq9Z3X1e6oUOHWuPGjV3leeEyXJUAGtQu0L59+1wl++DBg10r/8qVK13f+DZt2rgxdkRZfHPmzLEzzjjDjXSv7dtvv91VDiQlJR3DTw+gMqbS/7I5zWYsURC/zX5cX7Diul7tGOvXob7169jAtcjXjIqwVanp9u2KVJu1ItVmr9xhaQdy7NNftrpFGsTH2Mmtk13rvZaUhBoV+hl27Mu079fusgVrd1lOnseaJNW0Jkmx1rSOd10rJrghnALjdTszbOPuDMvO9biANjxM7UFhFhEW5tpTwrXWtmvV9m77jqsZFWlJcVGWFBttNaIijirjYt2ODFudmm5rdqTb6tQMW5P/ePOegIr4IxCef6667sXJzfO4pXDzmwL6YImsaql6X3/9tRtQr1mzZv59ygK488473U2GUvEKo19dNZW5L+BGf53ZrrUHA3cFLkqxLimIUwuwWiLrtvIGVUrHVXDp1gGPszIC9uevczPNomub1WlRMGD3rZVOHl7Cf24dBh5sZVTA5wvuXWC/0Buk+oLAo6FMAS1L3j+4r3bDg0G+Kg201rkWrjhTirwCPl/griBewbs+f2EK1hSou2C9oTdg17rwdmzdotdEgZuugSpeCi8u0yHTbPtS71KSGgneFuH4RvlLwGMFuXreF7Dr/f2P87fLs7Ze3QeOv8S7iL6Dq78yW6UA/ytv4L7qC+8iUXHeFvAiqfvFiIj2fjb9vtRyHhi867scHVuK14jKT7dva2a/O7hf30VVkPiD/Py1KhVUCaFKpug473K4xzpP/e70O9um390y73fa93ssKdDX70GBuv6WS1OBIWo1D2xZd2u1puevi+yv4z1PV/EV2JK/8xDr/Bb+yjQ2QgW47LLLbPv27TZ27Fg3EF63bt1s2rRp/uy7devWuZbzQJqjftasWTZ9+vQir6f7gkWLFtkbb7xhu3fvdgPbnnXWWfbQQw/5y2qtdQ/wwAMPuFb+li1buoA+sHIeqA72Hsi2H9bttsycPH+LYeFF+xWgREYEPFY2S3zMUQVTlSV435GeZRt37XcBplrYZy7ZZlvSCgZzSqHv17G+9evQwDo3irdwRW0B1AKv5fd9WrhgbfHGPfbNylT7ZkWqzVuzy7amZdrUHza6RVolx1nnxgnWIaW2tW9Q29qn1HZBd1la8fUZ1u/cb/PW7PQvK7enH/JnEmOj3Ps1TYotEuw3TqxpcUcZ8Gfl5NnG3ftt/c4Md139610ZLoBWhUd5qREV7gL7xNhoS4r1BvmJhdYK/nW74Qvc16R6g/hNe/a7/SVRpkXdWt7X9r1WQs2Dr+l7HPh+qizR71G/F30XFNj71jm5eQGPtT64rXWwhHl0tkGkPm+q0X/++ef9qXoKxpWqV9ygeD6vv/66m5JOg98F1u4rJU+j3wdSjb761Ku1oDT96tRCryltNApufHzVTJM8ppRavXy62dL/mSU0NWvV16xx9/JNoy1MX2vdcCvg8wft+a26vn16/lDUV9YFMO0C1u2Ovr+wWqtVCVDeqVu6zkqldgF+fpCv4FYt2gpMayZ61zUSS3ic5F2rS4DSsV0gvsi7VkVHcUGSAh613ivAV8CuIF6t5YHpyT46D19FQCO1+nfzXteSKi+OhioV9Dv2B/jrvCnP/oC9sbei4Fj0US+v77OCW9d6/5XZmq+9gaXou1QrxRusJzTOD9ybBjxu4g1eQ3EwO31uBeq+gN4F+UvyA/1DZHeoIsFdD9/S7OBjdSHQdTmW40/ob74cvueUTeWL64lQlJfnsZ827rGvft1uXy3fbgvW7S5zIKEWxZ4tk+zUtvXs1LbJ1jGlaKAbbPpsW9MOuOBSQbvWSqPesEutw/tt0+79xaZJK0g8pU0969+xvp3Rob41iK9xVKnb89fucq33asVftHFPsUGkgsd2CvBTavsD/Q4p8ZYQG1XkMy3dkmbfr9llc9fstO/X7HQVBoW1a1DLerSo4wJMBdS+z6108cPRz8REhrt0cHUrcEtEuEVFhltMMfu09pjHXWO9z+Y9++1wX6vkWjGuMkHXWregeQqAPR73c75guOBjj7tuOiY9M8elwZfUCn4kasVEWovkWGtRN85aJse5dYtk72NVEIRaV4mylE1BD+g1bZ1S9f7+97/7U/X+/e9/uz70qt0vKVXv1FNPdftVQ384muP+tttuc0tpVPlCXi3TCvY2zDXb8L23f3CnC8w6nmcWU7v83kd9lBe+aTbn795+4oWDu+YneVOH1T+4fueyBxxKBdbNvi/9XItaCLMPXbvpKIDVzb5u8pWWHRi4q5U4xP4TqNDvjAL1zfkBvhYFVupfXhxlIPgD9/y0fbUIV0TwXh35ujDo70gt+xVZORYKgb6vr78veFd3hir4t1vly6ZjjOuJULEt7YB96QL4VJu1fHuRgK5ZnVirExftTwX2thjmuWDKtSDmegOtg895LDs3r0ggnFwr2k5pk+wP8OsfRRB8qODY16d5d34/Zm//ZvVl9vZx1vbOjCwXVG7efeCwQZ/+u69fO8a1THdqFO9S6fu0qlth2Qc6x/nrdtrSLXttWf6ycvs+l3penJT4GtahYW0XYK7anu7S6PdmFrx/iooIc1kEPVvWsZ7N61iPFkmuVbk4+zJzXGC/Yac3wPcG+vtd67nWe/aXInOvFBSo67ulpamWJO/jZnW9WQGx0UeXBaAQVNdhd7qvX/vBvu7u+xCw1n5VCDSvG1sgYNfj5FrRIRe0l3fZFFnVUvVQzI2vWijXK3jXMs9s689FB/n6dZrZh3eadfidWdfLzFqdUfbgK3WF2dyXvMG8rxVNgXOXS70DnKmFUWmoarXXImpB9A3+pSBf6eeHCmQCg3elcxfXIixx9fNv9JvmrxW8Nzu4r4oOVFXu1JKt/ttafNQ3f9sv3lZ8/Q7UKqq++wrelcYdii3CoUJ/m+pPXl2p4HaVcE3N2p4Z7LMBUIWpZdQ7kFqOxdeMsvga3jRdLfE1I93al6JbnkGvWm/VAq+WeAWOgfR+fVrXtdPa1bPT29ZzAVZZgimldX+9fLv7fN+t2mGp+7LsvYWb3CJqZVZgrwC/V8s6JQbIujbb0jLdwHLb9h5wj7fuPWDb8/dpUDoF6wrK1DXgSKmbQMPEGi5gb5wYa42VYq7HLtW8puvPHhN57BoM1OL+2w4N3BKYoq4UcLW8+4J8/d6URaD0fy1fLNMgvwd/hyc2T7JeLZJcK3y3pomlroDQz6rlX0tx0g5k2859WZaVm+fOS9dca9+2KnPctp4LeKyAWddYwbsC94oOlPXa+nvSUpbvMCpRC31lFNK19moVV7r1+nne4F2LgufClHKqUbO1KFX6x0nedG0fpfB2udis6xCzlC6Hf1/l2qyaafbdRLMVnx7cr2mtet/gfR31kfUdq9HaXd/gL83Wflu0f7WCbqXmK7hX5YMveFfLcHF9sZUe71qEA6Z0082+0scBoAoI6bKpEuJ6ojj7szSt2Q5vi/iv291gaYejLPV4X5AfEPD75jX33WkrpTn/QeAq/xjv1s6MbJu7ekeB1nPFVGq9Pa1tPRfEn9As0aVSlycFdAvW7fIH+ErrD4wQlJ7du2Uda1u/tu1Iz3Rp8C5YT8ss0tpcmgBdfZUD+y8n1PSuNeK8246NtoYJ3iBe6fIaCyBUxzj4das3uFfrfNOkmi6A79gwPmQ/EypWSKbcV0YhVchrkLV1s81Wfm626nOzLRrt21N0tG+lPvsCeC3qXxtIXwOl3y+aZLb4PwX7lysdXgF5l0vM4hsWTcX+8W1vi7xazp0ws3YDvIG8WvoPV7unwc02fp8/4NeX3sclpXL7BgPT5/EF71rUr50WYQBVWEiVTSGA6wnRbfDybftc8K4gfs7qnS649VHQ1b1ZkmshViqz5qh26wM5bh14bHnSSOzeAD7ZpcHXrXVsB2/emZ7lBoTzBfiHGzFcI8VrJPj6tWtYPbeOcYG41vosvsBdaeRx0RFVKkUaKE8E9NWhkNevSynzK2d6A3i1bhdON1daeVNf8N7L28J+JIO4KcBWKryC+18/OTgvugbfUou5gnu1hi/4P7Mf/mWWuedgv+kTrjLrNdzbX7qsNL3Y2tne1vs1s7wjX2sKNl/wrpGt6YsNoJqp1GVTCOJ6Vl8KxDW4mQJ4LYWDVbUKu3T2dvXspDZ1Xav7odLjfUG+N9DPX+/PcfOd++LWwPA1MJYNy3/Gt08DmakFV+nulSXo9abnq9Ij1aWO16sV40bIV/DuXceUe7cDoLpKI6CvooX83q3e4N3XCu+mZQqg6bVan2HW+rdmLU7xDpJVXjT90s/vmi2abLZ+TvHHaOortcZ3u6J8B9UDAFTesinEcT1Dm25ffQOAKXBOz8qxjEzfOsfStS/TG1T71hpMTANu/bwprcDI8Aqie7eq6wJ4La3rxRGcAgiKkBwUD4dKo5/pDeI1unggzYWswL1VfhBfr33Fjeis+ZN7XutdNLjeon97U+w1R3brfma/GeFdk+4OAACOgR/W7bKHPvjFTdlWVgraT29X305vX8/1DQ/1+dgBVF8E9JWBkiTU/3zFDLOVM7xp5gXS6MO8Ke4K3tUS37T3sZ1D2Ucjl/cdbXb6vd7zY8A5AABwjGgas8enLbN3f9jon+pLfbPjYiItNjrCrdU/O9a3jo60uBjvulb+MVof1zjBjeQNAFUBAX2w7N/t7SPugviZZnvWF02jb/Nbbyu8RnvXvMqVhbIBCOYBAMAxGnn+pa9W2cQvV9r+7Fy37+LuTezuAe3dwGsAUJ0R0B8rmj9980JvAK9F08l5vIWSfyT65ieZteln1qa/Wb0OFZdGDwAAEAL95N//cZM9+vFS/8B1PZon2djzOtnxTRKDfXoAUCkQ0Fe0n94xW/aRty984fngk9t5+58riG9+slk06V8AACB0pe7LtPCwMKsTdwSz65TQT37cB7/YD/n95DXy/JhzO9jALg0ZsA4AAhDQVzSNDq8p4CQm3qzlad4WeAXxic2CfXYAAABHZf3ODJu2eIt9tHizPwBvlFDD9VX3LvFurWnOjrSfvPq939S3tV13aisGrgOAYhDQVzRN5ZZyvDeIb9LDLKLkuUwBAABCwerUdPvop80ukP9p454iz2/ac8At0385ONWu5ivv0jjBOjdOcGsF+inxNVyLO/3kAaBsCOgrWucLvQsAAEAIW751r3300xb7ePFmW7plr39/eJhZr5Z17NwuDW1A5xTXqv7LpjQX6P+cv165fZ9t25tpM5Zuc4tPcq1o69wowX7dutffT75niyQb+7vO1qVJQlA+JwCEEgJ6AAAAFDso3ZLNe10A//HiLbZi2z7/cxHhYXZS67p2znEN7azODSy5VsHpdHu3qusWn4ysHFuyOc1+2rDHFm9Ks8Ub99jybfssdV+Wffnrdn8/+T+e29HO7ZJCP3kAKCUCegAAAPjl5Xnsvz9utOdnrLBVqen+/Zr3/dS29ezs41LszI4NLOkIBr7TXPDdm9dxi8+B7FwX5Cu4j44Mtwu6NaafPAAcIQJ6AAAAOPPW7LS/fPCL/bjB2y8+JjLcTm9Xz6XT/7ZjfYuvUX5jASl4P6FZklsAAGVDQA8AAFDNrduRYY9NW2of/rTZbcdpdPkz2tiwk1pYrRhuFwGgsuJ/aAAAgGoq7UC2TZi5wl77Zo1l5ea5Ae4u69nU7jizvdWrXbBfPACg8iGgBwAAqGZycvNs0rz19vSnv9qO9Cy375Q2yfangR2tY8P4YJ8eAKCUCOgBAACqEY0q//CHv9ivW72j1reqF2d/HtjRzmhfn9HlASDEENADAABUk3nk//LhEv80cYmxUXZ7/3Z2Re9mFhURHuzTAwCUAQE9AABAFbYt7YA9N3O5vT13veXmedz0c8P6tLBRv21rCbHlN2o9AODYI6AHAACogn7dutf+8dUq++/CTW7AOxnQuYGNPqejtUyOC/bpAQDKAQE9AABAFeHxeOzblTvspa9W+VPrpXvzJLvrrPbWp3XdoJ4fAKB8EdADAACEuOzcPPtg0Sb7x1er7ZfNaW6fpqA7+7gUu+7UVnZis6RgnyIAoAIQ0AMAAITwPPKT5q5z88hv3nPA7asZFWGX9mhifzilpTWvS2o9AFRlBPQAAAAhZuPu/fbarNVuLvl9mTluX3KtGLvm5BZ2Ze9mlhgbHexTBAAcAwT0AAAAIWLJ5jR78YuV9uFPm92I9dK2fi0bfmoru+CERhYTGRHsUwQAHENMOgoAAI7KhAkTrEWLFlajRg3r3bu3zZ07t8Rj+/bta2FhYUWWgQMH+o+5+uqrizx/9tlnF3idnTt32pVXXmnx8fGWmJho1157re3bt8+qqtR9mTZm6k927nNf2/s/bnLB/Emt69pr1/S0T247zS7t2ZRgHgCqIVroAQBAmU2ePNnuuOMOmzhxogvmn3nmGRswYIAtW7bM6tevX+T4qVOnWlZWln97x44d1rVrV7vkkksKHKcA/rXXXvNvx8TEFHhewfzmzZvt008/tezsbLvmmmvs+uuvt7feesuqkqycPPvn7DX27GfLbW9+av25XVLspr5t7LjGCcE+PQBAkBHQAwCAMnvqqads+PDhLqAWBfYffvihvfrqqzZ69Ogix9epU6fA9qRJkyw2NrZIQK8APiUlpdj3XLJkiU2bNs3mzZtnPXr0cPuef/55O/fcc+2vf/2rNWrUyKrC9HMzl26zhz9cYqtS092+zo3i7f7zOluvlgWvIQCg+iLlHgAAlIla2ufPn2/9+/f37wsPD3fbs2fPLtVrvPLKKzZkyBCLiys4GvsXX3zhWvjbt29vI0aMcC35Pnptpdn7gnnRe+q958yZU+z7ZGZmWlpaWoGlslqxba8Ne22eXfvG9y6YT64VbY8N7mLvjzyFYB4AUAAt9AAAoExSU1MtNzfXGjRoUGC/tpcuXXrYn1df+8WLF7ugvnC6/UUXXWQtW7a0lStX2h//+Ec755xzXCAfERFhW7ZsKZLOHxkZ6Vr/9Vxxxo8fbw8++KBVZrszsuyZz5bb/3231vWRj4oIsz+c3NJG/raN1a4RFezTAwBUQgT0AAAgKBTId+nSxXr16lVgv1rsffT88ccfb61bt3at9v369SvTe40ZM8b19fdRC33Tpk2tMsjJzbO3566zJz/91XZnZLt9Z3ZqYH86t6O1SGYeeQBAyQjoAQBAmSQnJ7sW861btxbYr+2S+r/7pKenu/7z48aNO+z7tGrVyr3XihUrXECv1962bVuBY3JyctzI9yW9r/rkFx5YrzKYtTzVHvrgF1u2da/bbteglo39XWc7pW1ysE8NABAC6EMPAADKJDo62rp3724zZszw78vLy3Pbffr0OeTPTpkyxfVrv+qqqw77Phs2bHB96Bs2bOi29dq7d+92/fd9Zs6c6d5bI+2Hgp3pWXbD/31vV70yxwXzibFRNu6CzvbRLacSzAMASo0WegAAUGZKYx82bJgboE6p85q2Tq3vvlHvhw4dao0bN3Z92Aun2w8aNMjq1q1bYL/mkldf98GDB7vWdvWhv+eee6xNmzZuOjzp2LGj62ev0fU1qr6mrRs5cqRL1Q+FEe7nr91lI99aYJv3HLCI8DD7/W+a223921pibHSwTw0AEGII6AEAQJlddtlltn37dhs7dqwbkK5bt25uSjnfQHnr1q1zo88H0hz1s2bNsunTpxd5PaXwL1q0yN544w3XCq8A/ayzzrKHHnqoQMr8m2++6YJ4peDr9VUB8Nxzz1lln4ru1W/W2PiPllhOnsdaJsfZhCtOtE6N4oN9agCAEBXmUemCAjRQTkJCgu3Zs8fi4ylkAQDBR9kU2tcz7UC23TNlkU372TsK/8DjG9qjF3Vh9HoAwFGVTbTQAwAAVKDFG/fYzW8tsLU7MtxUdH8e2MmG9mluYWFhwT41AECII6AHAACoAEqCfHvuenvgfz9bVk6eNU6saROuPNG6NU0M9qkBAKoIAnoAAIBylpGVY39+d7FN/WGj2+7Xob49eWlXBr4DAJQrAnoAAIBytHzrXrvpzQW2fNs+N4r9XWe1txtOa2Xh4aTYAwDKFwE9AABAOXnvh402ZupPtj871+rXjrHnLz/BercqODUfAADlhYAeAADgKB3IzrVxH/xib81Z57ZPal3Xnh1ygtWrfXCqPQAAyhsBPQAAwFFYuyPdpdj/vCnNNHD9qDPa2K3927l0ewAAKhIBPQAAwFF4c846F8wnxUbZM0NOsNPb1Qv2KQEAqgkCegAAgKNw51ntLD0zx24+o401SqwZ7NMBAFQjBPQAAABHISYywh6+sEuwTwMAUA2FB/sEAAAAAADAkSOgBwAAAAAgBBHQAwAAAAAQggjoAQAAAAAIQQT0AAAAAACEIAJ6AAAAAABCEAE9AAAAAAAhiIAeAAAAAIAQVCkC+gkTJliLFi2sRo0a1rt3b5s7d26Jx/bt29fCwsKKLAMHDnTPZ2dn27333mtdunSxuLg4a9SokQ0dOtQ2bdp0DD8RAAAAAABVPKCfPHmy3XHHHXb//ffbggULrGvXrjZgwADbtm1bscdPnTrVNm/e7F8WL15sERERdskll7jnMzIy3Ovcd999bq3jly1bZueff/4x/mQAAAAAAFScMI/H47EgUot8z5497YUXXnDbeXl51rRpUxs1apSNHj36sD//zDPP2NixY11wrxb54sybN8969epla9eutWbNmh32NdPS0iwhIcH27Nlj8fHxZfhUAACUL8qm8sX1BABUhbIpqC30WVlZNn/+fOvfv//BEwoPd9uzZ88u1Wu88sorNmTIkBKDedEFUVp+YmJisc9nZma6ixe4AAAAAABQmQU1oE9NTbXc3Fxr0KBBgf3a3rJly2F/Xn3tlXJ/3XXXlXjMgQMHXJ/6yy+/vMRajvHjx7uaEN+iDAEAAAAAACqzoPehPxpqndfgd0qnL44GyLv00ktNvQpefPHFEl9nzJgxrhXft6xfv74CzxoAAAAAgKMXaUGUnJzsBrTbunVrgf3aTklJOeTPpqen26RJk2zcuHGHDObVb37mzJmH7IMQExPjFgAAAAAAQkVQW+ijo6Ote/fuNmPGDP8+DYqn7T59+hzyZ6dMmeL6vl911VUlBvPLly+3zz77zOrWrVsh5w8AAAAAQLVsoRdNWTds2DDr0aOHS53XqPVqfb/mmmvc85pDvnHjxq6fe+F0+0GDBhUJ1hXMX3zxxW7Kug8++MD10ff1x69Tp46rRAAAAAAAINQFPaC/7LLLbPv27W7qOQXe3bp1s2nTpvkHylu3bp0b+T6Q5pWfNWuWTZ8+vcjrbdy40d5//333WK8V6PPPP7e+fftW6OcBAAAAAKBazENfGTE3LQCgsqFsKl9cTwBAZRNy89ADAAAAAICyIaAHAABHZcKECdaiRQurUaOG9e7d2+bOnVviser6FhYWVmQZOHBgscffeOON7nmNsRNI71f4NR599NFy/2wAAFRmQe9DDwAAQtfkyZPdALcTJ050wbwC7wEDBrjxburXr1/k+KlTp1pWVpZ/e8eOHda1a1e75JJLihz77rvv2nfffWeNGjUq9r01de3w4cP927Vr1y63zwUAQCighR4AAJTZU0895YJqzU7TqVMnF9jHxsbaq6++WuzxmnEmJSXFv3z66afu+MIBvQa5HTVqlL355psWFRVV7GspgA98rbi4uAr5jAAAVFYE9AAAoEzU0j5//nzr37+/f59mptH27NmzS/UamoZ2yJAhBYLxvLw8+/3vf2933323de7cucSfVYq9pq894YQT7IknnrCcnJwSj83MzHSDDQUuAACEOlLuAQBAmaSmplpubq5/qlkfbS9duvSwP6++9osXL3ZBfaDHHnvMIiMj7ZZbbinxZ/XciSee6Fr8v/32WxszZoxt3rzZZQwUZ/z48fbggw+W+rMBABAKCOgBAEBQKJDv0qWL9erVy79PLf7PPvusLViwwA10VxL12/c5/vjjLTo62m644QYXuMfExBQ5XgF/4M+ohb5p06bl+nkAADjWSLkHAABlkpycbBEREbZ169YC+7WtPu2Hkp6ebpMmTbJrr722wP6vv/7atm3bZs2aNXOt9FrWrl1rd955pxvZviQakE8p92vWrCn2eQX5mtM3cAEAINQR0AMAgDJRq3j37t1txowZBfq/a7tPnz6H/NkpU6a4fu1XXXVVgf3qO79o0SJbuHChf9Eo9+pP/8knn5T4ejpO/feLG1kfAICqipR7AABQZkpjHzZsmPXo0cOlzmvaOrW+a9R7GTp0qDVu3NilwhdOtx80aJAb1C6Qtgvv0yj3avFv376929aAe3PmzLEzzjjDjXSv7dtvv91VDiQlJVX4ZwYAoLIgoAcAAGV22WWX2fbt223s2LG2ZcsW69atm02bNs0/UN66detcy3kgzVE/a9Ysmz59epneU+nzStd/4IEHXCt/y5YtXUAf2EceAIDqIMzj8XiCfRKVjQbKSUhIsD179tDHDgBQKVA2lS+uJwCgKpRN9KEHAAAAACAEEdADAAAAABCCCOgBAAAAAAhBBPQAAAAAAIQgAnoAAAAAAEIQAT0AAAAAACGIgB4AAAAAgBBEQA8AAAAAQAgioAcAAAAAIAQR0AMAAAAAEIII6AEAAAAACEEE9AAAAAAAhCACegAAAAAAQhABPQAAAAAAIYiAHgAAAACAEERADwAAAABACCKgBwAAAAAgBBHQAwAAAAAQggjoAQAAAAAIQQT0AAAAAACEIAJ6AAAAAABCEAE9AAAAAAAhiIAeAAAAAIAQREAPAAAAAEAIIqAHAAAAACAEEdADAAAAABCCCOgBAKhmWrRoYePGjbN169YF+1QAAMBRIKAHAKCaue2222zq1KnWqlUrO/PMM23SpEmWmZkZ7NMCAABHiIAeAIBqGNAvXLjQ5s6dax07drRRo0ZZw4YNbeTIkbZgwYJgnx4AACglAnoAAKqpE0880Z577jnbtGmT3X///fbyyy9bz549rVu3bvbqq6+ax+MJ9ikCAIBDIKAHAKCays7Otn//+992/vnn25133mk9evRwQf3gwYPtj3/8o1155ZWlep0JEya4fvk1atSw3r17u5b/kvTt29fCwsKKLAMHDiz2+BtvvNE9/8wzzxTYv3PnTnd+8fHxlpiYaNdee63t27fvCK8AAAChLTLYJwAAOHpqSc3JybHc3NxgnwrKKCIiwiIjI13wWtGUVv/aa6/Z22+/beHh4TZ06FB7+umnrUOHDv5jLrzwQtdafziTJ0+2O+64wyZOnOiCeQXeAwYMsGXLlln9+vWLHK+++1lZWf7tHTt2WNeuXe2SSy4pcuy7775r3333nTVq1KjIcwrmN2/ebJ9++qmrmLjmmmvs+uuvt7feeusIrwYAhB7K/dAUUQFlPQE9AIQ4BUcKbDIyMoJ9KjhKsbGxri97dHR0hb6PAnUNhvfiiy/aoEGDLCoqqsgxLVu2tCFDhhz2tZ566ikbPny4C6hFgf2HH37oUvZHjx5d5Pg6deoU2NaAfPrchQP6jRs3ur79n3zySZHW+yVLlti0adNs3rx5LqtAnn/+eTv33HPtr3/9a7EVAABQVVDuh7bYci7rCegBIITl5eXZ6tWrXY2vghgVDseihRfl39KiG7Tt27e732fbtm1dy3lFWbVqlTVv3vyQx8TFxblW/EPROc+fP9/GjBnj36fz7t+/v82ePbtU5/LKK6+4igO9X+D3+ve//73dfffd1rlz5yI/o9dWmr0vmBe9p957zpw5LrugMI3iHziSf1paWqnODwAqE8r90OWpoLKegB4AQpgKBhXuTZs2dTW+CF01a9Z0LeVr1651v1f1R68o27Ztsy1btrgU+UAKhnWTGBgoH0pqaqpL92zQoEGB/dpeunTpYX9efe0XL17sgvpAjz32mEtJvOWWW4r9OZ174XR+Ha/Wfz1XnPHjx9uDDz5Yik8FAJUX5X5oq1kBZT2D4gFAFVCRrbmoer/Hm2++2davX19kv9Lc9dyxokC+S5cu1qtXL/8+tfg/++yz9vrrr5drq5OyCPbs2eNfivv8ABAqKPdDV3g5/+74JgAAUM388ssvbsq6wk444QT3XGklJye7Fv2tW7cW2K/tlJSUQ/5senq66z+v0ekDff311y6DoFmzZq7VXYtaMjQKv0bSF722jgmkwaE08n1J7xsTE+NGxA9cAAAIdQT0AABUMwpuCwfhokGWFECXlvpudu/e3WbMmOHfp1RQbffp0+eQPztlyhTXp/2qq64qsF995xctWmQLFy70L+onqv70GiBP9Nq7d+92rfk+M2fOdO9duBsBAABVGQE9ACDkqeW28DzlZfXFF1+4VG8FjFXVWWed5U9B99Hn1dzzGv3+SGjKun/84x/2xhtvuNHnR4wY4VrffaPea0q8wEHzAtPtNcJ+3bp1C+zX9nHHHVdgUX9Dtby3b9/eHdOxY0c7++yz3ej66of/zTff2MiRI93geoxwDwBVX3mW+6GOQfEAAEHRt29f69atW7kUyJq+LHCUdByapnY77bTT3Ej3SrMXtYRrMLv/+7//O6LXuuyyy9yIvWPHjnUD0ul3qinlfAPlrVu3rkh/Qc1RP2vWLJs+fXqZP8Obb77pgvh+/fq51x88eLA999xzZX49AEDFotyvGAT0AIBKO72LRlAvTQp4vXr1jsk5VRWNGzd2ae0Kin/88Uc36q5a1C+//PJi56Q/HAXWWkrKeChMLe36/ZbWmjVriuzTiPZvvfXWEZ4pAKCyotwvG1LuAaCKFYYZWTlBWY4kQLv66qvtyy+/dKOZK71di29U848//tj1y1Y/b7Xirly50i644ALX4lurVi3r2bOnffbZZ4dMvdPrvPzyy24+ck3ro7le33///TJf1//85z9uPnSdk97rySefLPD83/72N/cemn5G53nxxRf7n3vnnXfcSO4KmpVOrvnSlZIebGrZuP76623ChAmuxV6p8WUJ5gEAwUO5f/TlvioRNEBry5YtXVmtSmedZ2Gvvvqq/16gYcOGBSqy1W3thhtucOesewF1F/vggw/sWKCFHgCqkP3ZudZprHfgsGPtl3EDLDa6dMWKCspff/3VFXjjxo1z+37++We3Hj16tAswW7VqZUlJSW56sXPPPdcefvhhV4j+85//tPPOO8+lbWsk9JJozvHHH3/cnnjiCXv++eftyiuvdKOlq2X3SGjgtUsvvdQeeOABl17+7bff2k033eSCc92gfP/9926+dKWqn3TSSW6kdY3U7htkTq3eOg/dZOzdu9c9dyQ3QRVJI9orJV5z4QY6//zzg3ZOAIDSo9w/+nJfA6o2adLEDdaqsl3lvCq8FbSr/JcXX3zRjRnz6KOP2jnnnOPGoNH4Lb6f1z6V8f/617+sdevWrnzVLDCVNqDXRVYtiD64aEAapb116tTJffgjpdYBXXj1vevatav7BQTOSVu474VqdwrTL/3DDz90j3WjdP/997tBelRbcvLJJ7tfgmpqAADBl5CQ4EZIVy26b5qxpUuXurUK+sCB2VQQq2zweeihh+zdd991Ne8lpXmLgm0F0/LII4+4/tUqrzSY2pF46qmnXD/t++67z223a9fOFdQqt/QeCojV2v273/3OateuXaBfugJ6Tad20UUXuf2i1vpgW7Vqlatg+Omnn1x57qtg8M37rtYKAACqQ7kfFRXlKgN81FI/e/Zs+/e//+0P6P/yl7+46VNvvfVW/3HKHBBlD+h9NDCs7hFElRPHSpkC+iuuuMIF7ppaRkG4fgFKP1BfPG1rYJzSmjx5sqvtmDhxoptqRqkTAwYMcDUw9evXL3L81KlTC7Qk7Nixw/3CL7nkEv8+1czoF6gRd/UL0U2YXlM3YEqBAICqqmZUhKsxD9Z7l4cePXoU2N63b59rHVelrS9A3r9/vwukD+X444/3P1bArXnHC89dXhoqoJX6F0gVxSqvFPiqDFSwrsJbNw1afCl/Kp9UGaAgXuWQRpdXOr5aIIJJNyQqHzW9nNa6EVF5qpsVtZIAAEID5X75lPtqYFZKvd5D76V4UwP4iV5j06ZNrjwvjgaVVUO3L5gPiT70ixcv9regq+ZCqRNKTVBAr74QR9ryoWlnNBiPWvgV2OsmSBe0OKqxUa2Ob/n000/d8b6AXq0Musn685//7G7A9ItVmoZ+Ce+9915ZPi4AhAy1sCr9LRiLr3X3aBUetfauu+5yNfOqbVe6ugpOBciF08QLK9wfXOentLjyplb5BQsW2Ntvv+3S81SprUBeGWJKt1M5pf6BKuOUgaa+eatXr7ZgUsuDWkSSk5PdCPFaTjnlFBs/frzrPgAACA2U+0df7k+aNMm9p/rRa/YVvZ9iU9/7qV/9oRzu+UoZ0GdnZ7v+DL4UA19fuw4dOrhalNLSRVLfRA0Q5D+h8HC3rZuN0tA8tpp31vdF0E2SsgQCX1MpHmr9L+k1MzMzLS0trcACAKhYSr0rTWq3+qgpjU6t3irQVZlb3KjnFUVznvv6yQWek2riff3jNCKvyh1liGn0eJ3fzJkz/TcUatFXOt8PP/zgPrduVIJJ110VEaKgXpXeokwDZcgBAFBdyv1vvvnGjYGj8XHUZa5NmzZuYD4flZcahE9ZbcVRA/KGDRvcGAHBUKaUe6XXqyV94MCBruVB/RpENwQaSKC0UlNT3S/VN1etj7Z9fSoORSmCyhZQUO+jYN73GoVf0/dcYWqRCOw3AQCoeCoc58yZ4wppjWJbUi26xj9RdysNiKPgWN2oKqKlvSRKQ1c/OZV1GhRPlcMvvPCCG9leNIqt+qRrXnel0n/00Ufu/NQSr8+nGwCl2qsbmbY1Z7sqCYJJmXWark7p9qrwVkWEbrReeumlY9rvDwBQfVTWcr9t27Yuo/uTTz5x5aIGudU893rsoy4AN954oyvLfQPgqSJg1KhRdvrpp7t7gMGDB7vsc1UIKJbVuR/puD3HrIX+scces7///e9ugDoNPOAbtEADFZQ0mF1FUCCvWpujfc8xY8a4kQp9iwb9AwBULKW3qYVbqeiaT7akvnEqHBUoq/Zchbv6op944onH7Dz1XupeppQ8BcJKqVe6uloPJDEx0d14/Pa3v3WBuiq8lX6vym/13/vqq6/cwK1q0Vd3ME15p5uBYNJ5+G6O9FmU3Xbqqae6ygiNQQMAQHUp92+44QY3eK0q7VXJrTFl1FofaNiwYa5btyrzVb5rINzly5cXmN5Wlf+KjfX57rnnnmM2wGyYp4xz5+gElZoeOLCPalvUn724wexKSrnX8Zqjd9CgQQUumPoe/ve//y3xZzWHb6NGjdyNSOBog2ol0VQBSmv0DWQgqjnRdnFzChamz6U0fQX3uhkDgMrqwIEDLhhTLTKDflbt32dFl02abk9lenn1iazsKOsBhCLK/dB3oJzL+jK10GvkP/U79wXzmt9PNRYljUxfEqX3de/evUB/BLUYaLtPnz6H/FnNE6hzuOqqqwrs14VRP4vA19SFUXrH4V4TAICqTuPgqM+/uqwVHnS2ugTzAABUFWUK6DV6vPoZiFrSlZqgFEK1smu+9yOhKes0X7ymmNPUQCNGjHCt7xpZUIYOHepS4otLt9f7Fe6zr5uR2267zc0VqC4AmmNXr6HW/MAsAABA9aQ+cOq7V9yi56o6jQLcrFkz5poHAFQLN1bxcr9Mg+Jpep6nn37aPVa6vAacU4q7+g6ob6GC8tJSXwUNEKSf06B1SoufNm2af1A79a3QyPeBlAkwa9YsN61AcdRnQZUC119/vatw0FQ8ek3SUgAA6qqlfnzFqS6p13/605/sj3/8oxv4Ry3zAABUVeOqeLlfpj706veukftUw3/ppZe6gQHuv/9+N5icRvXNyMiwUEa/OgChgr50Vcux6kOvaXlWrFjh0u81VV3hOYBVcV/VUdYDCEWU+6HvQDmX9WVqoddQ/O+9956bG1DD+99+++1u/7Zt2ygUAQCo5OiCBgBA1VCmgF7p8VdccYUL5DVNj2+wOaXAq9YfAABUXsqqAwAA1TSgv/jii12/9M2bN/vnoJd+/fq5VnsAAAAAAFAJA3rR1HBaNmzY4LabNGlivXr1Ks9zAwAAFUCDzR5qijpGwAcAoAoH9JorXtPCaaq6ffv2uX21a9e2O++8042cW3hUegAAUHm8++67BbY1OJ5mq9EUsg8++GDQzgsAAByDgF5Bu+aBf/TRR+3kk092+zSN3AMPPOBG7Xv44YfL8rIAAJRaixYt7LbbbnPL4ag1WkEsg8F5XXDBBcV2p9OsNZMnT7Zrr702KOcFAEB5lPvVSZkCetXgv/zyy3b++ef79x1//PHWuHFju+mmmwjoAQAIQb/5zW/s+uuvD/ZpAACAUipTbvzOnTutQ4cORfZrn54DAAChZf/+/fbcc8+5ynkAAFCFA3qNbP/CCy8U2a99aqkHAASJx2OWlR6cRe9dSi+99JI1atTIjclSOBX8D3/4g61cudI9btCggdWqVct69uxpn332Wbldpp9++slNu1qzZk2rW7eua5X2jQkjX3zxhRvoNS4uzhITE133srVr17rnfvzxRzvjjDPc2DHx8fHWvXt3+/777y2UJCUlWZ06dfyLtvV5Xn31VXviiSeCfXoAgNKi3C/WU089ZV26dHHleNOmTV0WeWA5L99884317dvXYmNjXTk4YMAA27Vrl3tO5/n4449bmzZtLCYmxpo1a1Zps9DLlHKvDzdw4EB3kX1z0M+ePdvWr19vH330UXmfIwCgtLIzzB5pFJz3/uMms+i4Uh16ySWX2KhRo+zzzz93U56KMrymTZvmyhEVuueee64rPFWQ/vOf/7TzzjvPli1b5grVo5Genu4KbZVf8+bNs23bttl1111nI0eOtNdff91ycnJcX/vhw4fb22+/bVlZWTZ37lz/qPBXXnmlnXDCCfbiiy9aRESELVy40KKioiyUPP300wVGuddgtvXq1bPevXu7mxoAQIig3C+WyjVlnbVs2dJWrVrlAvp77rnH/va3v7nnVXbrPFSZ8Oyzz1pkZKQ7N98sL2PGjLF//OMfrrz0Tde+dOlSqzIB/emnn26//vqrTZgwwf/BLrroItfCodHvTz311PI+TwBAFaKg8ZxzzrG33nrLX7C/8847lpyc7Fq/VRArG8znoYcecoPavf/++y7wPhp6Tw3gqpsF1dz7Msx04/DYY4+54HzPnj32u9/9zlq3bu2e79ixo//n161bZ3fffbe/61nbtm0t1Fx99dXBPgUAQDVyrMv92wIGztNgeopRb7zxRn9ArwbqHj16+LdFA8PK3r17XZCve4Nhw4a5fbofUGBfpeahV8pE4bQDpSFq9HulVAAAgiAq1ltjHqz3PgJq6VYruApT1ca/+eabNmTIEFeoq6ZeM6d8+OGHrlZcrebq461g+mgtWbLE3TT4gnlRSr3S69QScNppp7mAV634Z555pvXv398uvfRSa9iwoTv2jjvucC36//d//+eeU6uDL/APFa+99ppLadS5B5oyZYplZGT4b2AAAJUc5X6xlEk+fvx41/iclpbmXk+V+SrjlGKvFvrCZWDgfUJmZqa/4qGyY8J4AKhKlEat9LdgLAEp3KWhFnGPx+MKb3XZ+vrrr11hL3fddZermX/kkUfcfhW86gun9PdjFfCqK9lJJ53kpnFr166dfffdd+453XD8/PPPruvZzJkzrVOnTkXmda/sdJOjVpHC6tev7645ACBEUO4XsWbNGpdlp7Hd/vOf/9j8+fNdZrn4Xk9j6JTkUM9VRgT0AICgqFGjhuuupRp69VVv3769nXjiif6BatRKfuGFF7oCPSUlxRXQ5UHp88ooU196H72fWgh0Dj7qJ68+dN9++60dd9xxLk3QRwH+7bffbtOnT3efQRUAoUQtHupXWFjz5s3LJQsCAIBglfvz5893WXdPPvmkm45VZfamTQWzGBTsz5gxo9ifV1c6BfUlPV/ZENADAIJGNfOqqdfo6r5ael9hOnXqVFdDr+D7iiuuKDIy7tG8p24qlFa+ePFiNwiOBur5/e9/70bXXb16tQvk1UKvke0VtC9fvtxVBCj9T335NAq+ntMNiAbWC+xjHwrUEr9o0aIi+3WtNeo/AAChWu63adPGsrOz7fnnn3cD4qmL3MSJEwsco3Je5bcGy1N5qNR8DXabmprq7hHuvfdeN4iextvRCPzK0lPX8pDvQ68alUPZvXv30Z4PAKAa0dRxmjZNfddVeAdON6ORZ5XyrtRwFazqA1ce1Hfuk08+sVtvvdVNi6PtwYMHu/f0Pa+C/Y033rAdO3a4vvM333yz3XDDDa4PnvYNHTrUtm7d6s5NZeODDz5ooeTyyy+3W265xU1VpzED5Msvv3TXRP0ZAQAI1XK/a9eu7vU00K0Cd5Vz6mqmsttHrfaqsP/jH//opqlVi7xmelH5KPfdd58b+X7s2LGudV/3AhpUrzIK86gjQyldc801pTou1FIPC9OXJyEhwY1yrDmGAaCy0gAvalFW+rRqlFF1f5/lWTapD6EyEjQInm5YRC0hutlRK0Z0dLRVdZT1AEIR5X7oO1DOZf0RtdCHeqAOAADMBewa7E/T+Ci9US0T6rOoPvRlocGGnnjiCduyZYtrGVGao1o8itO3b1+XDVCY5h9WGqZv4MFJkya5QZN0rt27d3cz66j1JHAaInV7CKQWmNGjR5fpMwAAEIrKPG0dAACVgQbXUTp8cRSgakR6FE99FrUcDVUMaCo/tewr4H7mmWfclH9Kp1Rf/cLURzJw1GJ1YVAlQOD0QUqF1Py/rVq1cuMWPP3003bWWWfZihUrrF69ev7jxo0b56ZA8lEXAgBA1Ua5XxABPQAgpJ1//vkFWm4DRUVFHfPzCQUaM0At6OqjGOjxxx93gwQpFb+01E9RQbWvW54Ce9+AR8W1lqvvZCC1xGvcgsCAPrBfpe89NBiRBi4KnBdYAbxGQgYAVB+U+wUR0AMAQpqCOlpmj8xXX33l0toLO+ecc9w0P6WllnZND6RBh3w0/V///v3dLAGloUBdA/HFxcWV+B4vvfSS61OolvxAjz76qD300EPWrFkzVwmgqQR9YwIUlpmZ6Raf8hpkEQBwbFHuF0RADwBVwBGMb4pK7Fj9Hvft21fswHdq2TiSQFfT++Tm5rrp/gJpWzMFHM7cuXPd1IHFTQX0wQcfuEA/IyPDjS786aefupGPfTRKv+YvVov/t99+6yoVNm/e7J+toDD1rw+12QgAoCSU+6HLU86/O+ahB4AQ5kstU9CD0Of7PVZ0yqAGwFPf98KU/t6pUyc7VhTI61yKG0DvjDPOcAP2KVg/++yz7dJLL7Vt27b5n1e/fQ2wd/zxx7uphJRZoMH4AlvhAyng16jBvkUD7gFAqKHcD30Z5VzW00IPACEsIiLCEhMT/YGO+iKHhYUF+7RQhtp6FfD6Per3qd9rRdL8uhdddJGtXLnSzQksM2bMsLfeesveeeedUr+OWsx1rlu3bi2wX9uH69uenp7uKhA0sF1xlILfpk0bt/zmN79xg/epAiAwvT+Q+lPm5OTYmjVrrH379kWej4mJcQsAhDLK/dDlqaCynoAeAEKcL3AKbL1EaFIBfywGeTvvvPPsvffes0ceecQF8Jq2Tv3TZ86cWWTQukPxTSmnyoBBgwb557PX9siRIw/5sxp4T63pV111VaneS69bUuu7qDVf/feLG1kfAKoSyv3QlljOZT0BPQCEONXMq4+xApns7Oxgnw7KSKl3Fd0yH2jgwIFuEfWbf/vtt+2uu+5yg9ypX3xpKfV92LBh1qNHD5c6r2nr1PruG/V+6NCh1rhxY9eHPZBa21UJULdu3QL79bOac16jGOt7rX76mud+48aN/pHwNeDenDlzXFq+BkbStgbEU+VAUlJSOVwdAKi8KPdDV1QFlPUE9ABQRaiAOJYBIarGaPcKrP/zn/9Yo0aNXBq+gucjcdlll9n27dtt7NixtmXLFuvWrZtNmzbNP1DeunXrXMt5IM1RP2vWLJs+fXqR19N3WAPqvfHGGy6YV8Dfs2dP+/rrr61z587uGKXOK11fI/Wr1b5ly5YuoFflAgBUF5T7kDAPQyQWoZYKTY+jQXPi4+ODfToAAJRb2aSg+/XXX3eBvF5Tg81p7vgff/zxmA6IF2yU9QCAqlA2Mco9AADVhPrOa8C4RYsWudT4TZs2uZHhAQBAaCLlHgCAauLjjz9287ePGDHCjRoPAABCGy30AABUE+q3vnfvXjcyvaZ5e+GFF1w/dQAAEJoI6AEAqCY0n/s//vEP27x5s91www1uYDkNhqcp4T799FMX7AMAgNBBQA8AQDUTFxdnf/jDH1yL/U8//WR33nmnPfroo24KJE0XBwAAQgMBPQAA1ZgGyXv88cdtw4YNbi56AAAQOgjoAQCAm8t40KBB9v777wf7VAAAQCkR0AMAAAAAEIII6AEAAAAACEEE9AAAAAAAhCACegAAAAAAQhABPQAAAAAAIYiAHgAAAACAEERADwAAAABACCKgBwAAAAAgBBHQAwAAAAAQggjoAQAAAAAIQQT0AAAAAACEIAJ6AAAAAABCEAE9AAAAAAAhiIAeAAAAAIAQREAPAAAAAEAIIqAHAAAAACAEEdADAAAAABCCCOgBAAAAAAhBBPQAAAAAAIQgAnoAAAAAAEJQ0AP6CRMmWIsWLaxGjRrWu3dvmzt37iGP3717t918883WsGFDi4mJsXbt2tlHH33kfz43N9fuu+8+a9mypdWsWdNat25tDz30kHk8nmPwaQAAAAAAODYiLYgmT55sd9xxh02cONEF888884wNGDDAli1bZvXr1y9yfFZWlp155pnuuXfeeccaN25sa9eutcTERP8xjz32mL344ov2xhtvWOfOne3777+3a665xhISEuyWW245xp8QAAAAAIAqGNA/9dRTNnz4cBdwiwL7Dz/80F599VUbPXp0keO1f+fOnfbtt99aVFSU26fW/UB67oILLrCBAwf6n3/77bcP2/IPAAAAAEAoCVrKvVrb58+fb/379z94MuHhbnv27NnF/sz7779vffr0cSn3DRo0sOOOO84eeeQRl2bvc9JJJ9mMGTPs119/dds//vijzZo1y84555wSzyUzM9PS0tIKLAAAoPy7z/Xt29fCwsKKLL6KeHnggQesQ4cOFhcXZ0lJSe7eYM6cOQVeRxX8V155pcXHx7tMvWuvvdb27dtXoZ8TAIDKJmgBfWpqqgvEFZgH0vaWLVuK/ZlVq1a5VHv9nPrNq6/8k08+aX/5y1/8x6hlf8iQIe5GQK34J5xwgt12222u0C/J+PHjXUq+b2natGk5flIAAKouX/e5+++/3xYsWGBdu3Z13ee2bdtW7PFTp061zZs3+5fFixdbRESEXXLJJf5jND7OCy+8YD/99JOrlFdlwVlnnWXbt2/3H6Ny/eeff7ZPP/3UPvjgA/vqq6/s+uuvPyafGQCAyiLME6TR4jZt2uT6wCtFXq3uPvfcc499+eWXRWrifQX8gQMHbPXq1a7w96XtP/HEE+6mQCZNmmR3332326c+9AsXLnQBvY4bNmxYiS30WnzUQq+gfs+ePa7mHwCAYFPZpErnylY2qUW+Z8+eLgCXvLw8V4aOGjWq2O5zhWn8nLFjx7pyXC3yh/rsn332mfXr18+WLFlinTp1snnz5lmPHj3cMdOmTbNzzz3XNmzYYI0aNQrZ6wkAqL7SylA2Ba0PfXJysgvKt27dWmC/tlNSUor9GY1sr1Z3XzAvHTt2dC36SuGPjo52wbyvlV66dOniBs5TK3xJAb1Gy9cCAACOvPvcmDFjSt19rrBXXnnFldklBfN6j5deesnd4Kj1X/TaSrP3BfOi99R7q0HgwgsvLFXlPQAAoS5oKfcKvrt37+76u/uoVl/bgS32gU4++WRbsWKFO85HfeUV6Ov1JCMjwxXogVQBEPgzAAAgON3nAqmvvVLur7vuuiLPKY2+Vq1arl/+008/7VLr1Rggeu3Cs+FERkZanTp1SnxfutcBAKqioM5Drz53//jHP9wUc0qfGzFihKWnp/tHvR86dGiBWn89r0Fwbr31VhfIa0R8DYqnQfJ8zjvvPHv44Yfdc2vWrLF3333XpdsXV1sPAACCR63zyqTr1atXkefOOOMM121OXfPOPvtsu/TSS0vsl18aup9QCqNvWb9+/VGePQAA1Xzaussuu8wNcKO+c6pR79atm+sD56vpX7duXYHWdtWmf/LJJ3b77bfb8ccf7/rgK7i/9957/cc8//zzbrC8m266yRX86kd3ww03uPcAAADB7T7nowp8jXszbty4Yp9XCn6bNm3c8pvf/Mbatm3rKgAUmOu1Cwf3OTk5rtK/pPelex0AoCoKakAvI0eOdEtxvvjiiyL7lI7/3Xfflfh6tWvXdgPsaAEAAMem+9ygQYMKdJ8rqWz3mTJliuvTftVVV5XqvfS6vj7wuhfYvXu367+v95eZM2e6YzRIHwAA1UXQA3oAABC61H1Og85qgDqlzqtCvXD3OWXUqQ97ILW2qxKgbt26BfbrZ9V17vzzz3dj5Kifvua537hxo39qOw2IqzT84cOH28SJEy07O9tVIGhwvdKMcA8AQFVBQA8AAI5Z9zlZtmyZm19++vTpRV5PKfxLly514+somFfAr2nxvv76azcdrc+bb77pgnhNY6fXHzx4sD333HPH4BMDAFB5BG0e+sqMuWkBAJUNZVP54noCAKpC2RTUUe4BAAAAAEDZENADAAAAABCCCOgBAAAAAAhBBPQAAAAAAIQgAnoAAAAAAEIQAT0AAAAAACGIgB4AAAAAgBBEQA8AAAAAQAgioAcAAAAAIAQR0AMAAAAAEIII6I+B3RlZwT4FAAAAAEAVQ0BfgTwej7389So79bHPbcnmtGCfDgAAAACgCiGgr0Aej9nXy1Ntb2aOjfjXfNuzPzvYpwQAAAAAqCII6CtQeHiYPXNZN2ucWNPW7Miwu6b86FrtAQAAAAA4WgT0FSwpLtr+duWJFh0Rbp/+stUmfrkq2KcEAAAAAKgCCOiPga5NE+2B8zu7x098stS+XZEa7FMCAAAAAIQ4Avpj5PJeTe3i7k0sz2M26u0fbPOe/cE+JQAAAABACCOgP0bCwsLsL4OOs44N421Hepbd9OYCy8rJC/ZpAQAAAABCFAH9MVQjKsImXnWi1a4RaT+s222PfLQk2KcEAAAAAAhRBPTHWPO6cW7ke3n92zX234Ubg31KAAAAAIAQREAfBP06NrCRZ7Rxj0f/5ydbtmVvsE8JAAAAABBiCOiD5PYz29kpbZJtf3aujfjXfNt7IDvYpwQAAAAACCEE9EESER5mzw7pZo0Satiq1HS7e8oi83g8wT4tAAAAAECIIKAPorq1YmzClSdaVESYTft5i/3j61XBPiUAAAAAQIggoA+yE5ol2djzOrvHj01bZt+t2hHsUwIAAAAAhAAC+krgqt7N7KITGltunsdGvvWDbU07EOxTAgAAAABUcgT0lUBYWJg9fGEX65BS21L3ZdrNby6w7Ny8YJ8WAAAAAKASI6CvJGpGR9iLV3W32jGR9v3aXfbIR0uCfUoAAAAAgEqMgL4SaZkcZ09e2tU9fu2bNfbEJ0tt+97MYJ8WAAAAAKASIqCvZM7qnGI39W3tHk/4fKWd/OhMu33yQlu4fnewTw0AAAAAUIkQ0FdCdw9o7+ao79o00bJy8+zdHzbaoAnf2AUTvrF3f9hgmTm5wT5FAAD8JkyYYC1atLAaNWpY7969be7cuSUe27dvXzd2TOFl4MCB7vns7Gy79957rUuXLhYXF2eNGjWyoUOH2qZNmwq8jt6v8Gs8+uijFf5ZAQCoTMI8Ho8n2CdR2aSlpVlCQoLt2bPH4uPjg3ouapn/57dr7INFm11wL8m1YuyKXk3tyt80twbxNYJ6fgCA6lc2BZo8ebILuCdOnOiC+WeeecamTJliy5Yts/r16xc5fufOnZaVleXf3rFjh3Xt2tVefvllu/rqq93nu/jii2348OFu/65du+zWW2+13Nxc+/777wsE9Ndee607zqd27dquEiCUrycAoPpKK0PZREAfIoW8+tJPmrvO/jVnrW1N8/arjwwPs7OPS7GrT2ph3ZsnudYJAEDVVBnLJlEQ37NnT3vhhRfcdl5enjVt2tRGjRplo0ePPuzPqwJg7Nixtnnz5hKD8Xnz5lmvXr1s7dq11qxZM39Af9ttt7mlKl1PAED1lVaGsomU+xBRr3aMjerX1mbd+1t74YoTrGeLJMvJ87iW+4snzrbfPT/L/v39ejuQTTo+AODYUEv7/PnzrX///v594eHhbnv27Nmleo1XXnnFhgwZcsiWdd3YqNI6MTGxwH6l2NetW9dOOOEEe+KJJywnJ6fE18jMzHQ3SoELAAChLjLYJ4AjExURbr87vpFbFm/cY/+cvcb+u3CT/bwpze55Z5GN+98vdlbnBnZ+10Z2cptkdzwAABUhNTXVpcI3aNCgwH5tL1269LA/r772ixcvdkF9SQ4cOOD61F9++eUFWituueUWO/HEE61OnTr27bff2pgxY1wr/1NPPVXs64wfP94efPDBI/p8AABUdqTcV4E0vF3pWTZp3nr713drbePu/f79deKi7ZzjUlxw37NFHQsPJyUfAEJVZSybNFBd48aNXUDdp08f//577rnHvvzyS5szZ84hf/6GG25wLfmLFi0q9nkNkDd48GDbsGGDffHFF4f83K+++qp7vX379llMTEyxLfRaAq+nugZUpusJAKje0spQ1tNCXwUkxUXbiL6t7YbTWtn8dbvs/YWb7KOfNtuO9Cx7c846t6TE17DfHd/Qzu/WyLo0TqC/PQDgqCUnJ1tERIRt3bq1wH5tp6SkHPJn09PTbdKkSTZu3LgSg/lLL73U9ZufOXPmYW9s1JdfKfdr1qyx9u3bF3leQX5xgT4AAKGMfOwqRC3waol/aNBxNueP/eyff+hll3RvYrVrRNqWtAP28qzVdv4L39gZf/3Cnpy+zH7dujfYpwwACGHR0dHWvXt3mzFjhn+fBsXTdmCLfXE0Er5azK+66qoSg/nly5fbZ5995vrJH87ChQtd//3iRtYHAKCqooW+ioqMCLfT2tVzy18uPM6+XLbd3v9xk322ZKut2ZFhz89c4ZYOKbXtkh5N3Uj5EaTkAwCO0B133GHDhg2zHj16uJHoNWq9Wt+vueYa97ymtFNavvqwB1K/+UGDBhUJ1hXMa9q6BQsW2AcffOD66G/ZssU9p/7yqkRQmr7S+c844ww3VZ22b7/9dlc5kJSUdAw/PQAAwUVAXw3EREbYWZ1T3JKemeOC+v/9uMm+/HW7Ld2y1x764Bf3+Lkh3SwxNjrYpwsACCGXXXaZbd++3U09p8C7W7duNm3aNP9AeevWrXMt54E0R/2sWbNs+vTpRV5v48aN9v7777vHeq1An3/+ufXt29elzitd/4EHHnCt/C1btnQBvSoXAACoThgUL0QGHqoIezKy7b2FG+3Rj5fa/uxca1Yn1l4a2t06pFTdzwwAoaq6lE3HCtcTAFDZMA89jkhCbJQNO6mF/WfESdYkqaat25lhF/3tW/tw0eZgnxoAAAAA4DAI6GGdGsXb/0aeYqe0SbaMrFy7+a0F9ti0pZabR/IGAAAAAFRWBPTwT333+jU97frTWrntF79Yade8Ps+l5QMAAAAAKh8CehQYGf+P53a0Z4d0sxpR4fbVr9vt/AmzbNkWprcDAAAAgMqGgB5FXNCtsb9f/dodGXbh376xj36iXz0AAAAAVCYE9ChW50YJ9v7IU+zkNnVdv/qb3lxgj9OvHgAAAAAqDQJ6lKhOXLS9cU0vG35qS7f9ty9W2rVv0K8eAAAAACoDAnoctl/9nwZ28ver/2LZdrtgwiz7dSv96gEAAAAgmCKD+u4IqX71revVshv+b76t2ZFhF7zwjf22Q307pW2ym+6uaZ3YYJ8iAAAAAFQrBPQoteMaJ9j/Rp1iI99aYN+u3GEf/rTZLdKsTqw/uO/Tqq6bBu9opGfm2OrUdDcoX+v6cdYhJb6cPgUAAAAAVA0E9DjifvX/ura3LVi3y2atSLVvVqTaD+t227qdGfbWnHVuCQszO65Rgj/A7948yWpERRR5rZzcPNuwa78L3Fdu3+fWq7an26rUfbY1LbPAsed2SbE7zmxnberXPoafFgAAAAAqrzCPxxPUYcsnTJhgTzzxhG3ZssW6du1qzz//vPXq1avE43fv3m1/+tOfbOrUqbZz505r3ry5PfPMM3buuef6j9m4caPde++99vHHH1tGRoa1adPGXnvtNevRo0epziktLc0SEhJsz549Fh9Py/Dh7MvMsTmrdvgD/F+37ivwfExkuPVqWcd6tahj+7JyXNDubX1Pt+xczyErDxol1rCfN6WZvqXhYWYXntDEbuvflhR/ANUOZVP54noCAKpC2RTUFvrJkyfbHXfcYRMnTrTevXu7wHzAgAG2bNkyq1+/fpHjs7Ky7Mwzz3TPvfPOO9a4cWNbu3atJSYm+o/ZtWuXnXzyyXbGGWe4gL5evXq2fPlyS0pKOsafrvqoFRNp/To2cItsSztg36xMtVnLFeRvd63tXy9PdUthCvZbJsdZq3px3nVyLWtZT+s4S4z1pu0v27LXnvp0mX3y81b7z4IN9v6PG+3yXs1s5BltrH58jWP+eQEAAADAqnsLvYL4nj172gsvvOC28/LyrGnTpjZq1CgbPXp0keMV+Ks1f+nSpRYVFVXsa+rnvvnmG/v666/LfF7U2pcffb2UTj9reaotWLfbtboHBvCNEmpauJreS2Hh+t325PRl/ooBjbp/9Ukt7cbTW/mDfwCoqiibyhfXEwBQFcqmoAX0am2PjY11Le2DBg3y7x82bJhLq//vf/9b5GeUVl+nTh33c3pere9XXHGFS6+PiPD20e7UqZNr5d+wYYN9+eWXrhX/pptusuHDh5d4LpmZmW4JvJCqWKCQr5y+XZlqT3yyzPXdl9oxkXb9aa3sD6e0tLgYhoUAUDURgJYvricAoCqUTUGbhz41NdVyc3OtQQNvmraPttWfvjirVq1yFQD6uY8++sjuu+8+e/LJJ+0vf/lLgWNefPFFa9u2rX3yySc2YsQIu+WWW+yNN94o8VzGjx/vLpxvUTCPyuuk1sk2dcRJ9sqwHtYhpbbtzcyxJz/91U57/HN7ddZqO5CdG+xTBAAAAIAKF7QW+k2bNrnW82+//db69Onj33/PPfe4lvU5c+YU+Zl27drZgQMHbPXq1f4W+aeeesql4W/e7J0+LTo62g1+p9f1UUA/b948mz17drHnQgt96MrL89j/Fm2ypz/91dbsyHD7GibUsOGntrKeLepYu5RaFhNZdIR9AAg1tCiXL64nAKCyCalB8ZKTk11QvnXr1gL7tZ2SklLszzRs2ND1nfcF89KxY0fXoq8UfgXzOkZp94F0zH/+858SzyUmJsYtCD3qf39Bt8Z2bpeG9s78DfbsZ8tt854DNu6DX9zzURFh1j6ltnVpnGDHNU5wa20T5AMAAAAIdUEL6BV8d+/e3WbMmOHvQ69B8bQ9cuTIYn9Go9e/9dZb7rjwcG9vgV9//dUF8Xo93zEaJT+QjtH0dqi6oiLC3cj3F57Q2N6eu85mLt1mP23cY7szsm3xxjS3mK13x0aGh1m7BvlBfhNvkK/U/RpRBPkAAAAAQkdQRxDTlHUaBE8p8pp7XtPWpaen2zXXXOOeHzp0qEvLVx93UX94jYh/6623upHwNR3dI4884lLqfW6//XY76aST3P5LL73U5s6day+99JJbUPUpKL/m5JZuUW+SDbv22+KNe1xwr0WPd2Vk2y+b09wy+fuDQX5bF+TH+1vzOzaMJ8gHAAAAUGkFNaC/7LLLbPv27TZ27FiXNt+tWzebNm2af6C8devW+VviRf3aNdCdgvbjjz/eBfsK7jXKvY+mwXv33XdtzJgxNm7cOGvZsqWrKLjyyiuD8hkRPGFhYda0TqxbzunS0O1TkL9xd2CQr9b7PbYzPcuWbE5zy7+/3+COJcgHAAAAUJkFdR76yoqBcqoX/Qls2nPAftrgbcH3teTvSM8qcmyEP13/YJDfvG6cJcVGuQoEAKgolE3li+sJAKhsQmpQPKCyUCDeOLGmW84+LsUf5GtwPV9wv2jDwSC/cEu+1IgKt4YJNd0I+1o3SqxxcDv/cXyNyGKDfo3Uv3t/tu3Yl2mp+7JsR3qmpe7NdO/ltvd5H+ucWiTHWet6taxlcpy1qhdnLerGkTEAAAAAVFME9EAxFHg3SlRgXtMGdC4+yNf6501ptn1vph3IzrPVqeluKUlcdIQ1TPQG+cqLSc0P1JXun5tXukSZBet2FzpPs0YJNV1wHxjot6pXyxrG13CzAAAAAAComgjogaMI8iUzJ9e27Dnggv3Ne/bbpt3e9ebdB1wqvx5rtP30rFxbsW2fW4qTGBtldeOirW6tGEuuFW3JtWKsblyM1XWPoy03z2x16j5btT3dVqWm26rt+yztQI4bE0DL18tTC7yesgbUgq+led1Y1zWgRd1Ya1Y31mUMqPvA0crOzbMd+7JcpUZSXJTLcqDrAQAAAHBsENADR0lz2itY1lKSjKwcF/Ar8N+0e79FRoT5g/V6tWIsKS7aTb13JJQxoBb+1fnBfWCgv25nhssaWLplr1sKi44It6Z1auafd6wL+pvlrxWU78/OdUH6tr0H3LrAss+73rY302UXBGoQH2MnNkvyLs2T7LjG8e76AAAAACh/DIpXDAbKQajLyc1zU/atSt1na3dk5C/pbr1+V4Zl55bfn71a+uvERduu9CzLKdR1QBUHnRvHW/f8AF+BfkpCjXJ7b1Qcje2QlZtnmdl5brtWjchyyepA2VE2VeLruW+72Y7lZvU6mMXWKa9TRChKTzXbMM+7pG83q5ViFt/QrHbAElfPLGAWJ1RiCpPSNpptWWy29SezrT97H+/ZYFanlVmDTmb1O5k1OM77OL6xtz8kQktujtme9Wa7Vnt/t7UbmTU83qxW/WN+KgyKB8CJjAh3A+hpKUz99ZUl4IL8nd4gf01qun9bLftSu0ak1a8dY/XcUsNlEtSPj3Fr7fM9ToqNdn3192flunEF5q/dZQvW7bIFa3e5DIIf1u12i81a7V5XGQAnNEt0wX2nRvGum0FirJaoI85SqGz2Hsh23SsU+GraQ/0eDj7WOtwUE5fULUH1q5k5eXYgO9dlSeia6vehx25fVv7+7FzLzM61rFyPq7xR1wdV0uTk5VlOrsf/2K1z81xFi47xPpfn3kNdRdw6Oy8/cM/fzsmzLC3q41HMOBC1a0RZfM1It9Z3xG3XOLitx/E1oywuOtIiIsIsPCzMIsK01v2rdzvwsZ7T5XCPw8OsZlSExcVoibSYyPCj7sKhz7tnf7Zb9LtJy3+sa1InLsp9f5Utoy4jtWKKH7gSOKyVM83evd77WAGbAnvd5NfPX9drbxZT26qkvFyzA3vMMtPMDqR515E1vUFsrQZm4REVE2Rl7vUueo+IIN3O5mabbV1stuF7s/VzvUG8AoLDCY/0nrcL8BXwN/KuFUQo2Je8HDNPrneta6ylwLaez8tfe8xqNzBLamlWp6VZzaTy/6zZ+72BTs4Bs4SmZjUTy++1df6713mD5W0/m239xVtBFl3r4HUpcJ3yK0aiY61c5WSabV+aH7wvNtuiAH6x2f5dxR+vc9USqEaCWf3OAYF+Z++6xhFWGup3rGuuc9L3O7p2xVUC6frrvbIzzCJjzKLigl/hpL8tXfeMnWb7d3rXuZlmMfHe/0t9a13X6FJem6wMs11rvH+jO1eZ7Vyd/1hB/Hrv31Jh+p417GqWcrx3rSBf3/9Kdq9AC30xaAVBdeVL41dgc7Sj5+u1lPqv4N4F+Wt329ItaXao8f/0vgrsFWRprUA/qcA6yhJqRll0RIRFRYRZVGS4ywJQsKzKAD2OKrLtDRTLI1DTZ1JXA1V+6LOtU9bDzgz/duEuCCXxnZMCfJ2rzkyBtAJ1/kc+SBUhCuxVkeDWMZHuO+IC/mjvtpacwKB9/8GgXUtGVm6p30/fFwX2deJiXLDv1rEHt9U1Rt+/eFepcbAiIzry2Nz4UDZV4uv5w7/MvnjUe1NYkoRmZvU7Hgzy9Ti5nVlUTe8NtW7cFSz5lmyt82/ofTf22tb+sHBvJoBb6noXBT9l/X9O75+V7m1RztjhbWV2j1O9wboCdX/Qnr/te5xV/Lgwjs7T10LtgrFG+Y8be2+U3b6AwCwvz/v++7aY7d1qtm9rwOPAfVu9wYcvONYNtgJZX0DrX7cwiy65O9wR27vFG7S74P17s00/eH8nhalCp0kP73npXPVzaZu8a21bBf9HXyOxhOvR0nu9Cwc/+v0reNL3d/d671rBu4Js3z59Fwq/R1Jz7zVObB7wWEtTb2BYnP27zbb94g3eXQCvx7+YZe0tw+dMKJj5oO9WlL5LHu9nUoWHWwIfq7Lat52/1vddgXvqr8UHdWER3r/VFLXCH+dd6zPvWHmwAkKfRZUQxf28/++/g1lEdP7feKG/68LbRV4nzBu86rrrc/sWVaz49wU8p0oA93e7O/9vNn/ZH7gd8Di30P2LKuX0d6ng3q1jvX9Lbu17nP+c/gZ1jfT3ru+W/3H+urjn9Fl9gbrWBYL3XUf+fYjOD+59wb7vsa63vscK2vV/yKFExHi/wwmNvd/5HSuK/1tVhVmBIL+bN1ujnCpBylI2EdAXg5smoGLsy8yxRet3+1vx1+zIsF0ZWS7wqsj/iXSPGxsVYbGFAkLvY1+g6A0afftioyPcefm6LKzbme4fm+BQNBih7kmz8/KO6jMp6Felipaa+UuNaK3DvY+jIg5WXuRXDLjtcG9FR1R+hkDg89qO0RLlrezQWmMcqCVcawWm7nHAfu3T51D2wd4DOflLtqW5JWB7v3etbT2XnpnjKm+UEZLn8S3eVH7fYz2nIig3YNuXhVDelD2gYNy3qEJF372dbqrILFehUlb6fShrITDQ96692QztGtS2C7o1rtJl04QJE+yJJ56wLVu2WNeuXe3555+3Xr16FXts37597csvvyyy/9xzz7UPP/zQsrOz7c9//rN99NFHtmrVKveZ+/fvb48++qg1atTIf/zOnTtt1KhR9r///c/Cw8Nt8ODB9uyzz1qtWrWCdz11A719mTdIUUuf1tuWlnwjqRtb3UTqBv9og7zwqPzg3hfk1zGrGRjwx3lvlhW8uKB9e37gru3U/HM4CgoA3E10vDfYVvCqFuXSUCCiig2dU0kBUXEUHBzuPdQSrpttX1CrQEyBhr8CJX+tgCZwO8e3nb/o91pchY2CpyY9zZr08gbxjbsfuvVaqb3p28zSNpvt3VQw2Ne2fje+IEiBks7VBUz5AZIveHKPFRzlV77rNdTa6CoMDiGyhvca6FqoFdgXvB+qYiYwaIqM9p7jIYV5K2t8gb6+hwp2FfQqfb2k768yWXyt2qoUUWDrvz6bCz72VeiUN30XU7ocDNy11rlElaK7oL47qhRQgO8C/fxgX79XlIEqMRIO/l+m764qEl12Tn5GUF52xVV2Ze7zVvRsXmS2+UezLT+abVtS/P9RqlDV9+byt486Q4aAvpxU5psmoCpSIJeW37qqIGt3RpbtSvc91v4s26V1RpYLHJVGrZTwwDRypYkHpppXFKWLa6YDDSbYrE7+DAJ1vLMHNKsT61psfRS8KrXbpcLneSzXnd/B1Pjc/McKZmtEKmAvGKxXV7ou6Vk5lpGZ6yqB0n1LVq5bB+7bl5nrKj8UQCeUsOi5w/X/V0XCjvRM971zawX76dm2Mz3Tv9Zzab5Ki/3ZtjezdIFH3/b17PVrig9uq0LZNHnyZBs6dKhNnDjRevfubc8884xNmTLFli1bZvXrF+1/qEA8K+tga9COHTtcJcDLL79sV199tft8F198sQ0fPtzt37Vrl916662Wm5tr33//vf/nzjnnHNu8ebP9/e9/d5UA11xzjfXs2dPeeuutync91fLkD/CXeIN8PVaAXUSYN7jVzasWBRK+x75tBWK+lqzyCMYDg/K4ZO8Sm792rX5q8UrIb/lKOBi4+1oD9ViBXiCd475t3mBGwasLxHyPN3qDMu0rEpiFed9XgbhLS08JeKy1Uq7zt3W+eh1f2mzhtVogy5OCagWcLoDPX+q2CX56ciBlWiituLjroZbKQ1WAxNU3S2jibWFXdkFiM+/at0/fBdWQK9DRa+l9dq8127W24OPskqfwdfSavsDdl5Ke3NYs4mD5efguF2lFK0P03dLfgqsQ8S1hBbf1/fLvy18rGPMF8BXRB15//66Sb5l3u6S/6wLb+j8gxvtY6eeFW9R92wVa3AOOUcVRYEu+vzU/cF+hbVX66fopNV2/Q7fO8H6ntPgeF1hnHOz+4fF1DVHmQ25+l5D8tX87/7E+l7/SUeukgMf5a53Tobrs+DKbMvODfJdFtDdgOy2/i0iTg0H70Y5xovfT/+EK8F2Qv8jbRUOVTzEJZqPXHvX3h4C+nFTWmyYApaP/1hTU+wL+zFxv/3NvIFgwKPTvyyocKOZYrZio/Cn/vMG6ZgXQGADHKsUalb/iYV9+RoKyOVzWwn7vtgJ+ZTBo3bp+Lfv9b5pX2bJJQbwC6RdeeMFt5+XlWdOmTV3r+ejRow/786oAGDt2rAvO4+KKT4+eN2+ea/Ffu3atNWvWzJYsWWKdOnVy+3v06OGOmTZtmmvl37BhQ4GW/Ep7PXX7pRZppZ76b95reoOaI70h1E21C/B35C8Bqay+fboB102zWuvVT9sftOtx/r7yTE8v7TXQTbiCct14K0jXeZQ2sDscXYMCQe0asz3rvEGdu975AVNEwGP/ft9z0d7HCkIbnxjaYyH4Bv5S/2EF4Grtd8G7AvfG3u9huXyvU/ODe/VXXuP9PdRt5e1brq4m5dn/HqgMf1dKz1dFZZt+R/1yDIoHAC7FPsyiI8MCAu9yujkEAqjVP0HjOsRGWVOrntTSPn/+fBszZox/n9LflSI/e/bsUr3GK6+8YkOGDCkxmBfd2OjvOjHRGwjotfXYF8yL3lPvPWfOHLvwwguLvEZmZqZbAm+agkpBe3mNoOz6tMZ6W6JCia6BgruKCvB84wwoDR7eftVqqdRSod/ret5FXRCA6vB3VV9jo3QI2inQzAQAAMokNTXVpcI3aNCgwH5tqz/94cydO9cWL15s1113XYnHHDhwwO699167/PLL/a0Veu3C6fyRkZFWp06dEt93/PjxrtXDtyiLAACAUEdADwAAgkKt8126dClxAD31jb/00ktdN5oXX3zxqN5LWQRq6fct69cfYkR6AABCBCn3AACgTJKTky0iIsK2bi04sra2U1JSDvmz6enpNmnSJBs3btwhg3n1m585c2aBvoR67W3bthU4Picnxw24V9L7xsTEuAUAgKqEFnoAAFAm0dHR1r17d5sxY4Z/nwbF03afPn0O+bMaCV992q+66qoSg/nly5fbZ599ZnXr1i3wvF579+7drv++j4J+vbcG6QMAoLqghR4AAJTZHXfcYcOGDXMD1Cl1XqPWq/Vd08iJprRr3Lix68NeON1+0KBBRYJ1BfOatm7BggX2wQcfuD76vn7x6iOvSoSOHTva2Wef7aa203R5+pmRI0e6wfVKM8I9AABVBQE9AAAos8suu8y2b9/upp5T4N2tWzc3hZxvoLx169a50ecDaY76WbNm2fTp04u83saNG+399993j/VagT7//HPr27eve/zmm2+6IL5fv37u9QcPHmzPPfdcBX5SAAAqH+ahr4xz0wIAUAhlU/niegIAqkLZRB96AAAAAABCEAE9AAAAAAAhiIAeAAAAAIAQREAPAAAAAEAIYpT7YvjGCdSgBAAAVAa+MomxbMsHZT0AoCqU9QT0xdi7d69bN23aNNinAgBAkTJKI+Di6FDWAwCqQlnPtHXFyMvLs02bNlnt2rUtLCzsqGtZdLOwfv36aj8tDtfCi+vgxXXw4jocxLU49HVQca0CvlGjRkXmdUdwy3rh++vFdfDiOnhxHQ7iWnhxHcq/rKeFvhi6eE2aNCnX19Qvqjp/aQNxLby4Dl5cBy+uw0Fci5KvAy3zlbusF76/XlwHL66DF9fhIK6FF9eh/Mp6qvgBAAAAAAhBBPQAAAAAAIQgAvoKFhMTY/fff79bV3dcCy+ugxfXwYvrcBDXwovrEJr4vXlxHby4Dl5ch4O4Fl5ch/K/DgyKBwAAAABACKKFHgAAAACAEERADwAAAABACCKgBwAAAAAgBBHQAwAAAAAQggjoK9iECROsRYsWVqNGDevdu7fNnTvXqpMHHnjAwsLCCiwdOnSw6uCrr76y8847zxo1auQ+93vvvVfgeY1HOXbsWGvYsKHVrFnT+vfvb8uXL7fqdh2uvvrqIt+Rs88+26qa8ePHW8+ePa127dpWv359GzRokC1btqzAMQcOHLCbb77Z6tata7Vq1bLBgwfb1q1brbpdh759+xb5Ttx4441Wlbz44ot2/PHHW3x8vFv69OljH3/8cbX6LlQl1b2sr87lPWW9F2W9F2W9F2X9sS3vCegr0OTJk+2OO+5wUxIsWLDAunbtagMGDLBt27ZZddK5c2fbvHmzf5k1a5ZVB+np6e53rhu94jz++OP23HPP2cSJE23OnDkWFxfnvh/6w65O10FUqAd+R95++22rar788kv3H/Z3331nn376qWVnZ9tZZ53lro/P7bffbv/73/9sypQp7vhNmzbZRRddZNXtOsjw4cMLfCf091KVNGnSxB599FGbP3++ff/99/bb3/7WLrjgAvv555+rzXehqqCsr97lPWW9F2W9F2W9F2X9MS7vNW0dKkavXr08N998s387NzfX06hRI8/48eM91cX999/v6dq1q6e605/au+++69/Oy8vzpKSkeJ544gn/vt27d3tiYmI8b7/9tqe6XAcZNmyY54ILLvBUN9u2bXPX48svv/T//qOiojxTpkzxH7NkyRJ3zOzZsz3V5TrI6aef7rn11ls91U1SUpLn5ZdfrrbfhVBFWe9FeU9Z70NZfxBlvRdlfcWW97TQV5CsrCxXE6PUKp/w8HC3PXv2bKtOlFqmFKxWrVrZlVdeaevWrbPqbvXq1bZly5YC34+EhASXqlndvh/yxRdfuJSs9u3b24gRI2zHjh1W1e3Zs8et69Sp49b6/0I12IHfCaWrNmvWrEp/JwpfB58333zTkpOT7bjjjrMxY8ZYRkaGVVW5ubk2adIk13KhVLzq+l0IRZT1BVHeF0RZXxBlPWV9dS7rK7K8jyz1kTgiqamp7pfWoEGDAvu1vXTpUqsuVGi9/vrr7j9vpdI8+OCDduqpp9rixYtdv5rqSgW8FPf98D1XXSgFT6lFLVu2tJUrV9of//hHO+ecc9x/ZBEREVYV5eXl2W233WYnn3yyK8REv/fo6GhLTEysNt+J4q6DXHHFFda8eXMXGCxatMjuvfde1/du6tSpVpX89NNPrkBX6q36zb377rvWqVMnW7hwYbX7LoQqyvqDKO+Loqw/iLKesr66lvXHorwnoEeF0n/WPhoQQgW+/nj//e9/27XXXhvUc0PlMGTIEP/jLl26uO9J69atXU1+v379rCpSvzLd5FaH/qVluQ7XX399ge+EBpPSd0E3gfpuVBUKfFSYq+XinXfesWHDhrn+c0AoorzHoVDWV1/Vvaw/FuU9KfcVROkjqnEsPEqhtlNSUqy6Ug1Uu3btbMWKFVad+b4DfD+KUqqm/n6q6ndk5MiR9sEHH9jnn3/uBkrx0e9d6bu7d++uFt+Jkq5DcRQYSFX7TqhWvk2bNta9e3c3IrAGlHr22Wer3XchlFHWl4zynrL+UCjrq8f/75T1x6a8J6CvwF+cfmkzZswokHKibaVcVFf79u1zNW+qhavOlHKmP9TA70daWpobAbc6fz9kw4YNrl9dVfuOaJwgFWxKs5o5c6b7DgTS/xdRUVEFvhNKPVMf1Kr0nTjcdSiOarWlqn0nClMZkZmZWW2+C1UBZX3JKO8p6w+Fsr5q//9OWX+My/tSD5+HIzZp0iQ3kunrr7/u+eWXXzzXX3+9JzEx0bNlyxZPdXHnnXd6vvjiC8/q1as933zzjad///6e5ORkN9plVbd3717PDz/84Bb9qT311FPu8dq1a93zjz76qPs+/Pe///UsWrTIjf7asmVLz/79+z3V5TroubvuusuN5KnvyGeffeY58cQTPW3btvUcOHDAU5WMGDHCk5CQ4P4eNm/e7F8yMjL8x9x4442eZs2aeWbOnOn5/vvvPX369HFLdboOK1as8IwbN859fn0n9PfRqlUrz2mnneapSkaPHu1G+9Vn1N+/tsPCwjzTp0+vNt+FqoKyvnqX95T1XpT1XpT1XpT1x7a8J6CvYM8//7z7JUVHR7upbb777jtPdXLZZZd5GjZs6D5/48aN3bb+iKuDzz//3BVqhRdN3eKbzua+++7zNGjQwN0M9uvXz7Ns2TJPdboO+o/9rLPO8tSrV89N29G8eXPP8OHDq+SNcHHXQMtrr73mP0Y3eDfddJObziQ2NtZz4YUXugKwOl2HdevWuQK9Tp067u+iTZs2nrvvvtuzZ88eT1Xyhz/8wX3f9X+jvv/6+/cV7tXlu1CVVPeyvjqX95T1XpT1XpT1XpT1x7a8D9M/pW/PBwAAAAAAlQF96AEAAAAACEEE9AAAAAAAhCACegAAAAAAQhABPQAAAAAAIYiAHgAAAACAEERADwAAAABACCKgBwAAAAAgBBHQAwAAAAAQggjoAVRKYWFh9t577wX7NAAAQAWhrAeOHgE9gCKuvvpqV8gWXs4+++xgnxoAACgHlPVA1RAZ7BMAUDmpQH/ttdcK7IuJiQna+QAAgPJFWQ+EPlroARRLBXpKSkqBJSkpyT2nGvwXX3zRzjnnHKtZs6a1atXK3nnnnQI//9NPP9lvf/tb93zdunXt+uuvt3379hU45tVXX7XOnTu792rYsKGNHDmywPOpqal24YUXWmxsrLVt29bef//9Y/DJAQCoHijrgdBHQA+gTO677z4bPHiw/fjjj3bllVfakCFDbMmSJe659PR0GzBggLspmDdvnk2ZMsU+++yzAoW4bhJuvvlmV/jrhkAFeJs2bQq8x4MPPmiXXnqpLVq0yM4991z3Pjt37jzmnxUAgOqIsh4IAR4AKGTYsGGeiIgIT1xcXIHl4Ycfds/rv44bb7yxwM/07t3bM2LECPf4pZde8iQlJXn27dvnf/7DDz/0hIeHe7Zs2eK2GzVq5PnTn/5U4jnoPf785z/7t/Va2vfxxx+X++cFAKC6oawHqgb60AMo1hlnnOFq1gPVqVPH/7hPnz4FntP2woUL3WPV3nft2tXi4uL8z5988smWl5dny5Ytc2l8mzZtsn79+h3yHI4//nj/Y71WfHy8bdu27ag/GwAAoKwHqgICegDFUqFaOC2uvKivXWlERUUV2NbNgW4UAADA0aOsB0IffegBlMl3331XZLtjx47usdbqb6f+dT7ffPONhYeHW/v27a127drWokULmzFjxjE/bwAAUDqU9UDlRws9gGJlZmbali1bCuyLjIy05ORk91iD3/To0cNOOeUUe/PNN23u3Ln2yiuvuOc0oM39999vw4YNswceeMC2b99uo0aNst///vfWoEEDd4z233jjjVa/fn03gu7evXvdjYCOAwAAFY+yHgh9BPQAijVt2jQ3vUwg1bgvXbrUPyrtpEmT7KabbnLHvf3229apUyf3nKae+eSTT+zWW2+1nj17um2NkvvUU0/5X0s3AAcOHLCnn37a7rrrLnfzcPHFFx/jTwkAQPVFWQ+EvjCNjBfskwAQWtS/7d1337VBgwYF+1QAAEAFoKwHQgN96AEAAAAACEEE9AAAAAAAhCBS7gEAAAAACEG00AMAAAAAEIII6AEAAAAACEEE9AAAAAAAhCACegAAAAAAQhABPQAAAAAAIYiAHgAAAACAEERADwAAAABACCKgBwAAAADAQs//AztUsCYdy40YAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Plot loss\n",
    "axs[0].plot(history.history['loss'], label='train_loss')\n",
    "axs[0].plot(history.history['val_loss'], label='val_loss')\n",
    "axs[0].set_title(\"Loss\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "# Plot accuracy\n",
    "axs[1].plot(history.history['accuracy'], label='train_acc')\n",
    "axs[1].plot(history.history['val_accuracy'], label='val_acc')\n",
    "axs[1].set_title(\"Accuracy\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Accuracy\")\n",
    "axs[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Testing vs MCTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_pick_move(board_2d, model, color='plus'):\n",
    "    \"\"\"\n",
    "    Given a 6x7 board (board_2d) and a trained Keras model,\n",
    "    pick the column with highest predicted probability (from the CNN)\n",
    "    that is also legal.\n",
    "    \n",
    "    If 'color' == 'minus', we flip channels so the CNN sees \"plus perspective.\"\n",
    "    That means channel 0 => squares of +1, channel 1 => squares of -1.\n",
    "    \n",
    "    Return: int column in [0..6].\n",
    "    \"\"\"\n",
    "    # Convert board to 6x7x2 representation\n",
    "    from_board = board_to_6x7x2(board_2d)\n",
    "    \n",
    "    if color == 'minus':\n",
    "        # Flip minus -> plus perspective\n",
    "        from_board = minus_to_plus(from_board)\n",
    "\n",
    "    # Model expects shape (N, 6, 7, 2). So expand dims.\n",
    "    input_for_model = np.expand_dims(from_board, axis=0)  # (1,6,7,2)\n",
    "    \n",
    "    # Predict probabilities for each column\n",
    "    # shape: (1,7)\n",
    "    pred_probs = model.predict(input_for_model, verbose=0)[0]  # (7,)\n",
    "\n",
    "    # Sort columns by descending probability\n",
    "    columns_ranked = np.argsort(pred_probs)[::-1]  # highest -> lowest\n",
    "\n",
    "    # Find a legal column among the top predictions\n",
    "    legal_cols = find_legal(board_2d)\n",
    "    for col in columns_ranked:\n",
    "        if col in legal_cols:\n",
    "            return col\n",
    "\n",
    "    # Fallback: if something weird happened (all top columns were illegal),\n",
    "    # pick a random legal column\n",
    "    if len(legal_cols) > 0:\n",
    "        return random.choice(legal_cols)\n",
    "    else:\n",
    "        return 0  # if no columns are legal, game is effectively a tie/loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_one_game_CNN_vs_MCTS(model, mcts_steps_minus=300, verbose=False):\n",
    "    \"\"\"\n",
    "    Let the CNN play as 'plus' and MCTS play as 'minus' with mcts_steps_minus.\n",
    "    Returns: winner (str), number_of_moves\n",
    "             where winner is in { 'nobody', 'v-plus', 'v-minus', 'h-plus', ... etc. }\n",
    "    \"\"\"\n",
    "    board = np.zeros((6,7), dtype=np.float32)\n",
    "    winner = 'nobody'\n",
    "    player = 'plus'\n",
    "    move_count = 0\n",
    "\n",
    "    while winner == 'nobody':\n",
    "        legal = find_legal(board)\n",
    "        if len(legal) == 0:\n",
    "            # tie\n",
    "            break\n",
    "\n",
    "        if player == 'plus':\n",
    "            col = cnn_pick_move(board, model, color='plus')\n",
    "        else:\n",
    "            col = mcts(board, 'minus', mcts_steps_minus)\n",
    "\n",
    "        board = update_board(board, player, col)\n",
    "        winner = check_for_win(board, col)\n",
    "        \n",
    "        move_count += 1\n",
    "        \n",
    "        if player == 'plus':\n",
    "            player = 'minus'\n",
    "        else:\n",
    "            player = 'plus'\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Move {move_count}, {player}, col={col}\")\n",
    "\n",
    "    return winner, move_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_CNN_vs_MCTS(model, num_games=100, mcts_steps_minus=300, verbose=False):\n",
    "    \"\"\"\n",
    "    Play 'num_games' between:\n",
    "      - CNN as 'plus'\n",
    "      - MCTS as 'minus' with mcts_steps_minus\n",
    "    Track how many times plus wins, minus wins, or tie.\n",
    "    Also track average length of game (moves).\n",
    "    \n",
    "    Returns: \n",
    "      plus_wins, minus_wins, ties, avg_moves\n",
    "    \"\"\"\n",
    "    plus_wins = 0\n",
    "    minus_wins = 0\n",
    "    ties = 0\n",
    "    total_moves = 0\n",
    "\n",
    "    for g in range(num_games):\n",
    "        winner, moves = play_one_game_CNN_vs_MCTS(\n",
    "            model,\n",
    "            mcts_steps_minus=mcts_steps_minus,\n",
    "            verbose=verbose\n",
    "        )\n",
    "        total_moves += moves\n",
    "\n",
    "        if winner == 'nobody' or winner == 'tie':\n",
    "            ties += 1\n",
    "        elif winner.endswith('plus'):\n",
    "            plus_wins += 1\n",
    "        elif winner.endswith('minus'):\n",
    "            minus_wins += 1\n",
    "        else:\n",
    "            if winner[-4:] == 'plus':\n",
    "                plus_wins += 1\n",
    "            else:\n",
    "                minus_wins += 1\n",
    "    \n",
    "    avg_moves = total_moves / num_games if num_games > 0 else 0\n",
    "    \n",
    "    return plus_wins, minus_wins, ties, avg_moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 50 games vs. MCTS(1000 steps):\n",
      "  CNN (plus) wins:  37\n",
      "  MCTS (minus) wins: 11\n",
      "  Ties: 2\n",
      "  Average number of moves per game: 30.7\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #model = tf.keras.models.load_model(\"cnn_connect4.h5\")\n",
    "    \n",
    "    num_games = 50\n",
    "    mcts_steps = 1000  # how many MCTS steps minus uses\n",
    "\n",
    "    pw, mw, ts, am = test_CNN_vs_MCTS(model, num_games=num_games, mcts_steps_minus=mcts_steps, verbose=False)\n",
    "    \n",
    "    print(f\"Out of {num_games} games vs. MCTS({mcts_steps} steps):\")\n",
    "    print(f\"  CNN (plus) wins:  {pw}\")\n",
    "    print(f\"  MCTS (minus) wins: {mw}\")\n",
    "    print(f\"  Ties: {ts}\")\n",
    "    print(f\"  Average number of moves per game: {am:.1f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
