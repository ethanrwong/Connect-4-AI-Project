{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #type: ignore\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from IPython.display import clear_output #type: ignore\n",
    "import tensorflow as tf #type: ignore\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split #type: ignore\n",
    "import matplotlib.pyplot as plt #type: ignore\n",
    "from joblib import Parallel, delayed  # for parallelism\n",
    "import multiprocessing\n",
    "\n",
    "SEED = 22\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect Four and MCTS Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_board(board_temp,color,column):\n",
    "    board = board_temp.copy()\n",
    "    colsum = abs(board[0,column])+abs(board[1,column])+abs(board[2,column])+abs(board[3,column])+abs(board[4,column])+abs(board[5,column])\n",
    "    row = int(5-colsum)\n",
    "    if row > -0.5:\n",
    "        if color == 'plus':\n",
    "            board[row,column] = 1\n",
    "        else:\n",
    "            board[row,column] = -1\n",
    "    return board\n",
    "    \n",
    "def check_for_win_slow(board):\n",
    "    nrow = board.shape[0]\n",
    "    ncol = board.shape[1]\n",
    "    winner = 'nobody'\n",
    "    for col in range(ncol):\n",
    "        for row in reversed(range(nrow)):\n",
    "            if abs(board[row,col]) < 0.1:\n",
    "                break\n",
    "            # vertical\n",
    "            if row <= (nrow-4):\n",
    "                tempsum = board[row,col]+board[row+1,col]+board[row+2,col]+board[row+3,col]\n",
    "                if tempsum==4:\n",
    "                    winner = 'v-plus'\n",
    "                    return winner\n",
    "                elif tempsum==-4:\n",
    "                    winner = 'v-minus'\n",
    "                    return winner\n",
    "            # horizontal\n",
    "            if col <= (ncol-4):\n",
    "                tempsum = board[row,col]+board[row,col+1]+board[row,col+2]+board[row,col+3]\n",
    "                if tempsum==4:\n",
    "                    winner = 'h-plus'\n",
    "                    return winner\n",
    "                elif tempsum==-4:\n",
    "                    winner = 'h-minus'\n",
    "                    return winner\n",
    "            # diagonal down-right\n",
    "            if (row <= (nrow-4)) and (col <= (ncol-4)):\n",
    "                tempsum = board[row,col]+board[row+1,col+1]+board[row+2,col+2]+board[row+3,col+3]\n",
    "                if tempsum==4:\n",
    "                    winner = 'd-plus'\n",
    "                    return winner\n",
    "                elif tempsum==-4:\n",
    "                    winner = 'd-minus'\n",
    "                    return winner\n",
    "            # diagonal down-left\n",
    "            if (row <= (nrow-4)) and (col >= 3):\n",
    "                tempsum = board[row,col]+board[row+1,col-1]+board[row+2,col-2]+board[row+3,col-3]\n",
    "                if tempsum==4:\n",
    "                    winner = 'd-plus'\n",
    "                    return winner\n",
    "                elif tempsum==-4:\n",
    "                    winner = 'd-minus'\n",
    "                    return winner\n",
    "    return winner\n",
    "\n",
    "def check_for_win(board,col):\n",
    "    nrow = 6\n",
    "    # figure out what row was just placed\n",
    "    colsum = abs(board[0,col])+abs(board[1,col])+abs(board[2,col])+abs(board[3,col])+abs(board[4,col])+abs(board[5,col])\n",
    "    row = int(6-colsum)\n",
    "    # vertical check\n",
    "    if row+3<6:\n",
    "        vert = board[row,col] + board[row+1,col] + board[row+2,col] + board[row+3,col]\n",
    "        if vert == 4:\n",
    "            return 'v-plus'\n",
    "        elif vert == -4:\n",
    "            return 'v-minus'\n",
    "    # horizontal checks (there are several)\n",
    "    # segment 0-3\n",
    "    if col+3<7:\n",
    "        hor = board[row,col] + board[row,col+1] + board[row,col+2] + board[row,col+3]\n",
    "        if hor == 4:\n",
    "            return 'h-plus'\n",
    "        elif hor == -4:\n",
    "            return 'h-minus'\n",
    "    # segment -1..+2\n",
    "    if col-1>=0 and col+2<7:\n",
    "        hor = board[row,col-1] + board[row,col] + board[row,col+1] + board[row,col+2]\n",
    "        if hor == 4:\n",
    "            return 'h-plus'\n",
    "        elif hor == -4:\n",
    "            return 'h-minus'\n",
    "    # segment -2..+1\n",
    "    if col-2>=0 and col+1<7:\n",
    "        hor = board[row,col-2] + board[row,col-1] + board[row,col] + board[row,col+1]\n",
    "        if hor == 4:\n",
    "            return 'h-plus'\n",
    "        elif hor == -4:\n",
    "            return 'h-minus'\n",
    "    # segment -3..0\n",
    "    if col-3>=0:\n",
    "        hor = board[row,col-3] + board[row,col-2] + board[row,col-1] + board[row,col]\n",
    "        if hor == 4:\n",
    "            return 'h-plus'\n",
    "        elif hor == -4:\n",
    "            return 'h-minus'\n",
    "    # diagonals down-right\n",
    "    if row < 3 and col < 4:\n",
    "        DR = board[row,col] + board[row+1,col+1] + board[row+2,col+2] + board[row+3,col+3]\n",
    "        if DR == 4:\n",
    "            return 'd-plus'\n",
    "        elif DR == -4:\n",
    "            return 'd-minus'\n",
    "    if row-1>=0 and col-1>=0 and row+2<6 and col+2<7:\n",
    "        DR = board[row-1,col-1] + board[row,col] + board[row+1,col+1] + board[row+2,col+2]\n",
    "        if DR == 4:\n",
    "            return 'd-plus'\n",
    "        elif DR == -4:\n",
    "            return 'd-minus'\n",
    "    if row-2>=0 and col-2>=0 and row+1<6 and col+1<7:\n",
    "        DR = board[row-2,col-2] + board[row-1,col-1] + board[row,col] + board[row+1,col+1]\n",
    "        if DR == 4:\n",
    "            return 'd-plus'\n",
    "        elif DR == -4:\n",
    "            return 'd-minus'\n",
    "    if row-3>=0 and col-3>=0:\n",
    "        DR = board[row-3,col-3] + board[row-2,col-2] + board[row-1,col-1] + board[row,col]\n",
    "        if DR == 4:\n",
    "            return 'd-plus'\n",
    "        elif DR == -4:\n",
    "            return 'd-minus'\n",
    "    # diagonals down-left\n",
    "    if row+3<6 and col-3>=0:\n",
    "        DL = board[row,col] + board[row+1,col-1] + board[row+2,col-2] + board[row+3,col-3]\n",
    "        if DL == 4:\n",
    "            return 'd-plus'\n",
    "        elif DL == -4:\n",
    "            return 'd-minus'\n",
    "    if row-1>=0 and col+1<7 and row+2<6 and col-2>=0:\n",
    "        DL = board[row-1,col+1] + board[row,col] + board[row+1,col-1] + board[row+2,col-2]\n",
    "        if DL == 4:\n",
    "            return 'd-plus'\n",
    "        elif DL == -4:\n",
    "            return 'd-minus'\n",
    "    if row-2>=0 and col+2<7 and row+1<6 and col-1>=0:\n",
    "        DL = board[row-2,col+2] + board[row-1,col+1] + board[row,col] + board[row+1,col-1]\n",
    "        if DL == 4:\n",
    "            return 'd-plus'\n",
    "        elif DL == -4:\n",
    "            return 'd-minus'\n",
    "    if row-3>=0 and col+3<7:\n",
    "        DL = board[row-3,col+3] + board[row-2,col+2] + board[row-1,col+1] + board[row,col]\n",
    "        if DL == 4:\n",
    "            return 'd-plus'\n",
    "        elif DL == -4:\n",
    "            return 'd-minus'\n",
    "    return 'nobody'\n",
    "\n",
    "def find_legal(board):\n",
    "    return [i for i in range(7) if abs(board[0,i]) < 0.1]\n",
    "\n",
    "def look_for_win(board_,color):\n",
    "    board_ = board_.copy()\n",
    "    legal = find_legal(board_)\n",
    "    winner_col = -1\n",
    "    for m in legal:\n",
    "        bt = update_board(board_.copy(),color,m)\n",
    "        wi = check_for_win(bt,m)\n",
    "        if wi[2:] == color:\n",
    "            winner_col = m\n",
    "            break\n",
    "    return winner_col\n",
    "\n",
    "def find_all_nonlosers(board,color):\n",
    "    if color == 'plus':\n",
    "        opp = 'minus'\n",
    "    else:\n",
    "        opp = 'plus'\n",
    "    legal = find_legal(board)\n",
    "    poss_boards = [update_board(board,color,l) for l in legal]\n",
    "    poss_legal = [find_legal(b) for b in poss_boards]\n",
    "    allowed = []\n",
    "    for i in range(len(legal)):\n",
    "        # if the opponent can immediately win after we move in col=legal[i], skip it\n",
    "        wins = [j for j in poss_legal[i] \n",
    "                if check_for_win(update_board(poss_boards[i],opp,j),j) != 'nobody']\n",
    "        if len(wins) == 0:\n",
    "            allowed.append(legal[i])\n",
    "    return allowed\n",
    "\n",
    "def back_prop(winner,path,color0,md):\n",
    "    for i, board_tuple in enumerate(path):\n",
    "        md[board_tuple][0] += 1\n",
    "        if winner[2] == color0[0]:\n",
    "            if i % 2 == 1:\n",
    "                md[board_tuple][1] += 1\n",
    "            else:\n",
    "                md[board_tuple][1] -= 1\n",
    "        elif winner[2] == 'e':\n",
    "            # tie => no change\n",
    "            pass\n",
    "        else:\n",
    "            if i % 2 == 1:\n",
    "                md[board_tuple][1] -= 1\n",
    "            else:\n",
    "                md[board_tuple][1] += 1\n",
    "\n",
    "def rollout(board,next_player):\n",
    "    winner = 'nobody'\n",
    "    player = next_player\n",
    "    while winner == 'nobody':\n",
    "        legal = find_legal(board)\n",
    "        if len(legal) == 0:\n",
    "            return 'tie'\n",
    "        move = random.choice(legal)\n",
    "        board = update_board(board,player,move)\n",
    "        winner = check_for_win(board,move)\n",
    "        # switch player\n",
    "        if player == 'plus':\n",
    "            player = 'minus'\n",
    "        else:\n",
    "            player = 'plus'\n",
    "    return winner\n",
    "        \n",
    "def mcts(board_temp,color0,nsteps):\n",
    "    # Traditional MCTS, plus small improvements:\n",
    "    board = board_temp.copy()\n",
    "    # 1. If there's an immediate winning move, use it\n",
    "    win_col = look_for_win(board,color0)\n",
    "    if win_col != -1:\n",
    "        return win_col\n",
    "    # 2. Look for any moves that avoid an immediate losing position\n",
    "    legal0 = find_all_nonlosers(board,color0)\n",
    "    if len(legal0) == 0:\n",
    "        # if no way to avoid opponent's immediate threat, use all legal moves\n",
    "        legal0 = find_legal(board)\n",
    "    \n",
    "    mcts_dict = {tuple(board.ravel()):[0,0]}\n",
    "    for _ in range(nsteps):\n",
    "        color = color0\n",
    "        winner = 'nobody'\n",
    "        board_mcts = board.copy()\n",
    "        path = [tuple(board_mcts.ravel())]\n",
    "        \n",
    "        while winner == 'nobody':\n",
    "            legal = find_legal(board_mcts)\n",
    "            if len(legal) == 0:\n",
    "                winner = 'tie'\n",
    "                back_prop(winner,path,color0,mcts_dict)\n",
    "                break\n",
    "            # list of next possible boards\n",
    "            board_list = []\n",
    "            for col in legal:\n",
    "                b_next = update_board(board_mcts,color,col)\n",
    "                board_list.append(tuple(b_next.ravel()))\n",
    "                if tuple(b_next.ravel()) not in mcts_dict:\n",
    "                    mcts_dict[tuple(b_next.ravel())] = [0,0]\n",
    "            \n",
    "            # UCB1 \n",
    "            ucb1 = np.zeros(len(legal))\n",
    "            for i, bl in enumerate(board_list):\n",
    "                num_sims, total_value = mcts_dict[bl]\n",
    "                if num_sims == 0:\n",
    "                    # large priority for unvisited\n",
    "                    ucb1[i] = 10 * nsteps\n",
    "                else:\n",
    "                    parent_sims = mcts_dict[path[-1]][0]\n",
    "                    avg_val = total_value / num_sims\n",
    "                    explore = np.sqrt(np.log(parent_sims)/num_sims)\n",
    "                    ucb1[i] = avg_val + 2*explore\n",
    "            \n",
    "            chosen = np.argmax(ucb1)\n",
    "            board_mcts = update_board(board_mcts,color,legal[chosen])\n",
    "            path.append(tuple(board_mcts.ravel()))\n",
    "            # check winner\n",
    "            winner = check_for_win(board_mcts,legal[chosen])\n",
    "            if winner[2] == color[0]:\n",
    "                back_prop(winner,path,color0,mcts_dict)\n",
    "                break\n",
    "            \n",
    "            # switch player\n",
    "            color = 'minus' if (color=='plus') else 'plus'\n",
    "            \n",
    "            # if the new board has never been visited, do a rollout\n",
    "            if mcts_dict[tuple(board_mcts.ravel())][0] == 0:\n",
    "                winner_roll = rollout(board_mcts,color)\n",
    "                back_prop(winner_roll,path,color0,mcts_dict)\n",
    "                break\n",
    "    \n",
    "    # pick the move with best average reward\n",
    "    best_col = -1\n",
    "    max_score = -np.inf\n",
    "    for col in legal0:\n",
    "        new_board = tuple(update_board(board,color0,col).ravel())\n",
    "        num_sims, total_val = mcts_dict[new_board]\n",
    "        if num_sims == 0:\n",
    "            # means we never visited it\n",
    "            score = -np.inf\n",
    "        else:\n",
    "            score = total_val/num_sims\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            best_col = col\n",
    "\n",
    "    return best_col\n",
    "\n",
    "\n",
    "def board_to_6x7x2(board_2d):\n",
    "    \"\"\"\n",
    "    Convert a 6x7 board with +1, -1, 0 \n",
    "    into a 6x7x2 one-hot style representation:\n",
    "       channel 0 => +1 positions\n",
    "       channel 1 => -1 positions\n",
    "    \"\"\"\n",
    "    X = np.zeros((6,7,2), dtype=np.float32)\n",
    "    for i in range(6):\n",
    "        for j in range(7):\n",
    "            if board_2d[i,j] == 1:\n",
    "                X[i,j,0] = 1\n",
    "            elif board_2d[i,j] == -1:\n",
    "                X[i,j,1] = 1\n",
    "    return X\n",
    "\n",
    "def minus_to_plus(board_6x7x2):\n",
    "    \"\"\"\n",
    "    Flip a (6,7,2) board from 'minus perspective' to 'plus perspective'\n",
    "    by swapping channels 0 and 1.\n",
    "      channel 0 => +1 squares\n",
    "      channel 1 => -1 squares\n",
    "    If originally channel 1 was the 'minus' squares, \n",
    "    after swap, that becomes the 'plus' squares, etc.\n",
    "    \"\"\"\n",
    "    flipped = board_6x7x2.copy()\n",
    "    flipped[..., 0], flipped[..., 1] = board_6x7x2[..., 1], board_6x7x2[..., 0]\n",
    "    return flipped\n",
    "\n",
    "def add_symmetric_flips(board_6x7x2, best_move):\n",
    "    \"\"\"\n",
    "    Given a (6,7,2) board and an integer best_move in [0..6],\n",
    "    return a list of:\n",
    "      [(original_board_6x7x2, best_move),\n",
    "       (flipped_board_6x7x2, flipped_move)].\n",
    "    The flipped version is mirrored left-to-right (column j -> 6-j).\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    \n",
    "    # 1) Original\n",
    "    out.append((board_6x7x2, best_move))\n",
    "    \n",
    "    # 2) Flipped left-right\n",
    "    flipped_board = board_6x7x2[:, ::-1, :].copy()\n",
    "    flipped_col = 6 - best_move\n",
    "    out.append((flipped_board, flipped_col))\n",
    "    \n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_one_game(\n",
    "    plus_mcts_steps=800, \n",
    "    minus_mcts_steps=800,\n",
    "    random_openings=2\n",
    "):\n",
    "    \"\"\"\n",
    "    Play one full game between plus & minus, each side using MCTS.\n",
    "    - random_openings => number of random moves each side does at the start.\n",
    "    - We'll capture BOTH plus and minus moves. \n",
    "      For minus, we flip the board to plus perspective before storing.\n",
    "    - We do NOT store random moves. \n",
    "    - Return a list of (board_6x7x2, best_move_col) for all MCTS-chosen moves \n",
    "      from the plus perspective.\n",
    "    \"\"\"\n",
    "    data_this_game = []\n",
    "    board = np.zeros((6,7), dtype=np.float32)\n",
    "    winner = 'nobody'\n",
    "    player = 'plus'\n",
    "    move_count = 0\n",
    "    \n",
    "    while winner == 'nobody':\n",
    "        legal = find_legal(board)\n",
    "        if len(legal) == 0:\n",
    "            break  # tie\n",
    "\n",
    "        # Possibly do a random move in the opening\n",
    "        use_random = False\n",
    "        if move_count < 2*random_openings:\n",
    "            # e.g. first X moves in the entire game: random for plus & minus\n",
    "            use_random = True\n",
    "\n",
    "        if use_random:\n",
    "            col = random.choice(legal)\n",
    "        else:\n",
    "            # MCTS to pick best move\n",
    "            if player == 'plus':\n",
    "                col = mcts(board, 'plus', plus_mcts_steps)\n",
    "            else:\n",
    "                col = mcts(board, 'minus', minus_mcts_steps)\n",
    "\n",
    "        old_board = board.copy()  # board before the current move\n",
    "        board = update_board(board, player, col)\n",
    "        winner = check_for_win(board, col)\n",
    "\n",
    "        # Store the data if this move is MCTS-based (not random)\n",
    "        if not use_random:\n",
    "            if player == 'plus':\n",
    "                # plus perspective => straightforward\n",
    "                board_6x7x2 = board_to_6x7x2(old_board)\n",
    "                data_this_game.append((board_6x7x2, col))\n",
    "            else:\n",
    "                # minus perspective => flip channels to get plus perspective\n",
    "                board_6x7x2_minus = board_to_6x7x2(old_board)\n",
    "                board_6x7x2_plus = minus_to_plus(board_6x7x2_minus)\n",
    "                # The chosen column from minus's vantage is the same col index on the grid\n",
    "                data_this_game.append((board_6x7x2_plus, col))\n",
    "\n",
    "        # Switch player\n",
    "        player = 'minus' if (player == 'plus') else 'plus'\n",
    "        move_count += 1\n",
    "    \n",
    "    return data_this_game\n",
    "\n",
    "def play_one_game_random_params():\n",
    "    \"\"\"\n",
    "    Roll random settings:\n",
    "      plus_mcts_steps   in [500..5000]\n",
    "      minus_mcts_steps  in [500..5000]\n",
    "      random_openings   in [1..15]\n",
    "\n",
    "    Then call play_one_game(...) once.\n",
    "    Return the list of (board_6x7x2, best_move).\n",
    "    \"\"\"\n",
    "    plus_mcts = random.randint(500, 5000)\n",
    "    minus_mcts = random.randint(500, 5000)\n",
    "    openings   = random.randint(1, 15)\n",
    "    game_data = play_one_game(\n",
    "        plus_mcts_steps=plus_mcts,\n",
    "        minus_mcts_steps=minus_mcts,\n",
    "        random_openings=openings\n",
    "    )\n",
    "    return game_data  # list of (board_6x7x2, best_move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_build_dataset(num_games=25000):\n",
    "    \"\"\"\n",
    "    Use joblib to run 'play_one_game_random_params()' in parallel.\n",
    "\n",
    "    We store results in a collision dictionary (board -> {move->count}).\n",
    "    Then we do final collision resolution + stacking into X,y.\n",
    "\n",
    "    Returns X, y as np arrays:\n",
    "      X.shape = (N, 6, 7, 2)\n",
    "      y.shape = (N,)\n",
    "    \"\"\"\n",
    "    print(f\"Building dataset with {num_games} games in parallel...\")\n",
    "\n",
    "    # Step 1: run each game in parallel\n",
    "    results = Parallel(n_jobs=-1, backend='loky')(\n",
    "        delayed(play_one_game_random_params)()\n",
    "        for _ in range(num_games)\n",
    "    )\n",
    "\n",
    "    # 'results' is a list of lists. Each sub-list is the (board_6x7x2, best_move) pairs for one game.\n",
    "    # We'll store them with symmetrical flips & collisions.\n",
    "    data_dict = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    print(\"Aggregating results & handling collisions...\")\n",
    "\n",
    "    # Step 2: For each game’s data, do symmetry flips & increment collision dictionary\n",
    "    for game_data in results:\n",
    "        for (board_6x7x2, best_move) in game_data:\n",
    "            # augment\n",
    "            augmented = add_symmetric_flips(board_6x7x2, best_move)\n",
    "            for (b_aug, m_aug) in augmented:\n",
    "                key = b_aug.tobytes()\n",
    "                data_dict[key][m_aug] += 1\n",
    "\n",
    "    # Step 3: collision resolution\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    for key, move_counts in data_dict.items():\n",
    "        best_move = max(move_counts, key=move_counts.get)\n",
    "        arr = np.frombuffer(key, dtype=np.float32).reshape(6,7,2)\n",
    "        X_list.append(arr)\n",
    "        y_list.append(best_move)\n",
    "\n",
    "    X = np.stack(X_list, axis=0)\n",
    "    y = np.array(y_list, dtype=np.int32)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataset with 25000 games in parallel...\n",
      "Aggregating results & handling collisions...\n",
      "Finished building dataset!\n",
      "X shape: (457185, 6, 7, 2)\n",
      "y shape: (457185,)\n",
      "Unique moves in y: [0 1 2 3 4 5 6]\n",
      "Dataset saved to X_dataset_new.ethan and y_dataset_ethan.npy.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    NUM_GAMES = 25000  \n",
    "    X, y = parallel_build_dataset(num_games=NUM_GAMES)\n",
    "    print(\"Finished building dataset!\")\n",
    "    print(\"X shape:\", X.shape)  # (N,6,7,2)\n",
    "    print(\"y shape:\", y.shape)\n",
    "    print(\"Unique moves in y:\", np.unique(y))\n",
    "\n",
    "    # Save to disk\n",
    "    np.save(\"X_dataset_ethan.npy\", X) # change filename as needed\n",
    "    np.save(\"y_dataset_ethan.npy\", y) # change filename as needed\n",
    "    print(\"Dataset saved to X_dataset_new.ethan.npy and y_dataset_ethan.npy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append dataset code\n",
    "\n",
    "#def append_datasets(file1_X, file1_y, file2_X, file2_y, out_X, out_y):\n",
    "#    \"\"\"\n",
    "#    Load two Connect4 datasets (X1,y1) and (X2,y2),\n",
    "#    concatenate them along axis=0,\n",
    "#    then save as (out_X, out_y).\n",
    "#    \"\"\"\n",
    "#    X1 = np.load(file1_X)\n",
    "#    y1 = np.load(file1_y)\n",
    "#    X2 = np.load(file2_X)\n",
    "#    y2 = np.load(file2_y)\n",
    "\n",
    "#    print(\"Before concatenation:\")\n",
    "#    print(\"  Dataset 1:\", X1.shape, y1.shape)\n",
    "#    print(\"  Dataset 2:\", X2.shape, y2.shape)\n",
    "\n",
    "#    X_merged = np.concatenate([X1, X2], axis=0)\n",
    "#    y_merged = np.concatenate([y1, y2], axis=0)\n",
    "\n",
    "#    print(\"After concatenation:\", X_merged.shape, y_merged.shape)\n",
    "\n",
    "#    np.save(out_X, X_merged)\n",
    "#    np.save(out_y, y_merged)\n",
    "#    print(f\"Saved merged dataset to {out_X}, {out_y}.\")\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "#    append_datasets(\n",
    "#        file1_X=\"X_dataset_new.npy\",\n",
    "#        file1_y=\"y_dataset_new.npy\",\n",
    "#        file2_X=\"X_dataset_peer.npy\",\n",
    "#        file2_y=\"y_dataset_peer.npy\",\n",
    "#        out_X=\"X_dataset_merged.npy\",\n",
    "#        out_y=\"y_dataset_merged.npy\"\n",
    "#    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes:\n",
      "X: (457185, 6, 7, 2)\n",
      "y: (457185,)\n",
      "Unique moves in y: [0 1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "X_file = \"X_dataset_ethan.npy\"\n",
    "y_file = \"y_dataset_ethan.npy\"\n",
    "\n",
    "X = np.load(X_file)  # shape (N, 6, 7, 2)\n",
    "y = np.load(y_file)  # shape (N,)\n",
    "\n",
    "print(\"Data shapes:\")\n",
    "print(\"X:\", X.shape)\n",
    "print(\"y:\", y.shape)\n",
    "unique_moves = np.unique(y)\n",
    "print(\"Unique moves in y:\", unique_moves)  # should be [0..6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 365748\n",
      "Validation set size: 91437\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.2, \n",
    "    random_state=22, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(\"Training set size:\", X_train.shape[0])\n",
    "print(\"Validation set size:\", X_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAvailable GPUs:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 6, 7, 64)          1216      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 6, 7, 64)         256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 6, 7, 64)          0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 3, 3, 64)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 3, 3, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 3, 3, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 3, 3, 128)         0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 1, 1, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 1, 1, 128)         147584    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 1, 1, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 1, 1, 128)         0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 1, 1, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 1, 1, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              (None, 1, 1, 256)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               131584    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_4 (ReLU)              (None, 512)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_5 (ReLU)              (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7)                 1799      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 787,911\n",
      "Trainable params: 785,223\n",
      "Non-trainable params: 2,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # Block 1\n",
    "    tf.keras.layers.Conv2D(64, (3,3), padding='same', input_shape=(6, 7, 2)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=2),  # (6,7)->(3,4)\n",
    "    \n",
    "    # Block 2\n",
    "    tf.keras.layers.Conv2D(128, (3,3), padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=2),  # (3,4)->(1,2)\n",
    "    \n",
    "    # Block 3\n",
    "    tf.keras.layers.Conv2D(128, (3,3), padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    \n",
    "    # Block 4 (new)\n",
    "    tf.keras.layers.Conv2D(256, (3,3), padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    # Shape = (1,2,256) => total of 512 features after flatten\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    # Dense block\n",
    "    tf.keras.layers.Dense(\n",
    "        512, \n",
    "        kernel_regularizer=tf.keras.regularizers.l2(5e-5)\n",
    "    ),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    tf.keras.layers.Dense(\n",
    "        256, \n",
    "        kernel_regularizer=tf.keras.regularizers.l2(5e-5)\n",
    "    ),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    # Output\n",
    "    tf.keras.layers.Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "# Start with Adam(1e-4), use ReduceLROnPlateau to dynamically lower it\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception-Style CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Inception_CNN\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 6, 7, 2)]    0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 6, 7, 32)     608         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 6, 7, 32)    128         ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                   (None, 6, 7, 32)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 6, 7, 32)     1056        ['re_lu[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 6, 7, 32)     1056        ['re_lu[0][0]']                  \n",
      "                                                                                                  \n",
      " re_lu_1 (ReLU)                 (None, 6, 7, 32)     0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_2 (ReLU)                 (None, 6, 7, 32)     0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 6, 7, 32)     9248        ['re_lu_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 6, 7, 32)     25632       ['re_lu_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 6, 7, 32)     1056        ['re_lu[0][0]']                  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 6, 7, 96)     0           ['conv2d_2[0][0]',               \n",
      "                                                                  'conv2d_4[0][0]',               \n",
      "                                                                  'conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 6, 7, 96)    384         ['concatenate[0][0]']            \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_3 (ReLU)                 (None, 6, 7, 96)     0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 3, 3, 96)     0           ['re_lu_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 3, 3, 64)     6208        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 3, 3, 64)     6208        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " re_lu_4 (ReLU)                 (None, 3, 3, 64)     0           ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_5 (ReLU)                 (None, 3, 3, 64)     0           ['conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 3, 3, 64)     36928       ['re_lu_4[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 3, 3, 64)     102464      ['re_lu_5[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 3, 3, 64)     6208        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 3, 3, 192)    0           ['conv2d_7[0][0]',               \n",
      "                                                                  'conv2d_9[0][0]',               \n",
      "                                                                  'conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 3, 3, 192)   768         ['concatenate_1[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_6 (ReLU)                 (None, 3, 3, 192)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 192)         0           ['re_lu_6[0][0]']                \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 192)         768         ['global_average_pooling2d[0][0]'\n",
      " rmalization)                                                    ]                                \n",
      "                                                                                                  \n",
      " re_lu_7 (ReLU)                 (None, 192)          0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          49408       ['re_lu_7[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 256)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 256)         1024        ['dropout[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_8 (ReLU)                 (None, 256)          0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 128)          32896       ['re_lu_8[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 128)          0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 7)            903         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 282,951\n",
      "Trainable params: 281,415\n",
      "Non-trainable params: 1,536\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def inception_block(x, filters=64, wd=1e-4):\n",
    "    \"\"\"\n",
    "    A simplified 'Inception-like' block:\n",
    "      Branch A: 1×1 conv -> 3×3 conv\n",
    "      Branch B: 1×1 conv -> 5×5 conv\n",
    "      Branch C: 1×1 conv (just for channel mixing)\n",
    "    Then we concat them along the channel axis, \n",
    "    followed by BatchNorm + ReLU.\n",
    "    \n",
    "    'filters' is the number of output filters *per branch*, \n",
    "    so total output channels ~ 3 * filters after concat.\n",
    "    \"\"\"\n",
    "    # Branch A\n",
    "    branch_a = tf.keras.layers.Conv2D(\n",
    "        filters, kernel_size=1, padding='same',\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(wd)\n",
    "    )(x)\n",
    "    branch_a = tf.keras.layers.ReLU()(branch_a)\n",
    "    branch_a = tf.keras.layers.Conv2D(\n",
    "        filters, kernel_size=3, padding='same',\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(wd)\n",
    "    )(branch_a)\n",
    "    \n",
    "    # Branch B\n",
    "    branch_b = tf.keras.layers.Conv2D(\n",
    "        filters, kernel_size=1, padding='same',\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(wd)\n",
    "    )(x)\n",
    "    branch_b = tf.keras.layers.ReLU()(branch_b)\n",
    "    branch_b = tf.keras.layers.Conv2D(\n",
    "        filters, kernel_size=5, padding='same',\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(wd)\n",
    "    )(branch_b)\n",
    "    \n",
    "    # Branch C (just 1×1)\n",
    "    branch_c = tf.keras.layers.Conv2D(\n",
    "        filters, kernel_size=1, padding='same',\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(wd)\n",
    "    )(x)\n",
    "    \n",
    "    # Concatenate along channel axis\n",
    "    out = tf.keras.layers.Concatenate(axis=-1)([branch_a, branch_b, branch_c])\n",
    "    # Then BN + ReLU\n",
    "    out = tf.keras.layers.BatchNormalization()(out)\n",
    "    out = tf.keras.layers.ReLU()(out)\n",
    "    return out\n",
    "\n",
    "\n",
    "def build_inception_cnn(input_shape=(6, 7, 2),\n",
    "                        wd=5e-5,\n",
    "                        use_global_pool=True):\n",
    "    \"\"\"\n",
    "    A 'pure CNN' using Inception-style blocks, \n",
    "    plus optional global average pooling to handle the small 6x7 board.\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "\n",
    "    # (1) Initial Conv\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        32, (3,3), padding='same',\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(wd)\n",
    "    )(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    # (2) Inception Block #1\n",
    "    x = inception_block(x, filters=32, wd=wd)\n",
    "\n",
    "    # (3) Max Pool to reduce from (6,7) => ~ (3,3)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "\n",
    "    # (4) Inception Block #2\n",
    "    x = inception_block(x, filters=64, wd=wd)\n",
    "\n",
    "    # (5) Do Global pool\n",
    "    if use_global_pool:\n",
    "        # Global Average Pool => shape ~ (batch, channels)\n",
    "        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    else:\n",
    "        # Flatten directly\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "    # (6) Dense block\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = tf.keras.layers.Dense(\n",
    "        256,\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(wd)\n",
    "    )(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = tf.keras.layers.Dense(\n",
    "        128,\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(wd)\n",
    "    )(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "    # (7) Output layer\n",
    "    outputs = tf.keras.layers.Dense(7, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs, name=\"Inception_CNN\")\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = build_inception_cnn(input_shape=(6,7,2), wd=5e-5)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Res-Net Style CNN  - Best Perfomer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 6, 7, 2)]    0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 6, 7, 64)     1216        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 6, 7, 64)    256         ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                   (None, 6, 7, 64)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 6, 7, 64)     36928       ['re_lu[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 6, 7, 64)    256         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_1 (ReLU)                 (None, 6, 7, 64)     0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 6, 7, 64)     36928       ['re_lu_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 6, 7, 64)    256         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 6, 7, 64)     0           ['re_lu[0][0]',                  \n",
      "                                                                  'batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_2 (ReLU)                 (None, 6, 7, 64)     0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 6, 7, 64)     36928       ['re_lu_2[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 6, 7, 64)    256         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_3 (ReLU)                 (None, 6, 7, 64)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 6, 7, 64)     36928       ['re_lu_3[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 6, 7, 64)    256         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 6, 7, 64)     0           ['re_lu_2[0][0]',                \n",
      "                                                                  'batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_4 (ReLU)                 (None, 6, 7, 64)     0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 3, 3, 64)     0           ['re_lu_4[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 3, 3, 128)    8320        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 3, 3, 128)   512         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_5 (ReLU)                 (None, 3, 3, 128)    0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 3, 3, 128)    147584      ['re_lu_5[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 3, 3, 128)   512         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_6 (ReLU)                 (None, 3, 3, 128)    0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 3, 3, 128)    147584      ['re_lu_6[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 3, 3, 128)   512         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 3, 3, 128)    0           ['re_lu_5[0][0]',                \n",
      "                                                                  'batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " re_lu_7 (ReLU)                 (None, 3, 3, 128)    0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 128)   0           ['re_lu_7[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 1, 1, 256)    33024       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 1, 1, 256)   1024        ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_8 (ReLU)                 (None, 1, 1, 256)    0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 1, 1, 256)    590080      ['re_lu_8[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 1, 1, 256)   1024        ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_9 (ReLU)                 (None, 1, 1, 256)    0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 1, 1, 256)    590080      ['re_lu_9[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 1, 1, 256)   1024        ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 1, 1, 256)    0           ['re_lu_8[0][0]',                \n",
      "                                                                  'batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_10 (ReLU)                (None, 1, 1, 256)    0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 256)          0           ['re_lu_10[0][0]']               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 512)          131584      ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 512)         2048        ['dense[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_11 (ReLU)                (None, 512)          0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 512)          0           ['re_lu_11[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 256)          131328      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 256)         1024        ['dense_1[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_12 (ReLU)                (None, 256)          0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 256)          0           ['re_lu_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 7)            1799        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,939,271\n",
      "Trainable params: 1,934,791\n",
      "Non-trainable params: 4,480\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def residual_block(x, filters, kernel_size=(3,3), l2_reg=5e-5):\n",
    "    \"\"\"\n",
    "    A basic ResNet-style block:\n",
    "      - 2D Convolution -> BN -> ReLU\n",
    "      - 2D Convolution -> BN\n",
    "      - Skip connection: add the input 'x' to the result\n",
    "      - Final ReLU activation\n",
    "    \"\"\"\n",
    "    # Save the input to add back later\n",
    "    shortcut = x\n",
    "\n",
    "    # First conv\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        filters, kernel_size, padding='same',\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(l2_reg)\n",
    "    )(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    # Second conv\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        filters, kernel_size, padding='same',\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(l2_reg)\n",
    "    )(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    # Add the shortcut (must have same shape)\n",
    "    x = tf.keras.layers.Add()([shortcut, x])\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def build_resnet_cnn(input_shape=(6,7,2), num_classes=7, l2_reg=5e-5, dropout_rate=0.3):\n",
    "    \"\"\"\n",
    "    A deeper ResNet-style CNN for Connect4.\n",
    "    - input_shape: (6,7,2)\n",
    "    - num_classes: 7 (one per column)\n",
    "    - l2_reg: L2 regularization factor\n",
    "    - dropout_rate: dropout ratio in dense layers\n",
    "    \"\"\"\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "\n",
    "    # Initial conv: (like a \"stem\" layer)\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        64, (3,3), padding='same',\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(l2_reg)\n",
    "    )(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    # --- Residual Block 1 (64 filters) ---\n",
    "    x = residual_block(x, filters=64, l2_reg=l2_reg)\n",
    "\n",
    "    # Do a second residual block at same (64) filters\n",
    "    x = residual_block(x, filters=64, l2_reg=l2_reg)\n",
    "\n",
    "    # MaxPool to reduce from (6,7) -> (3,3)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=2)(x)\n",
    "\n",
    "    # --- Residual Block 2 (128 filters) ---\n",
    "    x = tf.keras.layers.Conv2D(128, (1,1), strides=1,  # 1x1 to expand channels\n",
    "                               padding='same',\n",
    "                               kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    x = residual_block(x, filters=128, l2_reg=l2_reg)\n",
    "\n",
    "    # (3,3) -> (1,1) with maxpool\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=2)(x)\n",
    "\n",
    "    # --- Residual Block 3 (256 filters) ---\n",
    "    # 1x1 conv to expand from 128->256 channels\n",
    "    x = tf.keras.layers.Conv2D(256, (1,1), strides=1,\n",
    "                               padding='same',\n",
    "                               kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    x = residual_block(x, filters=256, l2_reg=l2_reg)\n",
    "\n",
    "    # Flatten\n",
    "    x = tf.keras.layers.Flatten()(x)  # shape ~ (256,)\n",
    "\n",
    "    # Dense block\n",
    "    x = tf.keras.layers.Dense(\n",
    "        512,\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(l2_reg)\n",
    "    )(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(\n",
    "        256,\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(l2_reg)\n",
    "    )(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    # Output\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = build_resnet_cnn(input_shape=(6,7,2), num_classes=7, l2_reg=5e-5, dropout_rate=0.3)\n",
    "\n",
    "    # Compile\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5715/5715 [==============================] - 49s 8ms/step - loss: 1.6441 - accuracy: 0.4614 - val_loss: 1.4916 - val_accuracy: 0.5433 - lr: 0.0100\n",
      "Epoch 2/50\n",
      "5715/5715 [==============================] - 46s 8ms/step - loss: 1.3323 - accuracy: 0.5701 - val_loss: 1.3339 - val_accuracy: 0.5608 - lr: 0.0100\n",
      "Epoch 3/50\n",
      "5715/5715 [==============================] - 47s 8ms/step - loss: 1.2718 - accuracy: 0.5815 - val_loss: 1.2772 - val_accuracy: 0.5693 - lr: 0.0100\n",
      "Epoch 4/50\n",
      "5715/5715 [==============================] - 48s 8ms/step - loss: 1.2500 - accuracy: 0.5867 - val_loss: 1.2670 - val_accuracy: 0.5744 - lr: 0.0100\n",
      "Epoch 5/50\n",
      "5715/5715 [==============================] - 48s 8ms/step - loss: 1.2372 - accuracy: 0.5882 - val_loss: 1.2397 - val_accuracy: 0.5837 - lr: 0.0100\n",
      "Epoch 6/50\n",
      "5715/5715 [==============================] - 49s 9ms/step - loss: 1.2262 - accuracy: 0.5902 - val_loss: 1.1882 - val_accuracy: 0.5987 - lr: 0.0100\n",
      "Epoch 7/50\n",
      "5715/5715 [==============================] - 50s 9ms/step - loss: 1.2232 - accuracy: 0.5911 - val_loss: 1.2046 - val_accuracy: 0.5981 - lr: 0.0100\n",
      "Epoch 8/50\n",
      "5715/5715 [==============================] - 51s 9ms/step - loss: 1.2175 - accuracy: 0.5910 - val_loss: 1.2002 - val_accuracy: 0.6002 - lr: 0.0100\n",
      "Epoch 9/50\n",
      "5715/5715 [==============================] - 52s 9ms/step - loss: 1.2156 - accuracy: 0.5919 - val_loss: 1.2277 - val_accuracy: 0.5863 - lr: 0.0100\n",
      "Epoch 10/50\n",
      "5715/5715 [==============================] - 53s 9ms/step - loss: 1.2132 - accuracy: 0.5918 - val_loss: 1.2273 - val_accuracy: 0.5865 - lr: 0.0100\n",
      "Epoch 11/50\n",
      "5711/5715 [============================>.] - ETA: 0s - loss: 1.2078 - accuracy: 0.5937\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "5715/5715 [==============================] - 51s 9ms/step - loss: 1.2078 - accuracy: 0.5937 - val_loss: 1.3250 - val_accuracy: 0.5378 - lr: 0.0100\n",
      "Epoch 12/50\n",
      "5715/5715 [==============================] - 45s 8ms/step - loss: 1.1050 - accuracy: 0.6151 - val_loss: 1.0554 - val_accuracy: 0.6204 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "5715/5715 [==============================] - 49s 9ms/step - loss: 1.0856 - accuracy: 0.6167 - val_loss: 1.0313 - val_accuracy: 0.6314 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "5715/5715 [==============================] - 51s 9ms/step - loss: 1.0822 - accuracy: 0.6166 - val_loss: 1.0910 - val_accuracy: 0.6091 - lr: 0.0050\n",
      "Epoch 15/50\n",
      "5715/5715 [==============================] - 50s 9ms/step - loss: 1.0795 - accuracy: 0.6180 - val_loss: 1.0382 - val_accuracy: 0.6236 - lr: 0.0050\n",
      "Epoch 16/50\n",
      "5710/5715 [============================>.] - ETA: 0s - loss: 1.0790 - accuracy: 0.6176\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "5715/5715 [==============================] - 49s 9ms/step - loss: 1.0790 - accuracy: 0.6176 - val_loss: 1.0448 - val_accuracy: 0.6233 - lr: 0.0050\n",
      "Epoch 17/50\n",
      "5715/5715 [==============================] - 46s 8ms/step - loss: 1.0147 - accuracy: 0.6343 - val_loss: 0.9542 - val_accuracy: 0.6522 - lr: 0.0025\n",
      "Epoch 18/50\n",
      "5715/5715 [==============================] - 46s 8ms/step - loss: 1.0001 - accuracy: 0.6360 - val_loss: 0.9398 - val_accuracy: 0.6518 - lr: 0.0025\n",
      "Epoch 19/50\n",
      "5715/5715 [==============================] - 46s 8ms/step - loss: 0.9951 - accuracy: 0.6358 - val_loss: 0.9662 - val_accuracy: 0.6403 - lr: 0.0025\n",
      "Epoch 20/50\n",
      "5714/5715 [============================>.] - ETA: 0s - loss: 0.9922 - accuracy: 0.6371\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "5715/5715 [==============================] - 46s 8ms/step - loss: 0.9923 - accuracy: 0.6371 - val_loss: 0.9696 - val_accuracy: 0.6454 - lr: 0.0025\n",
      "Epoch 21/50\n",
      "5715/5715 [==============================] - 46s 8ms/step - loss: 0.9546 - accuracy: 0.6471 - val_loss: 0.9017 - val_accuracy: 0.6614 - lr: 0.0012\n",
      "Epoch 22/50\n",
      "5715/5715 [==============================] - 50s 9ms/step - loss: 0.9437 - accuracy: 0.6495 - val_loss: 0.8989 - val_accuracy: 0.6627 - lr: 0.0012\n",
      "Epoch 23/50\n",
      "5715/5715 [==============================] - 49s 9ms/step - loss: 0.9397 - accuracy: 0.6491 - val_loss: 0.9068 - val_accuracy: 0.6556 - lr: 0.0012\n",
      "Epoch 24/50\n",
      "5715/5715 [==============================] - 49s 8ms/step - loss: 0.9364 - accuracy: 0.6501 - val_loss: 0.9066 - val_accuracy: 0.6558 - lr: 0.0012\n",
      "Epoch 25/50\n",
      "5713/5715 [============================>.] - ETA: 0s - loss: 0.9342 - accuracy: 0.6500\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "5715/5715 [==============================] - 48s 8ms/step - loss: 0.9342 - accuracy: 0.6500 - val_loss: 0.8998 - val_accuracy: 0.6572 - lr: 0.0012\n",
      "Epoch 26/50\n",
      "5715/5715 [==============================] - 49s 9ms/step - loss: 0.9097 - accuracy: 0.6574 - val_loss: 0.8743 - val_accuracy: 0.6663 - lr: 6.2500e-04\n",
      "Epoch 27/50\n",
      "5715/5715 [==============================] - 48s 8ms/step - loss: 0.9037 - accuracy: 0.6591 - val_loss: 0.8720 - val_accuracy: 0.6673 - lr: 6.2500e-04\n",
      "Epoch 28/50\n",
      "5715/5715 [==============================] - 47s 8ms/step - loss: 0.9000 - accuracy: 0.6586 - val_loss: 0.8676 - val_accuracy: 0.6652 - lr: 6.2500e-04\n",
      "Epoch 29/50\n",
      "5715/5715 [==============================] - 46s 8ms/step - loss: 0.8990 - accuracy: 0.6586 - val_loss: 0.8673 - val_accuracy: 0.6665 - lr: 6.2500e-04\n",
      "Epoch 30/50\n",
      "5714/5715 [============================>.] - ETA: 0s - loss: 0.8969 - accuracy: 0.6598\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "5715/5715 [==============================] - 48s 8ms/step - loss: 0.8969 - accuracy: 0.6598 - val_loss: 0.8647 - val_accuracy: 0.6653 - lr: 6.2500e-04\n",
      "Epoch 31/50\n",
      "5715/5715 [==============================] - 48s 8ms/step - loss: 0.8834 - accuracy: 0.6630 - val_loss: 0.8536 - val_accuracy: 0.6708 - lr: 3.1250e-04\n",
      "Epoch 32/50\n",
      "5715/5715 [==============================] - 48s 8ms/step - loss: 0.8802 - accuracy: 0.6637 - val_loss: 0.8535 - val_accuracy: 0.6704 - lr: 3.1250e-04\n",
      "Epoch 33/50\n",
      "5715/5715 [==============================] - 48s 8ms/step - loss: 0.8788 - accuracy: 0.6636 - val_loss: 0.8522 - val_accuracy: 0.6701 - lr: 3.1250e-04\n",
      "Epoch 34/50\n",
      "5715/5715 [==============================] - 46s 8ms/step - loss: 0.8755 - accuracy: 0.6640 - val_loss: 0.8497 - val_accuracy: 0.6717 - lr: 3.1250e-04\n",
      "Epoch 35/50\n",
      "5715/5715 [==============================] - 48s 8ms/step - loss: 0.8749 - accuracy: 0.6653 - val_loss: 0.8504 - val_accuracy: 0.6726 - lr: 3.1250e-04\n",
      "Epoch 36/50\n",
      "5715/5715 [==============================] - 52s 9ms/step - loss: 0.8728 - accuracy: 0.6659 - val_loss: 0.8503 - val_accuracy: 0.6717 - lr: 3.1250e-04\n",
      "Epoch 37/50\n",
      "5715/5715 [==============================] - 51s 9ms/step - loss: 0.8712 - accuracy: 0.6659 - val_loss: 0.8508 - val_accuracy: 0.6711 - lr: 3.1250e-04\n",
      "Epoch 38/50\n",
      "5709/5715 [============================>.] - ETA: 0s - loss: 0.8704 - accuracy: 0.6662\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "5715/5715 [==============================] - 49s 9ms/step - loss: 0.8705 - accuracy: 0.6661 - val_loss: 0.8486 - val_accuracy: 0.6712 - lr: 3.1250e-04\n",
      "Epoch 39/50\n",
      "5715/5715 [==============================] - 49s 9ms/step - loss: 0.8619 - accuracy: 0.6678 - val_loss: 0.8436 - val_accuracy: 0.6732 - lr: 1.5625e-04\n",
      "Epoch 40/50\n",
      "5715/5715 [==============================] - 49s 9ms/step - loss: 0.8604 - accuracy: 0.6691 - val_loss: 0.8428 - val_accuracy: 0.6725 - lr: 1.5625e-04\n",
      "Epoch 41/50\n",
      "5715/5715 [==============================] - 48s 8ms/step - loss: 0.8595 - accuracy: 0.6686 - val_loss: 0.8441 - val_accuracy: 0.6728 - lr: 1.5625e-04\n",
      "Epoch 42/50\n",
      "5715/5715 [==============================] - ETA: 0s - loss: 0.8585 - accuracy: 0.6694\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "5715/5715 [==============================] - 48s 8ms/step - loss: 0.8585 - accuracy: 0.6694 - val_loss: 0.8425 - val_accuracy: 0.6721 - lr: 1.5625e-04\n",
      "Epoch 43/50\n",
      "5715/5715 [==============================] - 49s 9ms/step - loss: 0.8538 - accuracy: 0.6712 - val_loss: 0.8393 - val_accuracy: 0.6742 - lr: 7.8125e-05\n",
      "Epoch 44/50\n",
      "5715/5715 [==============================] - 49s 9ms/step - loss: 0.8524 - accuracy: 0.6704 - val_loss: 0.8393 - val_accuracy: 0.6740 - lr: 7.8125e-05\n",
      "Epoch 45/50\n",
      "5715/5715 [==============================] - 49s 8ms/step - loss: 0.8523 - accuracy: 0.6710 - val_loss: 0.8389 - val_accuracy: 0.6739 - lr: 7.8125e-05\n",
      "Epoch 46/50\n",
      "5712/5715 [============================>.] - ETA: 0s - loss: 0.8513 - accuracy: 0.6711\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "5715/5715 [==============================] - 49s 9ms/step - loss: 0.8513 - accuracy: 0.6711 - val_loss: 0.8388 - val_accuracy: 0.6740 - lr: 7.8125e-05\n",
      "Epoch 47/50\n",
      "5715/5715 [==============================] - 49s 9ms/step - loss: 0.8493 - accuracy: 0.6717 - val_loss: 0.8380 - val_accuracy: 0.6742 - lr: 3.9062e-05\n",
      "Epoch 48/50\n",
      "5715/5715 [==============================] - 48s 8ms/step - loss: 0.8490 - accuracy: 0.6716 - val_loss: 0.8379 - val_accuracy: 0.6747 - lr: 3.9062e-05\n",
      "Epoch 49/50\n",
      "5715/5715 [==============================] - 48s 8ms/step - loss: 0.8479 - accuracy: 0.6719 - val_loss: 0.8373 - val_accuracy: 0.6749 - lr: 3.9062e-05\n",
      "Epoch 50/50\n",
      "5715/5715 [==============================] - 49s 9ms/step - loss: 0.8476 - accuracy: 0.6718 - val_loss: 0.8375 - val_accuracy: 0.6738 - lr: 3.9062e-05\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "batch_size = 64\n",
    "\n",
    "# Early stopping if val_accuracy doesn’t improve for 7 epochs\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=7,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Reduce learning rate by factor of 0.5 if val_accuracy doesn’t improve for 3 epochs\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 67.37%   (loss=0.8375)\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(f\"Validation accuracy: {val_acc*100:.2f}%   (loss={val_loss:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to cnn_connect4.h5.\n"
     ]
    }
   ],
   "source": [
    "model.save(\"cnn_connect4.h5\")\n",
    "print(\"Model saved to cnn_connect4.h5.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Plot loss\n",
    "axs[0].plot(history.history['loss'], label='train_loss')\n",
    "axs[0].plot(history.history['val_loss'], label='val_loss')\n",
    "axs[0].set_title(\"Loss\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "# Plot accuracy\n",
    "axs[1].plot(history.history['accuracy'], label='train_acc')\n",
    "axs[1].plot(history.history['val_accuracy'], label='val_acc')\n",
    "axs[1].set_title(\"Accuracy\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Accuracy\")\n",
    "axs[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Testing vs MCTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_pick_move(board_2d, model, color='plus'):\n",
    "    \"\"\"\n",
    "    Given a 6x7 board (board_2d) and a trained Keras model,\n",
    "    pick the column with highest predicted probability (from the CNN)\n",
    "    that is also legal.\n",
    "    \n",
    "    If 'color' == 'minus', we flip channels so the CNN sees \"plus perspective.\"\n",
    "    That means channel 0 => squares of +1, channel 1 => squares of -1.\n",
    "    \n",
    "    Return: int column in [0..6].\n",
    "    \"\"\"\n",
    "    # Convert board to 6x7x2 representation\n",
    "    from_board = board_to_6x7x2(board_2d)\n",
    "    \n",
    "    if color == 'minus':\n",
    "        # Flip minus -> plus perspective\n",
    "        from_board = minus_to_plus(from_board)\n",
    "\n",
    "    # Model expects shape (N, 6, 7, 2). So expand dims.\n",
    "    input_for_model = np.expand_dims(from_board, axis=0)  # (1,6,7,2)\n",
    "    \n",
    "    # Predict probabilities for each column\n",
    "    # shape: (1,7)\n",
    "    pred_probs = model.predict(input_for_model, verbose=0)[0]  # (7,)\n",
    "\n",
    "    # Sort columns by descending probability\n",
    "    columns_ranked = np.argsort(pred_probs)[::-1]  # highest -> lowest\n",
    "\n",
    "    # Find a legal column among the top predictions\n",
    "    legal_cols = find_legal(board_2d)\n",
    "    for col in columns_ranked:\n",
    "        if col in legal_cols:\n",
    "            return col\n",
    "\n",
    "    # Fallback: if something weird happened (all top columns were illegal),\n",
    "    # pick a random legal column\n",
    "    if len(legal_cols) > 0:\n",
    "        return random.choice(legal_cols)\n",
    "    else:\n",
    "        return 0  # if no columns are legal, game is effectively a tie/loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_one_game_CNN_vs_MCTS(model, mcts_steps_minus=300, verbose=False):\n",
    "    \"\"\"\n",
    "    Let the CNN play as 'plus' and MCTS play as 'minus' with mcts_steps_minus.\n",
    "    Returns: winner (str), number_of_moves\n",
    "             where winner is in { 'nobody', 'v-plus', 'v-minus', 'h-plus', ... etc. }\n",
    "    \"\"\"\n",
    "    board = np.zeros((6,7), dtype=np.float32)\n",
    "    winner = 'nobody'\n",
    "    player = 'plus'\n",
    "    move_count = 0\n",
    "\n",
    "    while winner == 'nobody':\n",
    "        legal = find_legal(board)\n",
    "        if len(legal) == 0:\n",
    "            # tie\n",
    "            break\n",
    "\n",
    "        if player == 'plus':\n",
    "            col = cnn_pick_move(board, model, color='plus')\n",
    "        else:\n",
    "            col = mcts(board, 'minus', mcts_steps_minus)\n",
    "\n",
    "        board = update_board(board, player, col)\n",
    "        winner = check_for_win(board, col)\n",
    "        \n",
    "        move_count += 1\n",
    "        \n",
    "        if player == 'plus':\n",
    "            player = 'minus'\n",
    "        else:\n",
    "            player = 'plus'\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Move {move_count}, {player}, col={col}\")\n",
    "\n",
    "    return winner, move_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_CNN_vs_MCTS(model, num_games=100, mcts_steps_minus=300, verbose=False):\n",
    "    \"\"\"\n",
    "    Play 'num_games' between:\n",
    "      - CNN as 'plus'\n",
    "      - MCTS as 'minus' with mcts_steps_minus\n",
    "    Track how many times plus wins, minus wins, or tie.\n",
    "    Also track average length of game (moves).\n",
    "    \n",
    "    Returns: \n",
    "      plus_wins, minus_wins, ties, avg_moves\n",
    "    \"\"\"\n",
    "    plus_wins = 0\n",
    "    minus_wins = 0\n",
    "    ties = 0\n",
    "    total_moves = 0\n",
    "\n",
    "    for g in range(num_games):\n",
    "        winner, moves = play_one_game_CNN_vs_MCTS(\n",
    "            model,\n",
    "            mcts_steps_minus=mcts_steps_minus,\n",
    "            verbose=verbose\n",
    "        )\n",
    "        total_moves += moves\n",
    "\n",
    "        if winner == 'nobody' or winner == 'tie':\n",
    "            ties += 1\n",
    "        elif winner.endswith('plus'):\n",
    "            plus_wins += 1\n",
    "        elif winner.endswith('minus'):\n",
    "            minus_wins += 1\n",
    "        else:\n",
    "            if winner[-4:] == 'plus':\n",
    "                plus_wins += 1\n",
    "            else:\n",
    "                minus_wins += 1\n",
    "    \n",
    "    avg_moves = total_moves / num_games if num_games > 0 else 0\n",
    "    \n",
    "    return plus_wins, minus_wins, ties, avg_moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 50 games vs. MCTS(1000 steps):\n",
      "  CNN (plus) wins:  30\n",
      "  MCTS (minus) wins: 19\n",
      "  Ties: 1\n",
      "  Average number of moves per game: 32.1\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # model = tf.keras.models.load_model(\"cnn_connect4.h5\")\n",
    "    \n",
    "    num_games = 50\n",
    "    mcts_steps = 1000  # how many MCTS steps minus uses\n",
    "\n",
    "    pw, mw, ts, am = test_CNN_vs_MCTS(model, num_games=num_games, mcts_steps_minus=mcts_steps, verbose=False)\n",
    "    \n",
    "    print(f\"Out of {num_games} games vs. MCTS({mcts_steps} steps):\")\n",
    "    print(f\"  CNN (plus) wins:  {pw}\")\n",
    "    print(f\"  MCTS (minus) wins: {mw}\")\n",
    "    print(f\"  Ties: {ts}\")\n",
    "    print(f\"  Average number of moves per game: {am:.1f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
