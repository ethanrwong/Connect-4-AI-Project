{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #type: ignore\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from IPython.display import clear_output #type: ignore\n",
    "import tensorflow as tf #type: ignore\n",
    "from tensorflow.keras import layers, models, regularizers #type: ignore\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split #type: ignore\n",
    "import matplotlib.pyplot as plt #type: ignore\n",
    "from joblib import Parallel, delayed  # for parallelism\n",
    "import multiprocessing\n",
    "\n",
    "SEED = 22\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect Four and MCTS Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_board(board_temp,color,column):\n",
    "    board = board_temp.copy()\n",
    "    colsum = abs(board[0,column])+abs(board[1,column])+abs(board[2,column])+abs(board[3,column])+abs(board[4,column])+abs(board[5,column])\n",
    "    row = int(5-colsum)\n",
    "    if row > -0.5:\n",
    "        if color == 'plus':\n",
    "            board[row,column] = 1\n",
    "        else:\n",
    "            board[row,column] = -1\n",
    "    return board\n",
    "    \n",
    "def check_for_win_slow(board):\n",
    "    nrow = board.shape[0]\n",
    "    ncol = board.shape[1]\n",
    "    winner = 'nobody'\n",
    "    for col in range(ncol):\n",
    "        for row in reversed(range(nrow)):\n",
    "            if abs(board[row,col]) < 0.1:\n",
    "                break\n",
    "            # vertical\n",
    "            if row <= (nrow-4):\n",
    "                tempsum = board[row,col]+board[row+1,col]+board[row+2,col]+board[row+3,col]\n",
    "                if tempsum==4:\n",
    "                    winner = 'v-plus'\n",
    "                    return winner\n",
    "                elif tempsum==-4:\n",
    "                    winner = 'v-minus'\n",
    "                    return winner\n",
    "            # horizontal\n",
    "            if col <= (ncol-4):\n",
    "                tempsum = board[row,col]+board[row,col+1]+board[row,col+2]+board[row,col+3]\n",
    "                if tempsum==4:\n",
    "                    winner = 'h-plus'\n",
    "                    return winner\n",
    "                elif tempsum==-4:\n",
    "                    winner = 'h-minus'\n",
    "                    return winner\n",
    "            # diagonal down-right\n",
    "            if (row <= (nrow-4)) and (col <= (ncol-4)):\n",
    "                tempsum = board[row,col]+board[row+1,col+1]+board[row+2,col+2]+board[row+3,col+3]\n",
    "                if tempsum==4:\n",
    "                    winner = 'd-plus'\n",
    "                    return winner\n",
    "                elif tempsum==-4:\n",
    "                    winner = 'd-minus'\n",
    "                    return winner\n",
    "            # diagonal down-left\n",
    "            if (row <= (nrow-4)) and (col >= 3):\n",
    "                tempsum = board[row,col]+board[row+1,col-1]+board[row+2,col-2]+board[row+3,col-3]\n",
    "                if tempsum==4:\n",
    "                    winner = 'd-plus'\n",
    "                    return winner\n",
    "                elif tempsum==-4:\n",
    "                    winner = 'd-minus'\n",
    "                    return winner\n",
    "    return winner\n",
    "\n",
    "def check_for_win(board,col):\n",
    "    nrow = 6\n",
    "    # figure out what row was just placed\n",
    "    colsum = abs(board[0,col])+abs(board[1,col])+abs(board[2,col])+abs(board[3,col])+abs(board[4,col])+abs(board[5,col])\n",
    "    row = int(6-colsum)\n",
    "    # vertical check\n",
    "    if row+3<6:\n",
    "        vert = board[row,col] + board[row+1,col] + board[row+2,col] + board[row+3,col]\n",
    "        if vert == 4:\n",
    "            return 'v-plus'\n",
    "        elif vert == -4:\n",
    "            return 'v-minus'\n",
    "    # horizontal checks (there are several)\n",
    "    # segment 0-3\n",
    "    if col+3<7:\n",
    "        hor = board[row,col] + board[row,col+1] + board[row,col+2] + board[row,col+3]\n",
    "        if hor == 4:\n",
    "            return 'h-plus'\n",
    "        elif hor == -4:\n",
    "            return 'h-minus'\n",
    "    # segment -1..+2\n",
    "    if col-1>=0 and col+2<7:\n",
    "        hor = board[row,col-1] + board[row,col] + board[row,col+1] + board[row,col+2]\n",
    "        if hor == 4:\n",
    "            return 'h-plus'\n",
    "        elif hor == -4:\n",
    "            return 'h-minus'\n",
    "    # segment -2..+1\n",
    "    if col-2>=0 and col+1<7:\n",
    "        hor = board[row,col-2] + board[row,col-1] + board[row,col] + board[row,col+1]\n",
    "        if hor == 4:\n",
    "            return 'h-plus'\n",
    "        elif hor == -4:\n",
    "            return 'h-minus'\n",
    "    # segment -3..0\n",
    "    if col-3>=0:\n",
    "        hor = board[row,col-3] + board[row,col-2] + board[row,col-1] + board[row,col]\n",
    "        if hor == 4:\n",
    "            return 'h-plus'\n",
    "        elif hor == -4:\n",
    "            return 'h-minus'\n",
    "    # diagonals down-right\n",
    "    if row < 3 and col < 4:\n",
    "        DR = board[row,col] + board[row+1,col+1] + board[row+2,col+2] + board[row+3,col+3]\n",
    "        if DR == 4:\n",
    "            return 'd-plus'\n",
    "        elif DR == -4:\n",
    "            return 'd-minus'\n",
    "    if row-1>=0 and col-1>=0 and row+2<6 and col+2<7:\n",
    "        DR = board[row-1,col-1] + board[row,col] + board[row+1,col+1] + board[row+2,col+2]\n",
    "        if DR == 4:\n",
    "            return 'd-plus'\n",
    "        elif DR == -4:\n",
    "            return 'd-minus'\n",
    "    if row-2>=0 and col-2>=0 and row+1<6 and col+1<7:\n",
    "        DR = board[row-2,col-2] + board[row-1,col-1] + board[row,col] + board[row+1,col+1]\n",
    "        if DR == 4:\n",
    "            return 'd-plus'\n",
    "        elif DR == -4:\n",
    "            return 'd-minus'\n",
    "    if row-3>=0 and col-3>=0:\n",
    "        DR = board[row-3,col-3] + board[row-2,col-2] + board[row-1,col-1] + board[row,col]\n",
    "        if DR == 4:\n",
    "            return 'd-plus'\n",
    "        elif DR == -4:\n",
    "            return 'd-minus'\n",
    "    # diagonals down-left\n",
    "    if row+3<6 and col-3>=0:\n",
    "        DL = board[row,col] + board[row+1,col-1] + board[row+2,col-2] + board[row+3,col-3]\n",
    "        if DL == 4:\n",
    "            return 'd-plus'\n",
    "        elif DL == -4:\n",
    "            return 'd-minus'\n",
    "    if row-1>=0 and col+1<7 and row+2<6 and col-2>=0:\n",
    "        DL = board[row-1,col+1] + board[row,col] + board[row+1,col-1] + board[row+2,col-2]\n",
    "        if DL == 4:\n",
    "            return 'd-plus'\n",
    "        elif DL == -4:\n",
    "            return 'd-minus'\n",
    "    if row-2>=0 and col+2<7 and row+1<6 and col-1>=0:\n",
    "        DL = board[row-2,col+2] + board[row-1,col+1] + board[row,col] + board[row+1,col-1]\n",
    "        if DL == 4:\n",
    "            return 'd-plus'\n",
    "        elif DL == -4:\n",
    "            return 'd-minus'\n",
    "    if row-3>=0 and col+3<7:\n",
    "        DL = board[row-3,col+3] + board[row-2,col+2] + board[row-1,col+1] + board[row,col]\n",
    "        if DL == 4:\n",
    "            return 'd-plus'\n",
    "        elif DL == -4:\n",
    "            return 'd-minus'\n",
    "    return 'nobody'\n",
    "\n",
    "def find_legal(board):\n",
    "    return [i for i in range(7) if abs(board[0,i]) < 0.1]\n",
    "\n",
    "def look_for_win(board_,color):\n",
    "    board_ = board_.copy()\n",
    "    legal = find_legal(board_)\n",
    "    winner_col = -1\n",
    "    for m in legal:\n",
    "        bt = update_board(board_.copy(),color,m)\n",
    "        wi = check_for_win(bt,m)\n",
    "        if wi[2:] == color:\n",
    "            winner_col = m\n",
    "            break\n",
    "    return winner_col\n",
    "\n",
    "def find_all_nonlosers(board,color):\n",
    "    if color == 'plus':\n",
    "        opp = 'minus'\n",
    "    else:\n",
    "        opp = 'plus'\n",
    "    legal = find_legal(board)\n",
    "    poss_boards = [update_board(board,color,l) for l in legal]\n",
    "    poss_legal = [find_legal(b) for b in poss_boards]\n",
    "    allowed = []\n",
    "    for i in range(len(legal)):\n",
    "        # if the opponent can immediately win after we move in col=legal[i], skip it\n",
    "        wins = [j for j in poss_legal[i] \n",
    "                if check_for_win(update_board(poss_boards[i],opp,j),j) != 'nobody']\n",
    "        if len(wins) == 0:\n",
    "            allowed.append(legal[i])\n",
    "    return allowed\n",
    "\n",
    "def back_prop(winner,path,color0,md):\n",
    "    for i, board_tuple in enumerate(path):\n",
    "        md[board_tuple][0] += 1\n",
    "        if winner[2] == color0[0]:\n",
    "            if i % 2 == 1:\n",
    "                md[board_tuple][1] += 1\n",
    "            else:\n",
    "                md[board_tuple][1] -= 1\n",
    "        elif winner[2] == 'e':\n",
    "            # tie => no change\n",
    "            pass\n",
    "        else:\n",
    "            if i % 2 == 1:\n",
    "                md[board_tuple][1] -= 1\n",
    "            else:\n",
    "                md[board_tuple][1] += 1\n",
    "\n",
    "def rollout(board,next_player):\n",
    "    winner = 'nobody'\n",
    "    player = next_player\n",
    "    while winner == 'nobody':\n",
    "        legal = find_legal(board)\n",
    "        if len(legal) == 0:\n",
    "            return 'tie'\n",
    "        move = random.choice(legal)\n",
    "        board = update_board(board,player,move)\n",
    "        winner = check_for_win(board,move)\n",
    "        # switch player\n",
    "        if player == 'plus':\n",
    "            player = 'minus'\n",
    "        else:\n",
    "            player = 'plus'\n",
    "    return winner\n",
    "        \n",
    "def mcts(board_temp,color0,nsteps):\n",
    "    # Traditional MCTS, plus small improvements:\n",
    "    board = board_temp.copy()\n",
    "    # 1. If there's an immediate winning move, use it\n",
    "    win_col = look_for_win(board,color0)\n",
    "    if win_col != -1:\n",
    "        return win_col\n",
    "    # 2. Look for any moves that avoid an immediate losing position\n",
    "    legal0 = find_all_nonlosers(board,color0)\n",
    "    if len(legal0) == 0:\n",
    "        # if no way to avoid opponent's immediate threat, use all legal moves\n",
    "        legal0 = find_legal(board)\n",
    "    \n",
    "    mcts_dict = {tuple(board.ravel()):[0,0]}\n",
    "    for _ in range(nsteps):\n",
    "        color = color0\n",
    "        winner = 'nobody'\n",
    "        board_mcts = board.copy()\n",
    "        path = [tuple(board_mcts.ravel())]\n",
    "        \n",
    "        while winner == 'nobody':\n",
    "            legal = find_legal(board_mcts)\n",
    "            if len(legal) == 0:\n",
    "                winner = 'tie'\n",
    "                back_prop(winner,path,color0,mcts_dict)\n",
    "                break\n",
    "            # list of next possible boards\n",
    "            board_list = []\n",
    "            for col in legal:\n",
    "                b_next = update_board(board_mcts,color,col)\n",
    "                board_list.append(tuple(b_next.ravel()))\n",
    "                if tuple(b_next.ravel()) not in mcts_dict:\n",
    "                    mcts_dict[tuple(b_next.ravel())] = [0,0]\n",
    "            \n",
    "            # UCB1 \n",
    "            ucb1 = np.zeros(len(legal))\n",
    "            for i, bl in enumerate(board_list):\n",
    "                num_sims, total_value = mcts_dict[bl]\n",
    "                if num_sims == 0:\n",
    "                    # large priority for unvisited\n",
    "                    ucb1[i] = 10 * nsteps\n",
    "                else:\n",
    "                    parent_sims = mcts_dict[path[-1]][0]\n",
    "                    avg_val = total_value / num_sims\n",
    "                    explore = np.sqrt(np.log(parent_sims)/num_sims)\n",
    "                    ucb1[i] = avg_val + 2*explore\n",
    "            \n",
    "            chosen = np.argmax(ucb1)\n",
    "            board_mcts = update_board(board_mcts,color,legal[chosen])\n",
    "            path.append(tuple(board_mcts.ravel()))\n",
    "            # check winner\n",
    "            winner = check_for_win(board_mcts,legal[chosen])\n",
    "            if winner[2] == color[0]:\n",
    "                back_prop(winner,path,color0,mcts_dict)\n",
    "                break\n",
    "            \n",
    "            # switch player\n",
    "            color = 'minus' if (color=='plus') else 'plus'\n",
    "            \n",
    "            # if the new board has never been visited, do a rollout\n",
    "            if mcts_dict[tuple(board_mcts.ravel())][0] == 0:\n",
    "                winner_roll = rollout(board_mcts,color)\n",
    "                back_prop(winner_roll,path,color0,mcts_dict)\n",
    "                break\n",
    "    \n",
    "    # pick the move with best average reward\n",
    "    best_col = -1\n",
    "    max_score = -np.inf\n",
    "    for col in legal0:\n",
    "        new_board = tuple(update_board(board,color0,col).ravel())\n",
    "        num_sims, total_val = mcts_dict[new_board]\n",
    "        if num_sims == 0:\n",
    "            # means we never visited it\n",
    "            score = -np.inf\n",
    "        else:\n",
    "            score = total_val/num_sims\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            best_col = col\n",
    "\n",
    "    return best_col\n",
    "\n",
    "\n",
    "def board_to_6x7x2(board_2d):\n",
    "    \"\"\"\n",
    "    Convert a 6x7 board with +1, -1, 0 \n",
    "    into a 6x7x2 one-hot style representation:\n",
    "       channel 0 => +1 positions\n",
    "       channel 1 => -1 positions\n",
    "    \"\"\"\n",
    "    X = np.zeros((6,7,2), dtype=np.float32)\n",
    "    for i in range(6):\n",
    "        for j in range(7):\n",
    "            if board_2d[i,j] == 1:\n",
    "                X[i,j,0] = 1\n",
    "            elif board_2d[i,j] == -1:\n",
    "                X[i,j,1] = 1\n",
    "    return X\n",
    "\n",
    "def minus_to_plus(board_6x7x2):\n",
    "    \"\"\"\n",
    "    Flip a (6,7,2) board from 'minus perspective' to 'plus perspective'\n",
    "    by swapping channels 0 and 1.\n",
    "      channel 0 => +1 squares\n",
    "      channel 1 => -1 squares\n",
    "    If originally channel 1 was the 'minus' squares, \n",
    "    after swap, that becomes the 'plus' squares, etc.\n",
    "    \"\"\"\n",
    "    flipped = board_6x7x2.copy()\n",
    "    flipped[..., 0], flipped[..., 1] = board_6x7x2[..., 1], board_6x7x2[..., 0]\n",
    "    return flipped\n",
    "\n",
    "def add_symmetric_flips(board_6x7x2, best_move):\n",
    "    \"\"\"\n",
    "    Given a (6,7,2) board and an integer best_move in [0..6],\n",
    "    return a list of:\n",
    "      [(original_board_6x7x2, best_move),\n",
    "       (flipped_board_6x7x2, flipped_move)].\n",
    "    The flipped version is mirrored left-to-right (column j -> 6-j).\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    \n",
    "    # 1) Original\n",
    "    out.append((board_6x7x2, best_move))\n",
    "    \n",
    "    # 2) Flipped left-right\n",
    "    flipped_board = board_6x7x2[:, ::-1, :].copy()\n",
    "    flipped_col = 6 - best_move\n",
    "    out.append((flipped_board, flipped_col))\n",
    "    \n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_one_game(plus_mcts_steps=800,\n",
    "                  minus_mcts_steps=800,\n",
    "                  random_openings=2):\n",
    "    \"\"\"\n",
    "    Returns a list of (board_6x7x2, best_move, skill_level),\n",
    "    where 'skill_level' is whichever MCTS steps were used.\n",
    "    For 'minus', we also flip the board to plus perspective.\n",
    "    We do NOT store random moves.\n",
    "    \"\"\"\n",
    "    data_this_game = []\n",
    "    board = np.zeros((6, 7), dtype=np.float32)\n",
    "    winner = 'nobody'\n",
    "    player = 'plus'\n",
    "    move_count = 0\n",
    "\n",
    "    while winner == 'nobody':\n",
    "        legal = find_legal(board)\n",
    "        if len(legal) == 0:\n",
    "            break  # tie\n",
    "\n",
    "        use_random = False\n",
    "        if move_count < 2 * random_openings:\n",
    "            use_random = True\n",
    "\n",
    "        if use_random:\n",
    "            col = random.choice(legal)\n",
    "            skill_used = 0  # skill=0 for random (we won't store these anyway)\n",
    "        else:\n",
    "            if player == 'plus':\n",
    "                col = mcts(board, 'plus', plus_mcts_steps)\n",
    "                skill_used = plus_mcts_steps\n",
    "            else:\n",
    "                col = mcts(board, 'minus', minus_mcts_steps)\n",
    "                skill_used = minus_mcts_steps\n",
    "\n",
    "        old_board = board.copy()\n",
    "        board = update_board(board, player, col)\n",
    "        winner = check_for_win(board, col)\n",
    "\n",
    "        if not use_random:\n",
    "            if player == 'plus':\n",
    "                board_6x7x2 = board_to_6x7x2(old_board)\n",
    "                # store (board, move, skill)\n",
    "                data_this_game.append((board_6x7x2, col, skill_used))\n",
    "            else:\n",
    "                board_6x7x2_minus = board_to_6x7x2(old_board)\n",
    "                board_6x7x2_plus = minus_to_plus(board_6x7x2_minus)\n",
    "                data_this_game.append((board_6x7x2_plus, col, skill_used))\n",
    "\n",
    "        player = 'minus' if (player == 'plus') else 'plus'\n",
    "        move_count += 1\n",
    "\n",
    "    return data_this_game\n",
    "\n",
    "def play_one_game_random_params():\n",
    "    \"\"\"\n",
    "    Roll random settings for plus/minus MCTS [500..5000],\n",
    "    and random_openings [1..15].\n",
    "    Return list of (board_6x7x2, best_move, skill).\n",
    "    \"\"\"\n",
    "    plus_mcts = random.randint(500, 5000)\n",
    "    minus_mcts = random.randint(500, 5000)\n",
    "    openings = random.randint(1, 15)\n",
    "    game_data = play_one_game(\n",
    "        plus_mcts_steps=plus_mcts,\n",
    "        minus_mcts_steps=minus_mcts,\n",
    "        random_openings=openings\n",
    "    )\n",
    "    return game_data  # list of (board, move, skill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_build_dataset(num_games=25000):\n",
    "    \"\"\"\n",
    "    Use joblib to run 'play_one_game_random_params()' in parallel.\n",
    "\n",
    "    data_dict will map:\n",
    "      key = (6,7,2) board .tobytes()\n",
    "      => { 'best_skill': int,\n",
    "           'move_counts': { move: (count) } }\n",
    "\n",
    "    If a new skill > best_skill, override the entire move_counts with the new move.\n",
    "    If skill == best_skill, we increment counts for that move as usual.\n",
    "    If skill < best_skill, ignore it (we keep the higher skill's recommendation).\n",
    "    \"\"\"\n",
    "    print(f\"Building dataset with {num_games} games in parallel...\")\n",
    "\n",
    "    results = Parallel(n_jobs=-1, backend='loky')(\n",
    "        delayed(play_one_game_random_params)()\n",
    "        for _ in range(num_games)\n",
    "    )\n",
    "\n",
    "    # data_dict: \n",
    "    #   key -> {'best_skill': X,\n",
    "    #           'move_counts': {move -> count}}\n",
    "    data_dict = defaultdict(lambda: {\"best_skill\": 0, \"move_counts\": defaultdict(int)})\n",
    "\n",
    "    print(\"Aggregating results & handling collisions with skill priority...\")\n",
    "\n",
    "    for game_data in results:\n",
    "        # game_data is list of (board_6x7x2, best_move, skill)\n",
    "        for (board_6x7x2, best_move, skill_used) in game_data:\n",
    "            # augment with symmetry\n",
    "            augmented = add_symmetric_flips(board_6x7x2, best_move)\n",
    "\n",
    "            for (b_aug, m_aug) in augmented:\n",
    "                key = b_aug.tobytes()\n",
    "                entry = data_dict[key]\n",
    "\n",
    "                current_best_skill = entry[\"best_skill\"]\n",
    "                move_counts = entry[\"move_counts\"]\n",
    "\n",
    "                if skill_used > current_best_skill:\n",
    "                    # override entire dictionary with new skill\n",
    "                    # and reset move_counts\n",
    "                    entry[\"best_skill\"] = skill_used\n",
    "                    entry[\"move_counts\"] = defaultdict(int)\n",
    "                    entry[\"move_counts\"][m_aug] = 1\n",
    "                elif skill_used == current_best_skill:\n",
    "                    # same skill -> just increment\n",
    "                    entry[\"move_counts\"][m_aug] += 1\n",
    "                else:\n",
    "                    # skill_used < current_best_skill => ignore\n",
    "                    pass\n",
    "\n",
    "    # Now resolve collisions by picking the move with the highest count\n",
    "    # for each board. We already only store moves from the highest skill.\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    for key, val in data_dict.items():\n",
    "        move_dict = val[\"move_counts\"]\n",
    "        # pick move with max count\n",
    "        if len(move_dict) == 0:\n",
    "            # might happen if skill=0 or something unexpected\n",
    "            continue\n",
    "        best_move = max(move_dict, key=move_dict.get)\n",
    "        arr = np.frombuffer(key, dtype=np.float32).reshape(6,7,2)\n",
    "        X_list.append(arr)\n",
    "        y_list.append(best_move)\n",
    "\n",
    "    X = np.stack(X_list, axis=0)\n",
    "    y = np.array(y_list, dtype=np.int32)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    NUM_GAMES = 50000\n",
    "    X, y = parallel_build_dataset(num_games=NUM_GAMES)\n",
    "    print(\"Finished building dataset!\")\n",
    "    print(\"X shape:\", X.shape)\n",
    "    print(\"y shape:\", y.shape)\n",
    "    print(\"Unique moves in y:\", np.unique(y))\n",
    "\n",
    "    # Save to disk\n",
    "    np.save(\"X_dataset_ethan3.npy\", X)\n",
    "    np.save(\"y_dataset_ethan3.npy\", y)\n",
    "    print(\"Dataset saved to X_dataset_ethan3.npy and y_dataset_ethan3.npy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before concatenation:\n",
      "  Dataset 1: (457185, 6, 7, 2) (457185,)\n",
      "  Dataset 2: (465707, 6, 7, 2) (465707,)\n",
      "After concatenation: (922892, 6, 7, 2) (922892,)\n",
      "Saved merged dataset to X_dataset_merged.npy, y_dataset_merged.npy.\n"
     ]
    }
   ],
   "source": [
    "# Append dataset code\n",
    "\n",
    "def append_datasets(file1_X, file1_y, file2_X, file2_y, out_X, out_y):\n",
    "    \"\"\"\n",
    "    Load two Connect4 datasets (X1,y1) and (X2,y2),\n",
    "    concatenate them along axis=0,\n",
    "    then save as (out_X, out_y).\n",
    "    \"\"\"\n",
    "    X1 = np.load(file1_X)\n",
    "    y1 = np.load(file1_y)\n",
    "    X2 = np.load(file2_X)\n",
    "    y2 = np.load(file2_y)\n",
    "\n",
    "    print(\"Before concatenation:\")\n",
    "    print(\"  Dataset 1:\", X1.shape, y1.shape)\n",
    "    print(\"  Dataset 2:\", X2.shape, y2.shape)\n",
    "\n",
    "    X_merged = np.concatenate([X1, X2], axis=0)\n",
    "    y_merged = np.concatenate([y1, y2], axis=0)\n",
    "\n",
    "    print(\"After concatenation:\", X_merged.shape, y_merged.shape)\n",
    "\n",
    "    np.save(out_X, X_merged)\n",
    "    np.save(out_y, y_merged)\n",
    "    print(f\"Saved merged dataset to {out_X}, {out_y}.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    append_datasets(\n",
    "        file1_X=\"X_dataset_ethan.npy\",\n",
    "        file1_y=\"y_dataset_ethan.npy\",\n",
    "        file2_X=\"X_dataset_ethan2.npy\",\n",
    "        file2_y=\"y_dataset_ethan2.npy\",\n",
    "        out_X=\"X_dataset_merged.npy\",\n",
    "        out_y=\"y_dataset_merged.npy\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes:\n",
      "X: (900019, 6, 7, 2)\n",
      "y: (900019,)\n",
      "Unique moves in y: [0 1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "X_file = \"X_dataset_ethan3.npy\"\n",
    "y_file = \"y_dataset_ethan3.npy\"\n",
    "\n",
    "X = np.load(X_file)  # shape (N, 6, 7, 2)\n",
    "y = np.load(y_file)  # shape (N,)\n",
    "\n",
    "print(\"Data shapes:\")\n",
    "print(\"X:\", X.shape)\n",
    "print(\"y:\", y.shape)\n",
    "unique_moves = np.unique(y)\n",
    "print(\"Unique moves in y:\", unique_moves)  # should be [0..6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 720015\n",
      "Validation set size: 180004\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.2, \n",
    "    random_state=22, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(\"Training set size:\", X_train.shape[0])\n",
    "print(\"Validation set size:\", X_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAvailable GPUs:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Res-Net Style CNN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNetBigger\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 6, 7, 2)]    0           []                               \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 6, 7, 64)     1216        ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 6, 7, 64)    256         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_24 (ReLU)                (None, 6, 7, 64)     0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_24[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 6, 7, 64)    256         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_25 (ReLU)                (None, 6, 7, 64)     0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_25[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 6, 7, 64)    256         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_26 (ReLU)                (None, 6, 7, 64)     0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_26[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 6, 7, 64)    256         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 6, 7, 64)     0           ['re_lu_25[0][0]',               \n",
      "                                                                  'batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_27 (ReLU)                (None, 6, 7, 64)     0           ['add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_27[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 6, 7, 64)    256         ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_28 (ReLU)                (None, 6, 7, 64)     0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_28[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 6, 7, 64)    256         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 6, 7, 64)     0           ['re_lu_27[0][0]',               \n",
      "                                                                  'batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_29 (ReLU)                (None, 6, 7, 64)     0           ['add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_29[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 6, 7, 64)    256         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_30 (ReLU)                (None, 6, 7, 64)     0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_30[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 6, 7, 64)    256         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 6, 7, 64)     0           ['re_lu_29[0][0]',               \n",
      "                                                                  'batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_31 (ReLU)                (None, 6, 7, 64)     0           ['add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 3, 3, 64)    0           ['re_lu_31[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 3, 3, 128)    8320        ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 3, 3, 128)   512         ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_32 (ReLU)                (None, 3, 3, 128)    0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 3, 3, 128)    147584      ['re_lu_32[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 3, 3, 128)   512         ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_33 (ReLU)                (None, 3, 3, 128)    0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 3, 3, 128)    147584      ['re_lu_33[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 3, 3, 128)   512         ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 3, 3, 128)    0           ['re_lu_32[0][0]',               \n",
      "                                                                  'batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_34 (ReLU)                (None, 3, 3, 128)    0           ['add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 3, 3, 128)    147584      ['re_lu_34[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 3, 3, 128)   512         ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_35 (ReLU)                (None, 3, 3, 128)    0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 3, 3, 128)    147584      ['re_lu_35[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 3, 3, 128)   512         ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 3, 3, 128)    0           ['re_lu_34[0][0]',               \n",
      "                                                                  'batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_36 (ReLU)                (None, 3, 3, 128)    0           ['add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 128)   0           ['re_lu_36[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 1, 1, 128)    147584      ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 1, 1, 128)   512         ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_37 (ReLU)                (None, 1, 1, 128)    0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 1, 1, 128)    147584      ['re_lu_37[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 1, 1, 128)   512         ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 1, 1, 128)    0           ['max_pooling2d_3[0][0]',        \n",
      "                                                                  'batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_38 (ReLU)                (None, 1, 1, 128)    0           ['add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 1, 1, 128)    147584      ['re_lu_38[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 1, 1, 128)   512         ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_39 (ReLU)                (None, 1, 1, 128)    0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 1, 1, 128)    147584      ['re_lu_39[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 1, 1, 128)   512         ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 1, 1, 128)    0           ['re_lu_38[0][0]',               \n",
      "                                                                  'batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_40 (ReLU)                (None, 1, 1, 128)    0           ['add_15[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 1, 1, 256)    33024       ['re_lu_40[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 1, 1, 256)   1024        ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_41 (ReLU)                (None, 1, 1, 256)    0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 1, 1, 256)    590080      ['re_lu_41[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 1, 1, 256)   1024        ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_42 (ReLU)                (None, 1, 1, 256)    0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 1, 1, 256)    590080      ['re_lu_42[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 1, 1, 256)   1024        ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 1, 1, 256)    0           ['re_lu_41[0][0]',               \n",
      "                                                                  'batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_43 (ReLU)                (None, 1, 1, 256)    0           ['add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 1, 1, 256)    590080      ['re_lu_43[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 1, 1, 256)   1024        ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_44 (ReLU)                (None, 1, 1, 256)    0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 1, 1, 256)    590080      ['re_lu_44[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 1, 1, 256)   1024        ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 1, 1, 256)    0           ['re_lu_43[0][0]',               \n",
      "                                                                  'batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_45 (ReLU)                (None, 1, 1, 256)    0           ['add_17[0][0]']                 \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 256)          0           ['re_lu_45[0][0]']               \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1024)         263168      ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 1024)        4096        ['dense_3[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_46 (ReLU)                (None, 1024)         0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 1024)         0           ['re_lu_46[0][0]']               \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 512)          524800      ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 512)         2048        ['dense_4[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_47 (ReLU)                (None, 512)          0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 512)          0           ['re_lu_47[0][0]']               \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 7)            3591        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,651,527\n",
      "Trainable params: 4,642,567\n",
      "Non-trainable params: 8,960\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def residual_block(x, filters, kernel_size=(3,3), l2_reg=1e-6):\n",
    "    \"\"\"\n",
    "    A basic ResNet-style block:\n",
    "      - 3x3 Conv -> BN -> ReLU\n",
    "      - 3x3 Conv -> BN\n",
    "      - skip connection\n",
    "      - final ReLU\n",
    "    \"\"\"\n",
    "    shortcut = x\n",
    "\n",
    "    # 1st conv\n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same',\n",
    "                      kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 2nd conv\n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same',\n",
    "                      kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # skip connection\n",
    "    x = layers.Add()([shortcut, x])\n",
    "    x = layers.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "def build_resnet_bigger(\n",
    "    input_shape=(6,7,2),\n",
    "    num_classes=7,\n",
    "    l2_reg=1e-6,\n",
    "    dropout_rate=0.05\n",
    "):\n",
    "    \"\"\"\n",
    "    A bigger ResNet CNN for Connect 4.\n",
    "    Architecture:\n",
    "      1) Wide stem: conv(64)->(64) \n",
    "      2) 3 residual blocks at 64\n",
    "      3) MaxPool\n",
    "      4) Expand to 128\n",
    "      5) 2 residual blocks at 128\n",
    "      6) MaxPool\n",
    "      7) 2 residual blocks at 128\n",
    "      8) Expand to 256\n",
    "      9) 2 residual blocks at 256\n",
    "      10) Flatten\n",
    "      11) Dense(1024)->BN->ReLU->Dropout\n",
    "      12) Dense(512)->BN->ReLU->Dropout\n",
    "      13) Output(7, softmax)\n",
    "    \"\"\"\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # ==============\n",
    "    # 1. Wide Stem\n",
    "    # ==============\n",
    "    x = layers.Conv2D(64, (3,3), padding='same',\n",
    "                      kernel_regularizer=regularizers.l2(l2_reg))(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    x = layers.Conv2D(64, (3,3), padding='same',\n",
    "                      kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # ==============\n",
    "    # 2. 3 residual blocks at 64\n",
    "    # ==============\n",
    "    x = residual_block(x, filters=64,  l2_reg=l2_reg)\n",
    "    x = residual_block(x, filters=64,  l2_reg=l2_reg)\n",
    "    x = residual_block(x, filters=64,  l2_reg=l2_reg)\n",
    "\n",
    "    # 3. MaxPool\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), strides=2)(x)\n",
    "\n",
    "    # 4. Expand to 128\n",
    "    x = layers.Conv2D(128, (1,1), padding='same',\n",
    "                      kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 5. 2 residual blocks at 128\n",
    "    x = residual_block(x, filters=128, l2_reg=l2_reg)\n",
    "    x = residual_block(x, filters=128, l2_reg=l2_reg)\n",
    "\n",
    "    # 6. MaxPool\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), strides=2)(x)\n",
    "\n",
    "    # 7. 2 residual blocks at 128\n",
    "    x = residual_block(x, filters=128, l2_reg=l2_reg)\n",
    "    x = residual_block(x, filters=128, l2_reg=l2_reg)\n",
    "\n",
    "    # ==============\n",
    "    # 8. Expand to 256\n",
    "    # ==============\n",
    "    x = layers.Conv2D(256, (1,1), padding='same',\n",
    "                      kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 9. 2 residual blocks at 256\n",
    "    x = residual_block(x, filters=256, l2_reg=l2_reg)\n",
    "    x = residual_block(x, filters=256, l2_reg=l2_reg)\n",
    "\n",
    "    # flatten\n",
    "    x = layers.Flatten()(x)\n",
    "\n",
    "    # 11. Dense(1024)\n",
    "    x = layers.Dense(1024, kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    # 12. Dense(512)\n",
    "    x = layers.Dense(512, kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    # 13. Output\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs, outputs, name=\"ResNetBigger\")\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = build_resnet_bigger(\n",
    "        input_shape=(6,7,2),\n",
    "        num_classes=7,\n",
    "        l2_reg=1e-6,\n",
    "        dropout_rate=0.05\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.007),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11251/11251 [==============================] - 156s 14ms/step - loss: 1.2488 - accuracy: 0.5237 - val_loss: 0.9558 - val_accuracy: 0.6377 - lr: 0.0070\n",
      "Epoch 2/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.9407 - accuracy: 0.6488 - val_loss: 0.9086 - val_accuracy: 0.6640 - lr: 0.0070\n",
      "Epoch 3/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.8987 - accuracy: 0.6676 - val_loss: 0.8976 - val_accuracy: 0.6675 - lr: 0.0070\n",
      "Epoch 4/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.8787 - accuracy: 0.6762 - val_loss: 0.8829 - val_accuracy: 0.6742 - lr: 0.0070\n",
      "Epoch 5/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.8665 - accuracy: 0.6809 - val_loss: 0.8550 - val_accuracy: 0.6830 - lr: 0.0070\n",
      "Epoch 6/100\n",
      "11251/11251 [==============================] - 152s 14ms/step - loss: 0.8570 - accuracy: 0.6850 - val_loss: 0.8479 - val_accuracy: 0.6873 - lr: 0.0070\n",
      "Epoch 7/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.8493 - accuracy: 0.6879 - val_loss: 0.8489 - val_accuracy: 0.6825 - lr: 0.0070\n",
      "Epoch 8/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.8449 - accuracy: 0.6895 - val_loss: 0.8449 - val_accuracy: 0.6884 - lr: 0.0070\n",
      "Epoch 9/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.8393 - accuracy: 0.6920 - val_loss: 0.8395 - val_accuracy: 0.6933 - lr: 0.0070\n",
      "Epoch 10/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.8363 - accuracy: 0.6927 - val_loss: 0.8441 - val_accuracy: 0.6859 - lr: 0.0070\n",
      "Epoch 11/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.8329 - accuracy: 0.6943 - val_loss: 0.8424 - val_accuracy: 0.6921 - lr: 0.0070\n",
      "Epoch 12/100\n",
      "11250/11251 [============================>.] - ETA: 0s - loss: 0.8314 - accuracy: 0.6944\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0035000001080334187.\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.8314 - accuracy: 0.6944 - val_loss: 0.8295 - val_accuracy: 0.6921 - lr: 0.0070\n",
      "Epoch 13/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.7818 - accuracy: 0.7105 - val_loss: 0.7729 - val_accuracy: 0.7129 - lr: 0.0035\n",
      "Epoch 14/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.7678 - accuracy: 0.7146 - val_loss: 0.7721 - val_accuracy: 0.7114 - lr: 0.0035\n",
      "Epoch 15/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.7610 - accuracy: 0.7157 - val_loss: 0.7672 - val_accuracy: 0.7111 - lr: 0.0035\n",
      "Epoch 16/100\n",
      "11250/11251 [============================>.] - ETA: 0s - loss: 0.7569 - accuracy: 0.7167\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0017500000540167093.\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.7569 - accuracy: 0.7167 - val_loss: 0.7725 - val_accuracy: 0.7113 - lr: 0.0035\n",
      "Epoch 17/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.7247 - accuracy: 0.7283 - val_loss: 0.7442 - val_accuracy: 0.7188 - lr: 0.0018\n",
      "Epoch 18/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.7139 - accuracy: 0.7314 - val_loss: 0.7396 - val_accuracy: 0.7202 - lr: 0.0018\n",
      "Epoch 19/100\n",
      "11251/11251 [==============================] - 152s 14ms/step - loss: 0.7090 - accuracy: 0.7329 - val_loss: 0.7461 - val_accuracy: 0.7203 - lr: 0.0018\n",
      "Epoch 20/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.7051 - accuracy: 0.7341 - val_loss: 0.7412 - val_accuracy: 0.7203 - lr: 0.0018\n",
      "Epoch 21/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.7014 - accuracy: 0.7346 - val_loss: 0.7405 - val_accuracy: 0.7195 - lr: 0.0018\n",
      "Epoch 22/100\n",
      "11248/11251 [============================>.] - ETA: 0s - loss: 0.6977 - accuracy: 0.7361\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0008750000270083547.\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.6977 - accuracy: 0.7361 - val_loss: 0.7389 - val_accuracy: 0.7200 - lr: 0.0018\n",
      "Epoch 23/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.6752 - accuracy: 0.7447 - val_loss: 0.7331 - val_accuracy: 0.7245 - lr: 8.7500e-04\n",
      "Epoch 24/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.6682 - accuracy: 0.7471 - val_loss: 0.7359 - val_accuracy: 0.7229 - lr: 8.7500e-04\n",
      "Epoch 25/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.6647 - accuracy: 0.7478 - val_loss: 0.7342 - val_accuracy: 0.7240 - lr: 8.7500e-04\n",
      "Epoch 26/100\n",
      "11247/11251 [============================>.] - ETA: 0s - loss: 0.6609 - accuracy: 0.7490\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00043750001350417733.\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.6609 - accuracy: 0.7490 - val_loss: 0.7355 - val_accuracy: 0.7235 - lr: 8.7500e-04\n",
      "Epoch 27/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.6454 - accuracy: 0.7543 - val_loss: 0.7385 - val_accuracy: 0.7245 - lr: 4.3750e-04\n",
      "Epoch 28/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.6413 - accuracy: 0.7558 - val_loss: 0.7401 - val_accuracy: 0.7235 - lr: 4.3750e-04\n",
      "Epoch 29/100\n",
      "11248/11251 [============================>.] - ETA: 0s - loss: 0.6386 - accuracy: 0.7570\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00021875000675208867.\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.6386 - accuracy: 0.7570 - val_loss: 0.7418 - val_accuracy: 0.7230 - lr: 4.3750e-04\n",
      "Epoch 30/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.6295 - accuracy: 0.7603 - val_loss: 0.7452 - val_accuracy: 0.7237 - lr: 2.1875e-04\n",
      "Epoch 31/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.6270 - accuracy: 0.7610 - val_loss: 0.7448 - val_accuracy: 0.7237 - lr: 2.1875e-04\n",
      "Epoch 32/100\n",
      "11248/11251 [============================>.] - ETA: 0s - loss: 0.6254 - accuracy: 0.7612\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00010937500337604433.\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.6254 - accuracy: 0.7612 - val_loss: 0.7468 - val_accuracy: 0.7227 - lr: 2.1875e-04\n",
      "Epoch 33/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.6198 - accuracy: 0.7639 - val_loss: 0.7499 - val_accuracy: 0.7234 - lr: 1.0938e-04\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 64\n",
    "\n",
    "# Early stopping if val_accuracy doesnt improve for 7 epochs\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Reduce learning rate by factor of 0.5 if val_accuracy doesnt improve for 3 epochs\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 72.45%   (loss=0.7331)\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(f\"Validation accuracy: {val_acc*100:.2f}%   (loss={val_loss:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to cnn_connect4.h5.\n"
     ]
    }
   ],
   "source": [
    "#model.save(\"cnn_connect4.h5\")\n",
    "#print(\"Model saved to cnn_connect4.h5.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Plot loss\n",
    "axs[0].plot(history.history['loss'], label='train_loss')\n",
    "axs[0].plot(history.history['val_loss'], label='val_loss')\n",
    "axs[0].set_title(\"Loss\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "# Plot accuracy\n",
    "axs[1].plot(history.history['accuracy'], label='train_acc')\n",
    "axs[1].plot(history.history['val_accuracy'], label='val_acc')\n",
    "axs[1].set_title(\"Accuracy\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Accuracy\")\n",
    "axs[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Testing vs MCTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_pick_move(board_2d, model, color='plus'):\n",
    "    \"\"\"\n",
    "    Given a 6x7 board (board_2d) and a trained Keras model,\n",
    "    pick the column with highest predicted probability (from the CNN)\n",
    "    that is also legal.\n",
    "    \n",
    "    If 'color' == 'minus', we flip channels so the CNN sees \"plus perspective.\"\n",
    "    That means channel 0 => squares of +1, channel 1 => squares of -1.\n",
    "    \n",
    "    Return: int column in [0..6].\n",
    "    \"\"\"\n",
    "    # Convert board to 6x7x2 representation\n",
    "    from_board = board_to_6x7x2(board_2d)\n",
    "    \n",
    "    if color == 'minus':\n",
    "        # Flip minus -> plus perspective\n",
    "        from_board = minus_to_plus(from_board)\n",
    "\n",
    "    # Model expects shape (N, 6, 7, 2). So expand dims.\n",
    "    input_for_model = np.expand_dims(from_board, axis=0)  # (1,6,7,2)\n",
    "    \n",
    "    # Predict probabilities for each column\n",
    "    # shape: (1,7)\n",
    "    pred_probs = model.predict(input_for_model, verbose=0)[0]  # (7,)\n",
    "\n",
    "    # Sort columns by descending probability\n",
    "    columns_ranked = np.argsort(pred_probs)[::-1]  # highest -> lowest\n",
    "\n",
    "    # Find a legal column among the top predictions\n",
    "    legal_cols = find_legal(board_2d)\n",
    "    for col in columns_ranked:\n",
    "        if col in legal_cols:\n",
    "            return col\n",
    "\n",
    "    # Fallback: if something weird happened (all top columns were illegal),\n",
    "    # pick a random legal column\n",
    "    if len(legal_cols) > 0:\n",
    "        return random.choice(legal_cols)\n",
    "    else:\n",
    "        return 0  # if no columns are legal, game is effectively a tie/loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_one_game_CNN_vs_MCTS(model, mcts_steps_minus=300, verbose=False):\n",
    "    \"\"\"\n",
    "    Let the CNN play as 'plus' and MCTS play as 'minus' with mcts_steps_minus.\n",
    "    Returns: winner (str), number_of_moves\n",
    "             where winner is in { 'nobody', 'v-plus', 'v-minus', 'h-plus', ... etc. }\n",
    "    \"\"\"\n",
    "    board = np.zeros((6,7), dtype=np.float32)\n",
    "    winner = 'nobody'\n",
    "    player = 'plus'\n",
    "    move_count = 0\n",
    "\n",
    "    while winner == 'nobody':\n",
    "        legal = find_legal(board)\n",
    "        if len(legal) == 0:\n",
    "            # tie\n",
    "            break\n",
    "\n",
    "        if player == 'plus':\n",
    "            col = cnn_pick_move(board, model, color='plus')\n",
    "        else:\n",
    "            col = mcts(board, 'minus', mcts_steps_minus)\n",
    "\n",
    "        board = update_board(board, player, col)\n",
    "        winner = check_for_win(board, col)\n",
    "        \n",
    "        move_count += 1\n",
    "        \n",
    "        if player == 'plus':\n",
    "            player = 'minus'\n",
    "        else:\n",
    "            player = 'plus'\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Move {move_count}, {player}, col={col}\")\n",
    "\n",
    "    return winner, move_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_CNN_vs_MCTS(model, num_games=100, mcts_steps_minus=300, verbose=False):\n",
    "    \"\"\"\n",
    "    Play 'num_games' between:\n",
    "      - CNN as 'plus'\n",
    "      - MCTS as 'minus' with mcts_steps_minus\n",
    "    Track how many times plus wins, minus wins, or tie.\n",
    "    Also track average length of game (moves).\n",
    "    \n",
    "    Returns: \n",
    "      plus_wins, minus_wins, ties, avg_moves\n",
    "    \"\"\"\n",
    "    plus_wins = 0\n",
    "    minus_wins = 0\n",
    "    ties = 0\n",
    "    total_moves = 0\n",
    "\n",
    "    for g in range(num_games):\n",
    "        winner, moves = play_one_game_CNN_vs_MCTS(\n",
    "            model,\n",
    "            mcts_steps_minus=mcts_steps_minus,\n",
    "            verbose=verbose\n",
    "        )\n",
    "        total_moves += moves\n",
    "\n",
    "        if winner == 'nobody' or winner == 'tie':\n",
    "            ties += 1\n",
    "        elif winner.endswith('plus'):\n",
    "            plus_wins += 1\n",
    "        elif winner.endswith('minus'):\n",
    "            minus_wins += 1\n",
    "        else:\n",
    "            if winner[-4:] == 'plus':\n",
    "                plus_wins += 1\n",
    "            else:\n",
    "                minus_wins += 1\n",
    "    \n",
    "    avg_moves = total_moves / num_games if num_games > 0 else 0\n",
    "    \n",
    "    return plus_wins, minus_wins, ties, avg_moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 50 games vs. MCTS(1000 steps):\n",
      "  CNN (plus) wins:  35\n",
      "  MCTS (minus) wins: 15\n",
      "  Ties: 0\n",
      "  Average number of moves per game: 30.3\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #model = tf.keras.models.load_model(\"cnn_connect4.h5\")\n",
    "    \n",
    "    num_games = 50\n",
    "    mcts_steps = 1000  # how many MCTS steps minus uses\n",
    "\n",
    "    pw, mw, ts, am = test_CNN_vs_MCTS(model, num_games=num_games, mcts_steps_minus=mcts_steps, verbose=False)\n",
    "    \n",
    "    print(f\"Out of {num_games} games vs. MCTS({mcts_steps} steps):\")\n",
    "    print(f\"  CNN (plus) wins:  {pw}\")\n",
    "    print(f\"  MCTS (minus) wins: {mw}\")\n",
    "    print(f\"  Ties: {ts}\")\n",
    "    print(f\"  Average number of moves per game: {am:.1f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
