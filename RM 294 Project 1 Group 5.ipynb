{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #type: ignore\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from IPython.display import clear_output #type: ignore\n",
    "import tensorflow as tf #type: ignore\n",
    "from tensorflow.keras import layers, models, regularizers #type: ignore\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split #type: ignore\n",
    "import matplotlib.pyplot as plt #type: ignore\n",
    "from joblib import Parallel, delayed  # for parallelism\n",
    "import multiprocessing\n",
    "\n",
    "SEED = 22\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect Four and MCTS Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_board(board_temp,color,column):\n",
    "    board = board_temp.copy()\n",
    "    colsum = abs(board[0,column])+abs(board[1,column])+abs(board[2,column])+abs(board[3,column])+abs(board[4,column])+abs(board[5,column])\n",
    "    row = int(5-colsum)\n",
    "    if row > -0.5:\n",
    "        if color == 'plus':\n",
    "            board[row,column] = 1\n",
    "        else:\n",
    "            board[row,column] = -1\n",
    "    return board\n",
    "    \n",
    "def check_for_win_slow(board):\n",
    "    nrow = board.shape[0]\n",
    "    ncol = board.shape[1]\n",
    "    winner = 'nobody'\n",
    "    for col in range(ncol):\n",
    "        for row in reversed(range(nrow)):\n",
    "            if abs(board[row,col]) < 0.1:\n",
    "                break\n",
    "            # vertical\n",
    "            if row <= (nrow-4):\n",
    "                tempsum = board[row,col]+board[row+1,col]+board[row+2,col]+board[row+3,col]\n",
    "                if tempsum==4:\n",
    "                    winner = 'v-plus'\n",
    "                    return winner\n",
    "                elif tempsum==-4:\n",
    "                    winner = 'v-minus'\n",
    "                    return winner\n",
    "            # horizontal\n",
    "            if col <= (ncol-4):\n",
    "                tempsum = board[row,col]+board[row,col+1]+board[row,col+2]+board[row,col+3]\n",
    "                if tempsum==4:\n",
    "                    winner = 'h-plus'\n",
    "                    return winner\n",
    "                elif tempsum==-4:\n",
    "                    winner = 'h-minus'\n",
    "                    return winner\n",
    "            # diagonal down-right\n",
    "            if (row <= (nrow-4)) and (col <= (ncol-4)):\n",
    "                tempsum = board[row,col]+board[row+1,col+1]+board[row+2,col+2]+board[row+3,col+3]\n",
    "                if tempsum==4:\n",
    "                    winner = 'd-plus'\n",
    "                    return winner\n",
    "                elif tempsum==-4:\n",
    "                    winner = 'd-minus'\n",
    "                    return winner\n",
    "            # diagonal down-left\n",
    "            if (row <= (nrow-4)) and (col >= 3):\n",
    "                tempsum = board[row,col]+board[row+1,col-1]+board[row+2,col-2]+board[row+3,col-3]\n",
    "                if tempsum==4:\n",
    "                    winner = 'd-plus'\n",
    "                    return winner\n",
    "                elif tempsum==-4:\n",
    "                    winner = 'd-minus'\n",
    "                    return winner\n",
    "    return winner\n",
    "\n",
    "def check_for_win(board,col):\n",
    "    nrow = 6\n",
    "    # figure out what row was just placed\n",
    "    colsum = abs(board[0,col])+abs(board[1,col])+abs(board[2,col])+abs(board[3,col])+abs(board[4,col])+abs(board[5,col])\n",
    "    row = int(6-colsum)\n",
    "    # vertical check\n",
    "    if row+3<6:\n",
    "        vert = board[row,col] + board[row+1,col] + board[row+2,col] + board[row+3,col]\n",
    "        if vert == 4:\n",
    "            return 'v-plus'\n",
    "        elif vert == -4:\n",
    "            return 'v-minus'\n",
    "    # horizontal checks (there are several)\n",
    "    # segment 0-3\n",
    "    if col+3<7:\n",
    "        hor = board[row,col] + board[row,col+1] + board[row,col+2] + board[row,col+3]\n",
    "        if hor == 4:\n",
    "            return 'h-plus'\n",
    "        elif hor == -4:\n",
    "            return 'h-minus'\n",
    "    # segment -1..+2\n",
    "    if col-1>=0 and col+2<7:\n",
    "        hor = board[row,col-1] + board[row,col] + board[row,col+1] + board[row,col+2]\n",
    "        if hor == 4:\n",
    "            return 'h-plus'\n",
    "        elif hor == -4:\n",
    "            return 'h-minus'\n",
    "    # segment -2..+1\n",
    "    if col-2>=0 and col+1<7:\n",
    "        hor = board[row,col-2] + board[row,col-1] + board[row,col] + board[row,col+1]\n",
    "        if hor == 4:\n",
    "            return 'h-plus'\n",
    "        elif hor == -4:\n",
    "            return 'h-minus'\n",
    "    # segment -3..0\n",
    "    if col-3>=0:\n",
    "        hor = board[row,col-3] + board[row,col-2] + board[row,col-1] + board[row,col]\n",
    "        if hor == 4:\n",
    "            return 'h-plus'\n",
    "        elif hor == -4:\n",
    "            return 'h-minus'\n",
    "    # diagonals down-right\n",
    "    if row < 3 and col < 4:\n",
    "        DR = board[row,col] + board[row+1,col+1] + board[row+2,col+2] + board[row+3,col+3]\n",
    "        if DR == 4:\n",
    "            return 'd-plus'\n",
    "        elif DR == -4:\n",
    "            return 'd-minus'\n",
    "    if row-1>=0 and col-1>=0 and row+2<6 and col+2<7:\n",
    "        DR = board[row-1,col-1] + board[row,col] + board[row+1,col+1] + board[row+2,col+2]\n",
    "        if DR == 4:\n",
    "            return 'd-plus'\n",
    "        elif DR == -4:\n",
    "            return 'd-minus'\n",
    "    if row-2>=0 and col-2>=0 and row+1<6 and col+1<7:\n",
    "        DR = board[row-2,col-2] + board[row-1,col-1] + board[row,col] + board[row+1,col+1]\n",
    "        if DR == 4:\n",
    "            return 'd-plus'\n",
    "        elif DR == -4:\n",
    "            return 'd-minus'\n",
    "    if row-3>=0 and col-3>=0:\n",
    "        DR = board[row-3,col-3] + board[row-2,col-2] + board[row-1,col-1] + board[row,col]\n",
    "        if DR == 4:\n",
    "            return 'd-plus'\n",
    "        elif DR == -4:\n",
    "            return 'd-minus'\n",
    "    # diagonals down-left\n",
    "    if row+3<6 and col-3>=0:\n",
    "        DL = board[row,col] + board[row+1,col-1] + board[row+2,col-2] + board[row+3,col-3]\n",
    "        if DL == 4:\n",
    "            return 'd-plus'\n",
    "        elif DL == -4:\n",
    "            return 'd-minus'\n",
    "    if row-1>=0 and col+1<7 and row+2<6 and col-2>=0:\n",
    "        DL = board[row-1,col+1] + board[row,col] + board[row+1,col-1] + board[row+2,col-2]\n",
    "        if DL == 4:\n",
    "            return 'd-plus'\n",
    "        elif DL == -4:\n",
    "            return 'd-minus'\n",
    "    if row-2>=0 and col+2<7 and row+1<6 and col-1>=0:\n",
    "        DL = board[row-2,col+2] + board[row-1,col+1] + board[row,col] + board[row+1,col-1]\n",
    "        if DL == 4:\n",
    "            return 'd-plus'\n",
    "        elif DL == -4:\n",
    "            return 'd-minus'\n",
    "    if row-3>=0 and col+3<7:\n",
    "        DL = board[row-3,col+3] + board[row-2,col+2] + board[row-1,col+1] + board[row,col]\n",
    "        if DL == 4:\n",
    "            return 'd-plus'\n",
    "        elif DL == -4:\n",
    "            return 'd-minus'\n",
    "    return 'nobody'\n",
    "\n",
    "def find_legal(board):\n",
    "    return [i for i in range(7) if abs(board[0,i]) < 0.1]\n",
    "\n",
    "def look_for_win(board_,color):\n",
    "    board_ = board_.copy()\n",
    "    legal = find_legal(board_)\n",
    "    winner_col = -1\n",
    "    for m in legal:\n",
    "        bt = update_board(board_.copy(),color,m)\n",
    "        wi = check_for_win(bt,m)\n",
    "        if wi[2:] == color:\n",
    "            winner_col = m\n",
    "            break\n",
    "    return winner_col\n",
    "\n",
    "def find_all_nonlosers(board,color):\n",
    "    if color == 'plus':\n",
    "        opp = 'minus'\n",
    "    else:\n",
    "        opp = 'plus'\n",
    "    legal = find_legal(board)\n",
    "    poss_boards = [update_board(board,color,l) for l in legal]\n",
    "    poss_legal = [find_legal(b) for b in poss_boards]\n",
    "    allowed = []\n",
    "    for i in range(len(legal)):\n",
    "        # if the opponent can immediately win after we move in col=legal[i], skip it\n",
    "        wins = [j for j in poss_legal[i] \n",
    "                if check_for_win(update_board(poss_boards[i],opp,j),j) != 'nobody']\n",
    "        if len(wins) == 0:\n",
    "            allowed.append(legal[i])\n",
    "    return allowed\n",
    "\n",
    "def back_prop(winner,path,color0,md):\n",
    "    for i, board_tuple in enumerate(path):\n",
    "        md[board_tuple][0] += 1\n",
    "        if winner[2] == color0[0]:\n",
    "            if i % 2 == 1:\n",
    "                md[board_tuple][1] += 1\n",
    "            else:\n",
    "                md[board_tuple][1] -= 1\n",
    "        elif winner[2] == 'e':\n",
    "            # tie => no change\n",
    "            pass\n",
    "        else:\n",
    "            if i % 2 == 1:\n",
    "                md[board_tuple][1] -= 1\n",
    "            else:\n",
    "                md[board_tuple][1] += 1\n",
    "\n",
    "def rollout(board,next_player):\n",
    "    winner = 'nobody'\n",
    "    player = next_player\n",
    "    while winner == 'nobody':\n",
    "        legal = find_legal(board)\n",
    "        if len(legal) == 0:\n",
    "            return 'tie'\n",
    "        move = random.choice(legal)\n",
    "        board = update_board(board,player,move)\n",
    "        winner = check_for_win(board,move)\n",
    "        # switch player\n",
    "        if player == 'plus':\n",
    "            player = 'minus'\n",
    "        else:\n",
    "            player = 'plus'\n",
    "    return winner\n",
    "        \n",
    "def mcts(board_temp,color0,nsteps):\n",
    "    # Traditional MCTS, plus small improvements:\n",
    "    board = board_temp.copy()\n",
    "    # 1. If there's an immediate winning move, use it\n",
    "    win_col = look_for_win(board,color0)\n",
    "    if win_col != -1:\n",
    "        return win_col\n",
    "    # 2. Look for any moves that avoid an immediate losing position\n",
    "    legal0 = find_all_nonlosers(board,color0)\n",
    "    if len(legal0) == 0:\n",
    "        # if no way to avoid opponent's immediate threat, use all legal moves\n",
    "        legal0 = find_legal(board)\n",
    "    \n",
    "    mcts_dict = {tuple(board.ravel()):[0,0]}\n",
    "    for _ in range(nsteps):\n",
    "        color = color0\n",
    "        winner = 'nobody'\n",
    "        board_mcts = board.copy()\n",
    "        path = [tuple(board_mcts.ravel())]\n",
    "        \n",
    "        while winner == 'nobody':\n",
    "            legal = find_legal(board_mcts)\n",
    "            if len(legal) == 0:\n",
    "                winner = 'tie'\n",
    "                back_prop(winner,path,color0,mcts_dict)\n",
    "                break\n",
    "            # list of next possible boards\n",
    "            board_list = []\n",
    "            for col in legal:\n",
    "                b_next = update_board(board_mcts,color,col)\n",
    "                board_list.append(tuple(b_next.ravel()))\n",
    "                if tuple(b_next.ravel()) not in mcts_dict:\n",
    "                    mcts_dict[tuple(b_next.ravel())] = [0,0]\n",
    "            \n",
    "            # UCB1 \n",
    "            ucb1 = np.zeros(len(legal))\n",
    "            for i, bl in enumerate(board_list):\n",
    "                num_sims, total_value = mcts_dict[bl]\n",
    "                if num_sims == 0:\n",
    "                    # large priority for unvisited\n",
    "                    ucb1[i] = 10 * nsteps\n",
    "                else:\n",
    "                    parent_sims = mcts_dict[path[-1]][0]\n",
    "                    avg_val = total_value / num_sims\n",
    "                    explore = np.sqrt(np.log(parent_sims)/num_sims)\n",
    "                    ucb1[i] = avg_val + 2*explore\n",
    "            \n",
    "            chosen = np.argmax(ucb1)\n",
    "            board_mcts = update_board(board_mcts,color,legal[chosen])\n",
    "            path.append(tuple(board_mcts.ravel()))\n",
    "            # check winner\n",
    "            winner = check_for_win(board_mcts,legal[chosen])\n",
    "            if winner[2] == color[0]:\n",
    "                back_prop(winner,path,color0,mcts_dict)\n",
    "                break\n",
    "            \n",
    "            # switch player\n",
    "            color = 'minus' if (color=='plus') else 'plus'\n",
    "            \n",
    "            # if the new board has never been visited, do a rollout\n",
    "            if mcts_dict[tuple(board_mcts.ravel())][0] == 0:\n",
    "                winner_roll = rollout(board_mcts,color)\n",
    "                back_prop(winner_roll,path,color0,mcts_dict)\n",
    "                break\n",
    "    \n",
    "    # pick the move with best average reward\n",
    "    best_col = -1\n",
    "    max_score = -np.inf\n",
    "    for col in legal0:\n",
    "        new_board = tuple(update_board(board,color0,col).ravel())\n",
    "        num_sims, total_val = mcts_dict[new_board]\n",
    "        if num_sims == 0:\n",
    "            # means we never visited it\n",
    "            score = -np.inf\n",
    "        else:\n",
    "            score = total_val/num_sims\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            best_col = col\n",
    "\n",
    "    return best_col\n",
    "\n",
    "\n",
    "def board_to_6x7x2(board_2d):\n",
    "    \"\"\"\n",
    "    Convert a 6x7 board with +1, -1, 0 \n",
    "    into a 6x7x2 one-hot style representation:\n",
    "       channel 0 => +1 positions\n",
    "       channel 1 => -1 positions\n",
    "    \"\"\"\n",
    "    X = np.zeros((6,7,2), dtype=np.float32)\n",
    "    for i in range(6):\n",
    "        for j in range(7):\n",
    "            if board_2d[i,j] == 1:\n",
    "                X[i,j,0] = 1\n",
    "            elif board_2d[i,j] == -1:\n",
    "                X[i,j,1] = 1\n",
    "    return X\n",
    "\n",
    "def minus_to_plus(board_6x7x2):\n",
    "    \"\"\"\n",
    "    Flip a (6,7,2) board from 'minus perspective' to 'plus perspective'\n",
    "    by swapping channels 0 and 1.\n",
    "      channel 0 => +1 squares\n",
    "      channel 1 => -1 squares\n",
    "    If originally channel 1 was the 'minus' squares, \n",
    "    after swap, that becomes the 'plus' squares, etc.\n",
    "    \"\"\"\n",
    "    flipped = board_6x7x2.copy()\n",
    "    flipped[..., 0], flipped[..., 1] = board_6x7x2[..., 1], board_6x7x2[..., 0]\n",
    "    return flipped\n",
    "\n",
    "def add_symmetric_flips(board_6x7x2, best_move):\n",
    "    \"\"\"\n",
    "    Given a (6,7,2) board and an integer best_move in [0..6],\n",
    "    return a list of:\n",
    "      [(original_board_6x7x2, best_move),\n",
    "       (flipped_board_6x7x2, flipped_move)].\n",
    "    The flipped version is mirrored left-to-right (column j -> 6-j).\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    \n",
    "    # 1) Original\n",
    "    out.append((board_6x7x2, best_move))\n",
    "    \n",
    "    # 2) Flipped left-right\n",
    "    flipped_board = board_6x7x2[:, ::-1, :].copy()\n",
    "    flipped_col = 6 - best_move\n",
    "    out.append((flipped_board, flipped_col))\n",
    "    \n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_one_game(plus_mcts_steps=800,\n",
    "                  minus_mcts_steps=800,\n",
    "                  random_openings=2):\n",
    "    \"\"\"\n",
    "    Returns a list of (board_6x7x2, best_move, skill_level),\n",
    "    where 'skill_level' is whichever MCTS steps were used.\n",
    "    For 'minus', we also flip the board to plus perspective.\n",
    "    We do NOT store random moves.\n",
    "    \"\"\"\n",
    "    data_this_game = []\n",
    "    board = np.zeros((6, 7), dtype=np.float32)\n",
    "    winner = 'nobody'\n",
    "    player = 'plus'\n",
    "    move_count = 0\n",
    "\n",
    "    while winner == 'nobody':\n",
    "        legal = find_legal(board)\n",
    "        if len(legal) == 0:\n",
    "            break  # tie\n",
    "\n",
    "        use_random = False\n",
    "        if move_count < 2 * random_openings:\n",
    "            use_random = True\n",
    "\n",
    "        if use_random:\n",
    "            col = random.choice(legal)\n",
    "            skill_used = 0  # skill=0 for random (we won't store these anyway)\n",
    "        else:\n",
    "            if player == 'plus':\n",
    "                col = mcts(board, 'plus', plus_mcts_steps)\n",
    "                skill_used = plus_mcts_steps\n",
    "            else:\n",
    "                col = mcts(board, 'minus', minus_mcts_steps)\n",
    "                skill_used = minus_mcts_steps\n",
    "\n",
    "        old_board = board.copy()\n",
    "        board = update_board(board, player, col)\n",
    "        winner = check_for_win(board, col)\n",
    "\n",
    "        if not use_random:\n",
    "            if player == 'plus':\n",
    "                board_6x7x2 = board_to_6x7x2(old_board)\n",
    "                # store (board, move, skill)\n",
    "                data_this_game.append((board_6x7x2, col, skill_used))\n",
    "            else:\n",
    "                board_6x7x2_minus = board_to_6x7x2(old_board)\n",
    "                board_6x7x2_plus = minus_to_plus(board_6x7x2_minus)\n",
    "                data_this_game.append((board_6x7x2_plus, col, skill_used))\n",
    "\n",
    "        player = 'minus' if (player == 'plus') else 'plus'\n",
    "        move_count += 1\n",
    "\n",
    "    return data_this_game\n",
    "\n",
    "def play_one_game_random_params():\n",
    "    \"\"\"\n",
    "    Roll random settings for plus/minus MCTS [500..5000],\n",
    "    and random_openings [1..15].\n",
    "    Return list of (board_6x7x2, best_move, skill).\n",
    "    \"\"\"\n",
    "    plus_mcts = random.randint(500, 5000)\n",
    "    minus_mcts = random.randint(500, 5000)\n",
    "    openings = random.randint(1, 15)\n",
    "    game_data = play_one_game(\n",
    "        plus_mcts_steps=plus_mcts,\n",
    "        minus_mcts_steps=minus_mcts,\n",
    "        random_openings=openings\n",
    "    )\n",
    "    return game_data  # list of (board, move, skill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_build_dataset(num_games=25000):\n",
    "    \"\"\"\n",
    "    Use joblib to run 'play_one_game_random_params()' in parallel.\n",
    "\n",
    "    data_dict will map:\n",
    "      key = (6,7,2) board .tobytes()\n",
    "      => { 'best_skill': int,\n",
    "           'move_counts': { move: (count) } }\n",
    "\n",
    "    If a new skill > best_skill, override the entire move_counts with the new move.\n",
    "    If skill == best_skill, we increment counts for that move as usual.\n",
    "    If skill < best_skill, ignore it (we keep the higher skill's recommendation).\n",
    "    \"\"\"\n",
    "    print(f\"Building dataset with {num_games} games in parallel...\")\n",
    "\n",
    "    results = Parallel(n_jobs=-1, backend='loky')(\n",
    "        delayed(play_one_game_random_params)()\n",
    "        for _ in range(num_games)\n",
    "    )\n",
    "\n",
    "    # data_dict: \n",
    "    #   key -> {'best_skill': X,\n",
    "    #           'move_counts': {move -> count}}\n",
    "    data_dict = defaultdict(lambda: {\"best_skill\": 0, \"move_counts\": defaultdict(int)})\n",
    "\n",
    "    print(\"Aggregating results & handling collisions with skill priority...\")\n",
    "\n",
    "    for game_data in results:\n",
    "        # game_data is list of (board_6x7x2, best_move, skill)\n",
    "        for (board_6x7x2, best_move, skill_used) in game_data:\n",
    "            # augment with symmetry\n",
    "            augmented = add_symmetric_flips(board_6x7x2, best_move)\n",
    "\n",
    "            for (b_aug, m_aug) in augmented:\n",
    "                key = b_aug.tobytes()\n",
    "                entry = data_dict[key]\n",
    "\n",
    "                current_best_skill = entry[\"best_skill\"]\n",
    "                move_counts = entry[\"move_counts\"]\n",
    "\n",
    "                if skill_used > current_best_skill:\n",
    "                    # override entire dictionary with new skill\n",
    "                    # and reset move_counts\n",
    "                    entry[\"best_skill\"] = skill_used\n",
    "                    entry[\"move_counts\"] = defaultdict(int)\n",
    "                    entry[\"move_counts\"][m_aug] = 1\n",
    "                elif skill_used == current_best_skill:\n",
    "                    # same skill -> just increment\n",
    "                    entry[\"move_counts\"][m_aug] += 1\n",
    "                else:\n",
    "                    # skill_used < current_best_skill => ignore\n",
    "                    pass\n",
    "\n",
    "    # Now resolve collisions by picking the move with the highest count\n",
    "    # for each board. We already only store moves from the highest skill.\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    for key, val in data_dict.items():\n",
    "        move_dict = val[\"move_counts\"]\n",
    "        # pick move with max count\n",
    "        if len(move_dict) == 0:\n",
    "            # might happen if skill=0 or something unexpected\n",
    "            continue\n",
    "        best_move = max(move_dict, key=move_dict.get)\n",
    "        arr = np.frombuffer(key, dtype=np.float32).reshape(6,7,2)\n",
    "        X_list.append(arr)\n",
    "        y_list.append(best_move)\n",
    "\n",
    "    X = np.stack(X_list, axis=0)\n",
    "    y = np.array(y_list, dtype=np.int32)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    NUM_GAMES = 50000\n",
    "    X, y = parallel_build_dataset(num_games=NUM_GAMES)\n",
    "    print(\"Finished building dataset!\")\n",
    "    print(\"X shape:\", X.shape)\n",
    "    print(\"y shape:\", y.shape)\n",
    "    print(\"Unique moves in y:\", np.unique(y))\n",
    "\n",
    "    # Save to disk\n",
    "    np.save(\"X_dataset_ethan3.npy\", X)\n",
    "    np.save(\"y_dataset_ethan3.npy\", y)\n",
    "    print(\"Dataset saved to X_dataset_ethan3.npy and y_dataset_ethan3.npy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before concatenation:\n",
      "  Dataset 1: (457185, 6, 7, 2) (457185,)\n",
      "  Dataset 2: (465707, 6, 7, 2) (465707,)\n",
      "After concatenation: (922892, 6, 7, 2) (922892,)\n",
      "Saved merged dataset to X_dataset_merged.npy, y_dataset_merged.npy.\n"
     ]
    }
   ],
   "source": [
    "# Append dataset code\n",
    "\n",
    "def append_datasets(file1_X, file1_y, file2_X, file2_y, out_X, out_y):\n",
    "    \"\"\"\n",
    "    Load two Connect4 datasets (X1,y1) and (X2,y2),\n",
    "    concatenate them along axis=0,\n",
    "    then save as (out_X, out_y).\n",
    "    \"\"\"\n",
    "    X1 = np.load(file1_X)\n",
    "    y1 = np.load(file1_y)\n",
    "    X2 = np.load(file2_X)\n",
    "    y2 = np.load(file2_y)\n",
    "\n",
    "    print(\"Before concatenation:\")\n",
    "    print(\"  Dataset 1:\", X1.shape, y1.shape)\n",
    "    print(\"  Dataset 2:\", X2.shape, y2.shape)\n",
    "\n",
    "    X_merged = np.concatenate([X1, X2], axis=0)\n",
    "    y_merged = np.concatenate([y1, y2], axis=0)\n",
    "\n",
    "    print(\"After concatenation:\", X_merged.shape, y_merged.shape)\n",
    "\n",
    "    np.save(out_X, X_merged)\n",
    "    np.save(out_y, y_merged)\n",
    "    print(f\"Saved merged dataset to {out_X}, {out_y}.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    append_datasets(\n",
    "        file1_X=\"X_dataset_ethan.npy\",\n",
    "        file1_y=\"y_dataset_ethan.npy\",\n",
    "        file2_X=\"X_dataset_ethan2.npy\",\n",
    "        file2_y=\"y_dataset_ethan2.npy\",\n",
    "        out_X=\"X_dataset_merged.npy\",\n",
    "        out_y=\"y_dataset_merged.npy\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes:\n",
      "X: (900019, 6, 7, 2)\n",
      "y: (900019,)\n",
      "Unique moves in y: [0 1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "X_file = \"X_dataset_ethan3.npy\"\n",
    "y_file = \"y_dataset_ethan3.npy\"\n",
    "\n",
    "X = np.load(X_file)  # shape (N, 6, 7, 2)\n",
    "y = np.load(y_file)  # shape (N,)\n",
    "\n",
    "print(\"Data shapes:\")\n",
    "print(\"X:\", X.shape)\n",
    "print(\"y:\", y.shape)\n",
    "unique_moves = np.unique(y)\n",
    "print(\"Unique moves in y:\", unique_moves)  # should be [0..6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 720015\n",
      "Validation set size: 180004\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.2, \n",
    "    random_state=22, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(\"Training set size:\", X_train.shape[0])\n",
    "print(\"Validation set size:\", X_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAvailable GPUs:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNetBigger\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 6, 7, 2)]    0           []                               \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 6, 7, 64)     1216        ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 6, 7, 64)    256         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_24 (ReLU)                (None, 6, 7, 64)     0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_24[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 6, 7, 64)    256         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_25 (ReLU)                (None, 6, 7, 64)     0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_25[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 6, 7, 64)    256         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_26 (ReLU)                (None, 6, 7, 64)     0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_26[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 6, 7, 64)    256         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 6, 7, 64)     0           ['re_lu_25[0][0]',               \n",
      "                                                                  'batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_27 (ReLU)                (None, 6, 7, 64)     0           ['add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_27[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 6, 7, 64)    256         ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_28 (ReLU)                (None, 6, 7, 64)     0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_28[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 6, 7, 64)    256         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 6, 7, 64)     0           ['re_lu_27[0][0]',               \n",
      "                                                                  'batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_29 (ReLU)                (None, 6, 7, 64)     0           ['add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_29[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 6, 7, 64)    256         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_30 (ReLU)                (None, 6, 7, 64)     0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_30[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 6, 7, 64)    256         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 6, 7, 64)     0           ['re_lu_29[0][0]',               \n",
      "                                                                  'batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_31 (ReLU)                (None, 6, 7, 64)     0           ['add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 3, 3, 64)    0           ['re_lu_31[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 3, 3, 128)    8320        ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 3, 3, 128)   512         ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_32 (ReLU)                (None, 3, 3, 128)    0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 3, 3, 128)    147584      ['re_lu_32[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 3, 3, 128)   512         ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_33 (ReLU)                (None, 3, 3, 128)    0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 3, 3, 128)    147584      ['re_lu_33[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 3, 3, 128)   512         ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 3, 3, 128)    0           ['re_lu_32[0][0]',               \n",
      "                                                                  'batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_34 (ReLU)                (None, 3, 3, 128)    0           ['add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 3, 3, 128)    147584      ['re_lu_34[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 3, 3, 128)   512         ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_35 (ReLU)                (None, 3, 3, 128)    0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 3, 3, 128)    147584      ['re_lu_35[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 3, 3, 128)   512         ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 3, 3, 128)    0           ['re_lu_34[0][0]',               \n",
      "                                                                  'batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_36 (ReLU)                (None, 3, 3, 128)    0           ['add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 128)   0           ['re_lu_36[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 1, 1, 128)    147584      ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 1, 1, 128)   512         ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_37 (ReLU)                (None, 1, 1, 128)    0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 1, 1, 128)    147584      ['re_lu_37[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 1, 1, 128)   512         ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 1, 1, 128)    0           ['max_pooling2d_3[0][0]',        \n",
      "                                                                  'batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_38 (ReLU)                (None, 1, 1, 128)    0           ['add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 1, 1, 128)    147584      ['re_lu_38[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 1, 1, 128)   512         ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_39 (ReLU)                (None, 1, 1, 128)    0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 1, 1, 128)    147584      ['re_lu_39[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 1, 1, 128)   512         ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 1, 1, 128)    0           ['re_lu_38[0][0]',               \n",
      "                                                                  'batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_40 (ReLU)                (None, 1, 1, 128)    0           ['add_15[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 1, 1, 256)    33024       ['re_lu_40[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 1, 1, 256)   1024        ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_41 (ReLU)                (None, 1, 1, 256)    0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 1, 1, 256)    590080      ['re_lu_41[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 1, 1, 256)   1024        ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_42 (ReLU)                (None, 1, 1, 256)    0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 1, 1, 256)    590080      ['re_lu_42[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 1, 1, 256)   1024        ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 1, 1, 256)    0           ['re_lu_41[0][0]',               \n",
      "                                                                  'batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_43 (ReLU)                (None, 1, 1, 256)    0           ['add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 1, 1, 256)    590080      ['re_lu_43[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 1, 1, 256)   1024        ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_44 (ReLU)                (None, 1, 1, 256)    0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 1, 1, 256)    590080      ['re_lu_44[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 1, 1, 256)   1024        ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 1, 1, 256)    0           ['re_lu_43[0][0]',               \n",
      "                                                                  'batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_45 (ReLU)                (None, 1, 1, 256)    0           ['add_17[0][0]']                 \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 256)          0           ['re_lu_45[0][0]']               \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1024)         263168      ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 1024)        4096        ['dense_3[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_46 (ReLU)                (None, 1024)         0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 1024)         0           ['re_lu_46[0][0]']               \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 512)          524800      ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 512)         2048        ['dense_4[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_47 (ReLU)                (None, 512)          0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 512)          0           ['re_lu_47[0][0]']               \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 7)            3591        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,651,527\n",
      "Trainable params: 4,642,567\n",
      "Non-trainable params: 8,960\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def residual_block(x, filters, kernel_size=(3,3), l2_reg=1e-6):\n",
    "    \"\"\"\n",
    "    A basic ResNet-style block:\n",
    "      - 3x3 Conv -> BN -> ReLU\n",
    "      - 3x3 Conv -> BN\n",
    "      - skip connection\n",
    "      - final ReLU\n",
    "    \"\"\"\n",
    "    shortcut = x\n",
    "\n",
    "    # 1st conv\n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same',\n",
    "                      kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 2nd conv\n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same',\n",
    "                      kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # skip connection\n",
    "    x = layers.Add()([shortcut, x])\n",
    "    x = layers.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "def build_resnet_bigger(\n",
    "    input_shape=(6,7,2),\n",
    "    num_classes=7,\n",
    "    l2_reg=1e-6,\n",
    "    dropout_rate=0.05\n",
    "):\n",
    "    \"\"\"\n",
    "    A bigger ResNet CNN for Connect 4.\n",
    "    Architecture:\n",
    "      1) Wide stem: conv(64)->(64) \n",
    "      2) 3 residual blocks at 64\n",
    "      3) MaxPool\n",
    "      4) Expand to 128\n",
    "      5) 2 residual blocks at 128\n",
    "      6) MaxPool\n",
    "      7) 2 residual blocks at 128\n",
    "      8) Expand to 256\n",
    "      9) 2 residual blocks at 256\n",
    "      10) Flatten\n",
    "      11) Dense(1024)->BN->ReLU->Dropout\n",
    "      12) Dense(512)->BN->ReLU->Dropout\n",
    "      13) Output(7, softmax)\n",
    "    \"\"\"\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # ==============\n",
    "    # 1. Wide Stem\n",
    "    # ==============\n",
    "    x = layers.Conv2D(64, (3,3), padding='same',\n",
    "                      kernel_regularizer=regularizers.l2(l2_reg))(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    x = layers.Conv2D(64, (3,3), padding='same',\n",
    "                      kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # ==============\n",
    "    # 2. 3 residual blocks at 64\n",
    "    # ==============\n",
    "    x = residual_block(x, filters=64,  l2_reg=l2_reg)\n",
    "    x = residual_block(x, filters=64,  l2_reg=l2_reg)\n",
    "    x = residual_block(x, filters=64,  l2_reg=l2_reg)\n",
    "\n",
    "    # 3. MaxPool\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), strides=2)(x)\n",
    "\n",
    "    # 4. Expand to 128\n",
    "    x = layers.Conv2D(128, (1,1), padding='same',\n",
    "                      kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 5. 2 residual blocks at 128\n",
    "    x = residual_block(x, filters=128, l2_reg=l2_reg)\n",
    "    x = residual_block(x, filters=128, l2_reg=l2_reg)\n",
    "\n",
    "    # 6. MaxPool\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), strides=2)(x)\n",
    "\n",
    "    # 7. 2 residual blocks at 128\n",
    "    x = residual_block(x, filters=128, l2_reg=l2_reg)\n",
    "    x = residual_block(x, filters=128, l2_reg=l2_reg)\n",
    "\n",
    "    # ==============\n",
    "    # 8. Expand to 256\n",
    "    # ==============\n",
    "    x = layers.Conv2D(256, (1,1), padding='same',\n",
    "                      kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 9. 2 residual blocks at 256\n",
    "    x = residual_block(x, filters=256, l2_reg=l2_reg)\n",
    "    x = residual_block(x, filters=256, l2_reg=l2_reg)\n",
    "\n",
    "    # flatten\n",
    "    x = layers.Flatten()(x)\n",
    "\n",
    "    # 11. Dense(1024)\n",
    "    x = layers.Dense(1024, kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    # 12. Dense(512)\n",
    "    x = layers.Dense(512, kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    # 13. Output\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs, outputs, name=\"ResNetBigger\")\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cnn_model = build_resnet_bigger(\n",
    "        input_shape=(6,7,2),\n",
    "        num_classes=7,\n",
    "        l2_reg=1e-6,\n",
    "        dropout_rate=0.05 # maybe increase to 0.1 or 0.15?\n",
    "    )\n",
    "\n",
    "    cnn_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), # was 0.003\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11251/11251 [==============================] - 156s 14ms/step - loss: 1.2488 - accuracy: 0.5237 - val_loss: 0.9558 - val_accuracy: 0.6377 - lr: 0.0070\n",
      "Epoch 2/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.9407 - accuracy: 0.6488 - val_loss: 0.9086 - val_accuracy: 0.6640 - lr: 0.0070\n",
      "Epoch 3/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.8987 - accuracy: 0.6676 - val_loss: 0.8976 - val_accuracy: 0.6675 - lr: 0.0070\n",
      "Epoch 4/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.8787 - accuracy: 0.6762 - val_loss: 0.8829 - val_accuracy: 0.6742 - lr: 0.0070\n",
      "Epoch 5/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.8665 - accuracy: 0.6809 - val_loss: 0.8550 - val_accuracy: 0.6830 - lr: 0.0070\n",
      "Epoch 6/100\n",
      "11251/11251 [==============================] - 152s 14ms/step - loss: 0.8570 - accuracy: 0.6850 - val_loss: 0.8479 - val_accuracy: 0.6873 - lr: 0.0070\n",
      "Epoch 7/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.8493 - accuracy: 0.6879 - val_loss: 0.8489 - val_accuracy: 0.6825 - lr: 0.0070\n",
      "Epoch 8/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.8449 - accuracy: 0.6895 - val_loss: 0.8449 - val_accuracy: 0.6884 - lr: 0.0070\n",
      "Epoch 9/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.8393 - accuracy: 0.6920 - val_loss: 0.8395 - val_accuracy: 0.6933 - lr: 0.0070\n",
      "Epoch 10/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.8363 - accuracy: 0.6927 - val_loss: 0.8441 - val_accuracy: 0.6859 - lr: 0.0070\n",
      "Epoch 11/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.8329 - accuracy: 0.6943 - val_loss: 0.8424 - val_accuracy: 0.6921 - lr: 0.0070\n",
      "Epoch 12/100\n",
      "11250/11251 [============================>.] - ETA: 0s - loss: 0.8314 - accuracy: 0.6944\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0035000001080334187.\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.8314 - accuracy: 0.6944 - val_loss: 0.8295 - val_accuracy: 0.6921 - lr: 0.0070\n",
      "Epoch 13/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.7818 - accuracy: 0.7105 - val_loss: 0.7729 - val_accuracy: 0.7129 - lr: 0.0035\n",
      "Epoch 14/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.7678 - accuracy: 0.7146 - val_loss: 0.7721 - val_accuracy: 0.7114 - lr: 0.0035\n",
      "Epoch 15/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.7610 - accuracy: 0.7157 - val_loss: 0.7672 - val_accuracy: 0.7111 - lr: 0.0035\n",
      "Epoch 16/100\n",
      "11250/11251 [============================>.] - ETA: 0s - loss: 0.7569 - accuracy: 0.7167\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0017500000540167093.\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.7569 - accuracy: 0.7167 - val_loss: 0.7725 - val_accuracy: 0.7113 - lr: 0.0035\n",
      "Epoch 17/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.7247 - accuracy: 0.7283 - val_loss: 0.7442 - val_accuracy: 0.7188 - lr: 0.0018\n",
      "Epoch 18/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.7139 - accuracy: 0.7314 - val_loss: 0.7396 - val_accuracy: 0.7202 - lr: 0.0018\n",
      "Epoch 19/100\n",
      "11251/11251 [==============================] - 152s 14ms/step - loss: 0.7090 - accuracy: 0.7329 - val_loss: 0.7461 - val_accuracy: 0.7203 - lr: 0.0018\n",
      "Epoch 20/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.7051 - accuracy: 0.7341 - val_loss: 0.7412 - val_accuracy: 0.7203 - lr: 0.0018\n",
      "Epoch 21/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.7014 - accuracy: 0.7346 - val_loss: 0.7405 - val_accuracy: 0.7195 - lr: 0.0018\n",
      "Epoch 22/100\n",
      "11248/11251 [============================>.] - ETA: 0s - loss: 0.6977 - accuracy: 0.7361\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0008750000270083547.\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.6977 - accuracy: 0.7361 - val_loss: 0.7389 - val_accuracy: 0.7200 - lr: 0.0018\n",
      "Epoch 23/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.6752 - accuracy: 0.7447 - val_loss: 0.7331 - val_accuracy: 0.7245 - lr: 8.7500e-04\n",
      "Epoch 24/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.6682 - accuracy: 0.7471 - val_loss: 0.7359 - val_accuracy: 0.7229 - lr: 8.7500e-04\n",
      "Epoch 25/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.6647 - accuracy: 0.7478 - val_loss: 0.7342 - val_accuracy: 0.7240 - lr: 8.7500e-04\n",
      "Epoch 26/100\n",
      "11247/11251 [============================>.] - ETA: 0s - loss: 0.6609 - accuracy: 0.7490\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.00043750001350417733.\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.6609 - accuracy: 0.7490 - val_loss: 0.7355 - val_accuracy: 0.7235 - lr: 8.7500e-04\n",
      "Epoch 27/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.6454 - accuracy: 0.7543 - val_loss: 0.7385 - val_accuracy: 0.7245 - lr: 4.3750e-04\n",
      "Epoch 28/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.6413 - accuracy: 0.7558 - val_loss: 0.7401 - val_accuracy: 0.7235 - lr: 4.3750e-04\n",
      "Epoch 29/100\n",
      "11248/11251 [============================>.] - ETA: 0s - loss: 0.6386 - accuracy: 0.7570\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.00021875000675208867.\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.6386 - accuracy: 0.7570 - val_loss: 0.7418 - val_accuracy: 0.7230 - lr: 4.3750e-04\n",
      "Epoch 30/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.6295 - accuracy: 0.7603 - val_loss: 0.7452 - val_accuracy: 0.7237 - lr: 2.1875e-04\n",
      "Epoch 31/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.6270 - accuracy: 0.7610 - val_loss: 0.7448 - val_accuracy: 0.7237 - lr: 2.1875e-04\n",
      "Epoch 32/100\n",
      "11248/11251 [============================>.] - ETA: 0s - loss: 0.6254 - accuracy: 0.7612\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00010937500337604433.\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.6254 - accuracy: 0.7612 - val_loss: 0.7468 - val_accuracy: 0.7227 - lr: 2.1875e-04\n",
      "Epoch 33/100\n",
      "11251/11251 [==============================] - 153s 14ms/step - loss: 0.6198 - accuracy: 0.7639 - val_loss: 0.7499 - val_accuracy: 0.7234 - lr: 1.0938e-04\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 64\n",
    "\n",
    "# Early stopping if val_accuracy doesn’t improve for 7 epochs\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Reduce learning rate by factor of 0.5 if val_accuracy doesn’t improve for 3 epochs\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "history = cnn_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 72.45%   (loss=0.7331)\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = cnn_model.evaluate(X_val, y_val, verbose=0)\n",
    "print(f\"Validation accuracy: {val_acc*100:.2f}%   (loss={val_loss:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to cnn_connect4.h5.\n"
     ]
    }
   ],
   "source": [
    "#model.save(\"cnn_connect4.h5\")\n",
    "#print(\"Model saved to cnn_connect4.h5.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Plot loss\n",
    "axs[0].plot(history.history['loss'], label='train_loss')\n",
    "axs[0].plot(history.history['val_loss'], label='val_loss')\n",
    "axs[0].set_title(\"Loss\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "# Plot accuracy\n",
    "axs[1].plot(history.history['accuracy'], label='train_acc')\n",
    "axs[1].plot(history.history['val_accuracy'], label='val_acc')\n",
    "axs[1].set_title(\"Accuracy\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Accuracy\")\n",
    "axs[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalIndex(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Produces a position index [0..seq_len-1] for each\n",
    "    element in the batch, so we can embed positions.\n",
    "    \"\"\"\n",
    "    def call(self, x):\n",
    "        \"\"\"\n",
    "        x shape: (batch_size, seq_len, embed_dim)\n",
    "        returns: (batch_size, seq_len) of indices\n",
    "        \"\"\"\n",
    "        bs = tf.shape(x)[0]            # batch size\n",
    "        seq_len = tf.shape(x)[1]       # how many patches in the sequence\n",
    "        indices = tf.range(seq_len)    # [0..seq_len-1]\n",
    "        indices = tf.expand_dims(indices, 0)    # shape (1, seq_len)\n",
    "        return tf.tile(indices, [bs, 1])        # shape (bs, seq_len)\n",
    "\n",
    "class ClassTokenIndex(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Produces a single index (0) for each batch to embed\n",
    "    a class token. We'll embed that index with a separate embedding.\n",
    "    \"\"\"\n",
    "    def call(self, x):\n",
    "        \"\"\"\n",
    "        x shape: (batch_size, seq_len, embed_dim)\n",
    "        returns: (batch_size, 1)\n",
    "        \"\"\"\n",
    "        bs = tf.shape(x)[0]\n",
    "        # just a single index [0]\n",
    "        idx = tf.zeros((1,1), dtype=tf.int32)   # shape (1,1)\n",
    "        return tf.tile(idx, [bs, 1])           # shape (bs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transformer_connect4_overlapping(\n",
    "    input_shape=(6,7,2),\n",
    "    hidden_dim=256,\n",
    "    num_layers=8,\n",
    "    num_heads=8,\n",
    "    key_dim=None,\n",
    "    mlp_dim=None,\n",
    "    dropout_rate=0.15,\n",
    "    num_classes=7,\n",
    "    l2_reg=1e-4\n",
    "):\n",
    "    \"\"\"\n",
    "    A deeper Transformer for Connect4 with overlapping patches.\n",
    "\n",
    "    Steps:\n",
    "      1) Conv2D with kernel_size=3, stride=1 => overlapping patches:\n",
    "         output shape => (4,5, hidden_dim) => 20 patches\n",
    "      2) Flatten to (20, hidden_dim)\n",
    "      3) Learn positional embedding for positions [0..19]\n",
    "      4) Class token appended => total 21 tokens\n",
    "      5) 8 Transformer blocks (Multi-head attention + MLP)\n",
    "      6) Output on class token => Dense(7, softmax)\n",
    "\n",
    "    Returns: compiled tf.keras.Model\n",
    "    \"\"\"\n",
    "    if key_dim is None:\n",
    "        key_dim = hidden_dim // num_heads\n",
    "    if mlp_dim is None:\n",
    "        mlp_dim = hidden_dim * 4  # typical factor of 4\n",
    "\n",
    "    # 1) Overlapping patch embedding\n",
    "    inputs = layers.Input(shape=input_shape)  # (None,6,7,2)\n",
    "    # conv with stride=1 => shape => ((6-3+1)=4, (7-3+1)=5) => 4x5=20 patches\n",
    "    patch_embed = layers.Conv2D(\n",
    "        filters=hidden_dim,\n",
    "        kernel_size=3,\n",
    "        strides=1,\n",
    "        padding='valid',\n",
    "        kernel_regularizer=regularizers.l2(l2_reg)\n",
    "    )(inputs)  # shape => (None,4,5, hidden_dim)\n",
    "    # flatten => shape => (None, 20, hidden_dim)\n",
    "    seq = layers.Reshape((-1, hidden_dim))(patch_embed)\n",
    "\n",
    "    # 2) Positional embedding\n",
    "    pos_indices = PositionalIndex()(seq)  # shape (bs, 20)\n",
    "    pos_embed = layers.Embedding(\n",
    "        input_dim=20,     # up to 20 patch positions\n",
    "        output_dim=hidden_dim,\n",
    "        embeddings_regularizer=regularizers.l2(l2_reg)\n",
    "    )(pos_indices)        # (bs, 20, hidden_dim)\n",
    "\n",
    "    x = layers.Add()([seq, pos_embed])  # shape => (bs,20,hidden_dim)\n",
    "\n",
    "    # 3) Class token\n",
    "    cls_idx = ClassTokenIndex()(x)  # shape => (bs,1)\n",
    "    cls_token = layers.Embedding(\n",
    "        input_dim=1,\n",
    "        output_dim=hidden_dim,\n",
    "        embeddings_regularizer=regularizers.l2(l2_reg)\n",
    "    )(cls_idx)  # => (bs,1,hidden_dim)\n",
    "\n",
    "    # concat => shape => (bs,21,hidden_dim)\n",
    "    x = layers.Concatenate(axis=1)([cls_token, x])\n",
    "\n",
    "    # 4) Stacked Transformer blocks\n",
    "    for _ in range(num_layers):\n",
    "        # LN + MHA\n",
    "        ln1 = layers.LayerNormalization()(x)\n",
    "        attn_out = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=key_dim,\n",
    "            dropout=dropout_rate,\n",
    "            kernel_regularizer=regularizers.l2(l2_reg),\n",
    "            bias_regularizer=regularizers.l2(l2_reg),\n",
    "        )(ln1, ln1, ln1)  # self-attention\n",
    "        x = layers.Add()([x, attn_out])  # residual\n",
    "\n",
    "        # LN + Feed-forward\n",
    "        ln2 = layers.LayerNormalization()(x)\n",
    "        ff = layers.Dense(\n",
    "            mlp_dim, activation='gelu',\n",
    "            kernel_regularizer=regularizers.l2(l2_reg)\n",
    "        )(ln2)\n",
    "        ff = layers.Dropout(dropout_rate)(ff)\n",
    "        ff = layers.Dense(\n",
    "            hidden_dim,\n",
    "            kernel_regularizer=regularizers.l2(l2_reg)\n",
    "        )(ff)\n",
    "        ff = layers.Dropout(dropout_rate)(ff)\n",
    "        x = layers.Add()([x, ff])  # residual\n",
    "\n",
    "    # 5) Final classification on class token => x[:,0,:]\n",
    "    cls_vec = x[:, 0, :]  # shape (bs, hidden_dim)\n",
    "    ln = layers.LayerNormalization()(cls_vec)\n",
    "    logits = layers.Dense(\n",
    "        num_classes, activation='softmax',\n",
    "        kernel_regularizer=regularizers.l2(l2_reg)\n",
    "    )(ln)\n",
    "\n",
    "    # compile\n",
    "    model = models.Model(inputs, logits, name=\"ViT_Connect4_Overlapping\")\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building an Overlapping-Patch Transformer for Connect4 shape (6,7,2)...\n",
      "Model: \"ViT_Connect4_Overlapping\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 6, 7, 2)]    0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 4, 5, 512)    9728        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 20, 512)      0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " positional_index (PositionalIn  (None, 20)          0           ['reshape[0][0]']                \n",
      " dex)                                                                                             \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 20, 512)      10240       ['positional_index[0][0]']       \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 20, 512)      0           ['reshape[0][0]',                \n",
      "                                                                  'embedding[0][0]']              \n",
      "                                                                                                  \n",
      " class_token_index (ClassTokenI  (None, 1)           0           ['add[0][0]']                    \n",
      " ndex)                                                                                            \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 1, 512)       512         ['class_token_index[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 21, 512)      0           ['embedding_1[0][0]',            \n",
      "                                                                  'add[0][0]']                    \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 21, 512)     1024        ['concatenate[0][0]']            \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 21, 512)     1050624     ['layer_normalization[0][0]',    \n",
      " dAttention)                                                      'layer_normalization[0][0]',    \n",
      "                                                                  'layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 21, 512)      0           ['concatenate[0][0]',            \n",
      "                                                                  'multi_head_attention[0][0]']   \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 21, 512)     1024        ['add_1[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 21, 2048)     1050624     ['layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 21, 2048)     0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 21, 512)      1049088     ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 21, 512)      0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 21, 512)      0           ['add_1[0][0]',                  \n",
      "                                                                  'dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 21, 512)     1024        ['add_2[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 21, 512)     1050624     ['layer_normalization_2[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_2[0][0]',  \n",
      "                                                                  'layer_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 21, 512)      0           ['add_2[0][0]',                  \n",
      "                                                                  'multi_head_attention_1[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 21, 512)     1024        ['add_3[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 21, 2048)     1050624     ['layer_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 21, 2048)     0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 21, 512)      1049088     ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 21, 512)      0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 21, 512)      0           ['add_3[0][0]',                  \n",
      "                                                                  'dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 21, 512)     1024        ['add_4[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 21, 512)     1050624     ['layer_normalization_4[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_4[0][0]',  \n",
      "                                                                  'layer_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 21, 512)      0           ['add_4[0][0]',                  \n",
      "                                                                  'multi_head_attention_2[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 21, 512)     1024        ['add_5[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 21, 2048)     1050624     ['layer_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 21, 2048)     0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 21, 512)      1049088     ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 21, 512)      0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 21, 512)      0           ['add_5[0][0]',                  \n",
      "                                                                  'dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 21, 512)     1024        ['add_6[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 21, 512)     1050624     ['layer_normalization_6[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_6[0][0]',  \n",
      "                                                                  'layer_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 21, 512)      0           ['add_6[0][0]',                  \n",
      "                                                                  'multi_head_attention_3[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 21, 512)     1024        ['add_7[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 21, 2048)     1050624     ['layer_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 21, 2048)     0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 21, 512)      1049088     ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 21, 512)      0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 21, 512)      0           ['add_7[0][0]',                  \n",
      "                                                                  'dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_8 (LayerNo  (None, 21, 512)     1024        ['add_8[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_4 (MultiH  (None, 21, 512)     1050624     ['layer_normalization_8[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_8[0][0]',  \n",
      "                                                                  'layer_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 21, 512)      0           ['add_8[0][0]',                  \n",
      "                                                                  'multi_head_attention_4[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_9 (LayerNo  (None, 21, 512)     1024        ['add_9[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 21, 2048)     1050624     ['layer_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 21, 2048)     0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 21, 512)      1049088     ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 21, 512)      0           ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 21, 512)      0           ['add_9[0][0]',                  \n",
      "                                                                  'dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_10 (LayerN  (None, 21, 512)     1024        ['add_10[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (MultiH  (None, 21, 512)     1050624     ['layer_normalization_10[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_10[0][0]', \n",
      "                                                                  'layer_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 21, 512)      0           ['add_10[0][0]',                 \n",
      "                                                                  'multi_head_attention_5[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_11 (LayerN  (None, 21, 512)     1024        ['add_11[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 21, 2048)     1050624     ['layer_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 21, 2048)     0           ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 21, 512)      1049088     ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 21, 512)      0           ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 21, 512)      0           ['add_11[0][0]',                 \n",
      "                                                                  'dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_12 (LayerN  (None, 21, 512)     1024        ['add_12[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_6 (MultiH  (None, 21, 512)     1050624     ['layer_normalization_12[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_12[0][0]', \n",
      "                                                                  'layer_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 21, 512)      0           ['add_12[0][0]',                 \n",
      "                                                                  'multi_head_attention_6[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_13 (LayerN  (None, 21, 512)     1024        ['add_13[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 21, 2048)     1050624     ['layer_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 21, 2048)     0           ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 21, 512)      1049088     ['dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 21, 512)      0           ['dense_13[0][0]']               \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 21, 512)      0           ['add_13[0][0]',                 \n",
      "                                                                  'dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_14 (LayerN  (None, 21, 512)     1024        ['add_14[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_7 (MultiH  (None, 21, 512)     1050624     ['layer_normalization_14[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_14[0][0]', \n",
      "                                                                  'layer_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 21, 512)      0           ['add_14[0][0]',                 \n",
      "                                                                  'multi_head_attention_7[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_15 (LayerN  (None, 21, 512)     1024        ['add_15[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 21, 2048)     1050624     ['layer_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 21, 2048)     0           ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 21, 512)      1049088     ['dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 21, 512)      0           ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 21, 512)      0           ['add_15[0][0]',                 \n",
      "                                                                  'dropout_15[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_16 (LayerN  (None, 21, 512)     1024        ['add_16[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_8 (MultiH  (None, 21, 512)     1050624     ['layer_normalization_16[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_16[0][0]', \n",
      "                                                                  'layer_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 21, 512)      0           ['add_16[0][0]',                 \n",
      "                                                                  'multi_head_attention_8[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_17 (LayerN  (None, 21, 512)     1024        ['add_17[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 21, 2048)     1050624     ['layer_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 21, 2048)     0           ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 21, 512)      1049088     ['dropout_16[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 21, 512)      0           ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, 21, 512)      0           ['add_17[0][0]',                 \n",
      "                                                                  'dropout_17[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_18 (LayerN  (None, 21, 512)     1024        ['add_18[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_9 (MultiH  (None, 21, 512)     1050624     ['layer_normalization_18[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_18[0][0]', \n",
      "                                                                  'layer_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " add_19 (Add)                   (None, 21, 512)      0           ['add_18[0][0]',                 \n",
      "                                                                  'multi_head_attention_9[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_19 (LayerN  (None, 21, 512)     1024        ['add_19[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 21, 2048)     1050624     ['layer_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)           (None, 21, 2048)     0           ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 21, 512)      1049088     ['dropout_18[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)           (None, 21, 512)      0           ['dense_19[0][0]']               \n",
      "                                                                                                  \n",
      " add_20 (Add)                   (None, 21, 512)      0           ['add_19[0][0]',                 \n",
      "                                                                  'dropout_19[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 512)         0           ['add_20[0][0]']                 \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " layer_normalization_20 (LayerN  (None, 512)         1024        ['tf.__operators__.getitem[0][0]'\n",
      " ormalization)                                                   ]                                \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 7)            3591        ['layer_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,548,935\n",
      "Trainable params: 31,548,935\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Building an Overlapping-Patch Transformer for Connect4 shape (6,7,2)...\")\n",
    "    # You can tweak hidden_dim, num_layers, etc. further\n",
    "    transformer_model = build_transformer_connect4_overlapping(\n",
    "        input_shape=(6,7,2),\n",
    "        hidden_dim=512, # Was 384\n",
    "        num_layers=10,\n",
    "        num_heads=8,\n",
    "        key_dim=None,     # defaults to hidden_dim//num_heads # Was 48\n",
    "        mlp_dim=None,     # defaults to 4*hidden_dim (was 384 but should have been 1536)\n",
    "        dropout_rate=0.15, # was 0.1\n",
    "        num_classes=7,    \n",
    "        l2_reg=1e-3        # was 1e-4\n",
    "    )\n",
    "\n",
    "    transformer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5626/5626 [==============================] - 299s 52ms/step - loss: 2.5556 - accuracy: 0.3955 - val_loss: 1.7970 - val_accuracy: 0.4433 - lr: 1.0000e-04\n",
      "Epoch 2/200\n",
      "5626/5626 [==============================] - 291s 52ms/step - loss: 1.5656 - accuracy: 0.4555 - val_loss: 1.4183 - val_accuracy: 0.4778 - lr: 1.0000e-04\n",
      "Epoch 3/200\n",
      "5626/5626 [==============================] - 291s 52ms/step - loss: 1.3888 - accuracy: 0.4807 - val_loss: 1.3378 - val_accuracy: 0.4964 - lr: 1.0000e-04\n",
      "Epoch 4/200\n",
      "5626/5626 [==============================] - 291s 52ms/step - loss: 1.3195 - accuracy: 0.5029 - val_loss: 1.2952 - val_accuracy: 0.5112 - lr: 1.0000e-04\n",
      "Epoch 5/200\n",
      "5626/5626 [==============================] - 291s 52ms/step - loss: 1.2656 - accuracy: 0.5256 - val_loss: 1.2263 - val_accuracy: 0.5418 - lr: 1.0000e-04\n",
      "Epoch 6/200\n",
      "5626/5626 [==============================] - 291s 52ms/step - loss: 1.2200 - accuracy: 0.5455 - val_loss: 1.1902 - val_accuracy: 0.5598 - lr: 1.0000e-04\n",
      "Epoch 7/200\n",
      "5626/5626 [==============================] - 291s 52ms/step - loss: 1.1825 - accuracy: 0.5625 - val_loss: 1.1523 - val_accuracy: 0.5740 - lr: 1.0000e-04\n",
      "Epoch 8/200\n",
      "5626/5626 [==============================] - 291s 52ms/step - loss: 1.1504 - accuracy: 0.5780 - val_loss: 1.1236 - val_accuracy: 0.5876 - lr: 1.0000e-04\n",
      "Epoch 9/200\n",
      "5626/5626 [==============================] - 291s 52ms/step - loss: 1.1211 - accuracy: 0.5902 - val_loss: 1.1013 - val_accuracy: 0.5984 - lr: 1.0000e-04\n",
      "Epoch 10/200\n",
      "5626/5626 [==============================] - 291s 52ms/step - loss: 1.0939 - accuracy: 0.6015 - val_loss: 1.0687 - val_accuracy: 0.6109 - lr: 1.0000e-04\n",
      "Epoch 11/200\n",
      "5626/5626 [==============================] - 291s 52ms/step - loss: 1.0653 - accuracy: 0.6146 - val_loss: 1.0429 - val_accuracy: 0.6241 - lr: 1.0000e-04\n",
      "Epoch 12/200\n",
      "5626/5626 [==============================] - 291s 52ms/step - loss: 1.0404 - accuracy: 0.6248 - val_loss: 1.0289 - val_accuracy: 0.6294 - lr: 1.0000e-04\n",
      "Epoch 13/200\n",
      "5626/5626 [==============================] - 291s 52ms/step - loss: 1.0193 - accuracy: 0.6333 - val_loss: 1.0136 - val_accuracy: 0.6333 - lr: 1.0000e-04\n",
      "Epoch 14/200\n",
      "5626/5626 [==============================] - 291s 52ms/step - loss: 1.0018 - accuracy: 0.6412 - val_loss: 1.0030 - val_accuracy: 0.6398 - lr: 1.0000e-04\n",
      "Epoch 15/200\n",
      "5626/5626 [==============================] - 291s 52ms/step - loss: 0.9868 - accuracy: 0.6473 - val_loss: 0.9890 - val_accuracy: 0.6450 - lr: 1.0000e-04\n",
      "Epoch 16/200\n",
      "5626/5626 [==============================] - 292s 52ms/step - loss: 0.9730 - accuracy: 0.6539 - val_loss: 0.9854 - val_accuracy: 0.6478 - lr: 1.0000e-04\n",
      "Epoch 17/200\n",
      "5626/5626 [==============================] - 292s 52ms/step - loss: 0.9615 - accuracy: 0.6584 - val_loss: 0.9813 - val_accuracy: 0.6494 - lr: 1.0000e-04\n",
      "Epoch 18/200\n",
      "5626/5626 [==============================] - 291s 52ms/step - loss: 0.9523 - accuracy: 0.6623 - val_loss: 0.9715 - val_accuracy: 0.6535 - lr: 1.0000e-04\n",
      "Epoch 19/200\n",
      "5626/5626 [==============================] - 292s 52ms/step - loss: 0.9438 - accuracy: 0.6660 - val_loss: 0.9674 - val_accuracy: 0.6544 - lr: 1.0000e-04\n",
      "Epoch 20/200\n",
      "5626/5626 [==============================] - 292s 52ms/step - loss: 0.9346 - accuracy: 0.6703 - val_loss: 0.9631 - val_accuracy: 0.6582 - lr: 1.0000e-04\n",
      "Epoch 21/200\n",
      "5626/5626 [==============================] - 291s 52ms/step - loss: 0.9270 - accuracy: 0.6729 - val_loss: 0.9637 - val_accuracy: 0.6595 - lr: 1.0000e-04\n",
      "Epoch 22/200\n",
      "5626/5626 [==============================] - 292s 52ms/step - loss: 0.9194 - accuracy: 0.6763 - val_loss: 0.9564 - val_accuracy: 0.6610 - lr: 1.0000e-04\n",
      "Epoch 23/200\n",
      "5626/5626 [==============================] - 292s 52ms/step - loss: 0.9128 - accuracy: 0.6798 - val_loss: 0.9457 - val_accuracy: 0.6653 - lr: 1.0000e-04\n",
      "Epoch 24/200\n",
      "5626/5626 [==============================] - 292s 52ms/step - loss: 0.9052 - accuracy: 0.6832 - val_loss: 0.9540 - val_accuracy: 0.6645 - lr: 1.0000e-04\n",
      "Epoch 25/200\n",
      "5626/5626 [==============================] - 292s 52ms/step - loss: 0.8999 - accuracy: 0.6863 - val_loss: 0.9587 - val_accuracy: 0.6638 - lr: 1.0000e-04\n",
      "Epoch 26/200\n",
      "5626/5626 [==============================] - 287s 51ms/step - loss: 0.8945 - accuracy: 0.6889 - val_loss: 0.9480 - val_accuracy: 0.6667 - lr: 1.0000e-04\n",
      "Epoch 27/200\n",
      "5626/5626 [==============================] - 286s 51ms/step - loss: 0.8881 - accuracy: 0.6922 - val_loss: 0.9558 - val_accuracy: 0.6643 - lr: 1.0000e-04\n",
      "Epoch 28/200\n",
      "5626/5626 [==============================] - 287s 51ms/step - loss: 0.8835 - accuracy: 0.6943 - val_loss: 0.9552 - val_accuracy: 0.6659 - lr: 1.0000e-04\n",
      "Epoch 29/200\n",
      "5626/5626 [==============================] - 287s 51ms/step - loss: 0.8787 - accuracy: 0.6967 - val_loss: 0.9537 - val_accuracy: 0.6678 - lr: 1.0000e-04\n",
      "Epoch 30/200\n",
      "5626/5626 [==============================] - 287s 51ms/step - loss: 0.8727 - accuracy: 0.6994 - val_loss: 0.9510 - val_accuracy: 0.6688 - lr: 1.0000e-04\n",
      "Epoch 31/200\n",
      "5626/5626 [==============================] - 287s 51ms/step - loss: 0.8680 - accuracy: 0.7016 - val_loss: 0.9559 - val_accuracy: 0.6674 - lr: 1.0000e-04\n",
      "Epoch 32/200\n",
      "5626/5626 [==============================] - 286s 51ms/step - loss: 0.8631 - accuracy: 0.7040 - val_loss: 0.9552 - val_accuracy: 0.6693 - lr: 1.0000e-04\n",
      "Epoch 33/200\n",
      "5626/5626 [==============================] - 287s 51ms/step - loss: 0.8581 - accuracy: 0.7073 - val_loss: 0.9548 - val_accuracy: 0.6701 - lr: 1.0000e-04\n",
      "Epoch 34/200\n",
      "5626/5626 [==============================] - 287s 51ms/step - loss: 0.8536 - accuracy: 0.7092 - val_loss: 0.9538 - val_accuracy: 0.6689 - lr: 1.0000e-04\n",
      "Epoch 35/200\n",
      "5626/5626 [==============================] - 287s 51ms/step - loss: 0.8489 - accuracy: 0.7118 - val_loss: 0.9573 - val_accuracy: 0.6708 - lr: 1.0000e-04\n",
      "Epoch 36/200\n",
      "5626/5626 [==============================] - 286s 51ms/step - loss: 0.8441 - accuracy: 0.7137 - val_loss: 0.9668 - val_accuracy: 0.6668 - lr: 1.0000e-04\n",
      "Epoch 37/200\n",
      "5626/5626 [==============================] - 287s 51ms/step - loss: 0.8395 - accuracy: 0.7162 - val_loss: 0.9605 - val_accuracy: 0.6707 - lr: 1.0000e-04\n",
      "Epoch 38/200\n",
      "5626/5626 [==============================] - ETA: 0s - loss: 0.8355 - accuracy: 0.7189\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "5626/5626 [==============================] - 286s 51ms/step - loss: 0.8355 - accuracy: 0.7189 - val_loss: 0.9691 - val_accuracy: 0.6693 - lr: 1.0000e-04\n",
      "Epoch 39/200\n",
      "5626/5626 [==============================] - 287s 51ms/step - loss: 0.7641 - accuracy: 0.7472 - val_loss: 0.9626 - val_accuracy: 0.6764 - lr: 5.0000e-05\n",
      "Epoch 40/200\n",
      "5626/5626 [==============================] - 286s 51ms/step - loss: 0.7422 - accuracy: 0.7557 - val_loss: 0.9754 - val_accuracy: 0.6757 - lr: 5.0000e-05\n",
      "Epoch 41/200\n",
      "5626/5626 [==============================] - 287s 51ms/step - loss: 0.7306 - accuracy: 0.7607 - val_loss: 0.9895 - val_accuracy: 0.6724 - lr: 5.0000e-05\n",
      "Epoch 42/200\n",
      "5626/5626 [==============================] - ETA: 0s - loss: 0.7219 - accuracy: 0.7640\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "5626/5626 [==============================] - 286s 51ms/step - loss: 0.7219 - accuracy: 0.7640 - val_loss: 0.9835 - val_accuracy: 0.6748 - lr: 5.0000e-05\n",
      "Epoch 43/200\n",
      "5626/5626 [==============================] - 287s 51ms/step - loss: 0.6696 - accuracy: 0.7864 - val_loss: 1.0278 - val_accuracy: 0.6748 - lr: 2.5000e-05\n",
      "Epoch 44/200\n",
      "5626/5626 [==============================] - 290s 52ms/step - loss: 0.6543 - accuracy: 0.7917 - val_loss: 1.0326 - val_accuracy: 0.6728 - lr: 2.5000e-05\n",
      "Epoch 45/200\n",
      "5625/5626 [============================>.] - ETA: 0s - loss: 0.6457 - accuracy: 0.7954\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "5626/5626 [==============================] - 294s 52ms/step - loss: 0.6457 - accuracy: 0.7954 - val_loss: 1.0588 - val_accuracy: 0.6717 - lr: 2.5000e-05\n",
      "Epoch 46/200\n",
      "5626/5626 [==============================] - 292s 52ms/step - loss: 0.6123 - accuracy: 0.8097 - val_loss: 1.0901 - val_accuracy: 0.6704 - lr: 1.2500e-05\n",
      "Epoch 47/200\n",
      "5626/5626 [==============================] - 290s 51ms/step - loss: 0.6041 - accuracy: 0.8124 - val_loss: 1.1023 - val_accuracy: 0.6707 - lr: 1.2500e-05\n",
      "Epoch 48/200\n",
      "5626/5626 [==============================] - ETA: 0s - loss: 0.5976 - accuracy: 0.8151\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "5626/5626 [==============================] - 289s 51ms/step - loss: 0.5976 - accuracy: 0.8151 - val_loss: 1.1102 - val_accuracy: 0.6688 - lr: 1.2500e-05\n",
      "Epoch 49/200\n",
      "5626/5626 [==============================] - 290s 52ms/step - loss: 0.5786 - accuracy: 0.8232 - val_loss: 1.1444 - val_accuracy: 0.6687 - lr: 6.2500e-06\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "batch_size = 128 #64\n",
    "\n",
    "# Early stopping if val_accuracy doesn’t improve for 7 epochs\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Reduce learning rate by factor of 0.5 if val_accuracy doesn’t improve for 3 epochs\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "history = transformer_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 67.64%   (loss=0.9626)\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = transformer_model.evaluate(X_val, y_val, verbose=0)\n",
    "print(f\"Validation accuracy: {val_acc*100:.2f}%   (loss={val_loss:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Plot loss\n",
    "axs[0].plot(history.history['loss'], label='train_loss')\n",
    "axs[0].plot(history.history['val_loss'], label='val_loss')\n",
    "axs[0].set_title(\"Loss\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "# Plot accuracy\n",
    "axs[1].plot(history.history['accuracy'], label='train_acc')\n",
    "axs[1].plot(history.history['val_accuracy'], label='val_acc')\n",
    "axs[1].set_title(\"Accuracy\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Accuracy\")\n",
    "axs[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to ViT_Connect4_final.h5\n"
     ]
    }
   ],
   "source": [
    "#transformer_model.save(\"ViT_Connect4_final.h5\")\n",
    "#print(\"Saved to ViT_Connect4_final.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing CNN and Transformer vs MCTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalIndex(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Produces a position index [0..seq_len-1] for each element in the batch,\n",
    "    to embed positions.\n",
    "    \"\"\"\n",
    "    def call(self, x):\n",
    "        \"\"\"\n",
    "        x shape: (batch, seq_len, embed_dim)\n",
    "        returns: (batch, seq_len) of indices\n",
    "        \"\"\"\n",
    "        bs       = tf.shape(x)[0]\n",
    "        seq_len  = tf.shape(x)[1]\n",
    "        indices  = tf.range(seq_len)            # shape (seq_len,)\n",
    "        indices  = tf.expand_dims(indices, 0)   # shape (1, seq_len)\n",
    "        indices  = tf.tile(indices, [bs, 1])    # shape (bs, seq_len)\n",
    "        return indices  # int32 by default\n",
    "\n",
    "class ClassTokenIndex(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Produces a single index (0) for each batch to embed a class token.\n",
    "    \"\"\"\n",
    "    def call(self, x):\n",
    "        \"\"\"\n",
    "        x shape: (batch, seq_len, embed_dim)\n",
    "        returns: (batch, 1)\n",
    "        \"\"\"\n",
    "        bs = tf.shape(x)[0]\n",
    "        idx = tf.zeros((1,1), dtype=tf.int32)  # shape (1,1)\n",
    "        return tf.tile(idx, [bs, 1])           # shape (bs, 1)\n",
    "\n",
    "def build_transformer_connect4_overlapping(\n",
    "    input_shape=(6,7,2),\n",
    "    hidden_dim=256,\n",
    "    num_layers=8,\n",
    "    num_heads=8,\n",
    "    key_dim=None,\n",
    "    mlp_dim=None,\n",
    "    dropout_rate=0.15,\n",
    "    num_classes=7,\n",
    "    l2_reg=1e-4\n",
    "):\n",
    "    \"\"\"\n",
    "    A deeper Transformer for Connect4 with overlapping patches.\n",
    "    ...\n",
    "    [Same code you posted]\n",
    "    \"\"\"\n",
    "    if key_dim is None:\n",
    "        key_dim = hidden_dim // num_heads\n",
    "    if mlp_dim is None:\n",
    "        mlp_dim = hidden_dim * 4  # typical factor of 4\n",
    "\n",
    "    # 1) Overlapping patch embedding via Conv2D with stride=1 => shape => (4,5,hidden_dim)\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    patch_embed = layers.Conv2D(\n",
    "        filters=hidden_dim,\n",
    "        kernel_size=3,\n",
    "        strides=1,\n",
    "        padding='valid',\n",
    "        kernel_regularizer=regularizers.l2(l2_reg)\n",
    "    )(inputs)  # => (None,4,5,hidden_dim)\n",
    "    seq = layers.Reshape((-1, hidden_dim))(patch_embed)  # => (None,20,hidden_dim)\n",
    "\n",
    "    # 2) Positional embedding\n",
    "    pos_indices = PositionalIndex()(seq)  # => (batch,20)\n",
    "    pos_embed = layers.Embedding(\n",
    "        input_dim=20,\n",
    "        output_dim=hidden_dim,\n",
    "        embeddings_regularizer=regularizers.l2(l2_reg)\n",
    "    )(pos_indices)  # => (batch,20,hidden_dim)\n",
    "    x = layers.Add()([seq, pos_embed])    # => (batch,20,hidden_dim)\n",
    "\n",
    "    # 3) Class token\n",
    "    cls_idx = ClassTokenIndex()(x)  # => (batch,1)\n",
    "    cls_token = layers.Embedding(\n",
    "        input_dim=1,\n",
    "        output_dim=hidden_dim,\n",
    "        embeddings_regularizer=regularizers.l2(l2_reg)\n",
    "    )(cls_idx)   # => (batch,1,hidden_dim)\n",
    "    x = layers.Concatenate(axis=1)([cls_token, x])  # => (batch,21,hidden_dim)\n",
    "\n",
    "    # 4) Stacked Transformer blocks\n",
    "    for _ in range(num_layers):\n",
    "        # LN + MHA\n",
    "        ln1 = layers.LayerNormalization()(x)\n",
    "        attn_out = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=key_dim,\n",
    "            dropout=dropout_rate,\n",
    "            kernel_regularizer=regularizers.l2(l2_reg),\n",
    "            bias_regularizer=regularizers.l2(l2_reg)\n",
    "        )(ln1, ln1, ln1)\n",
    "        x = layers.Add()([x, attn_out])\n",
    "\n",
    "        # LN + Feed-forward\n",
    "        ln2 = layers.LayerNormalization()(x)\n",
    "        ff = layers.Dense(\n",
    "            mlp_dim, activation='gelu',\n",
    "            kernel_regularizer=regularizers.l2(l2_reg)\n",
    "        )(ln2)\n",
    "        ff = layers.Dropout(dropout_rate)(ff)\n",
    "        ff = layers.Dense(\n",
    "            hidden_dim,\n",
    "            kernel_regularizer=regularizers.l2(l2_reg)\n",
    "        )(ff)\n",
    "        ff = layers.Dropout(dropout_rate)(ff)\n",
    "        x = layers.Add()([x, ff])\n",
    "\n",
    "    # 5) Final classification (class token => x[:,0,:])\n",
    "    cls_vec = x[:,0,:]  # => (batch, hidden_dim)\n",
    "    ln = layers.LayerNormalization()(cls_vec)\n",
    "    logits = layers.Dense(\n",
    "        num_classes, activation='softmax',\n",
    "        kernel_regularizer=regularizers.l2(l2_reg)\n",
    "    )(ln)\n",
    "\n",
    "    model = models.Model(inputs, logits, name=\"ViT_Connect4_Overlapping\")\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.007),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = tf.keras.models.load_model(\"cnn_connect4.h5\")  # Adjust filename as needed\n",
    "\n",
    "# Load the transformer model with custom objects\n",
    "custom_objects = {\n",
    "\t'PositionalIndex': PositionalIndex,\n",
    "\t'ClassTokenIndex': ClassTokenIndex\n",
    "}\n",
    "#transformer_model = tf.keras.models.load_model(\"ViT_Connect4_final.h5\", custom_objects=custom_objects)  # Adjust filename as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_pick_move(board_2d, model, color='plus'):\n",
    "    \"\"\"\n",
    "    Given a 6x7 board (board_2d) and a trained CNN model,\n",
    "    pick the column with the highest predicted probability that is legal.\n",
    "    \"\"\"\n",
    "    # Convert board to 6x7x2 representation\n",
    "    from_board = board_to_6x7x2(board_2d)\n",
    "    \n",
    "    if color == 'minus':\n",
    "        # Flip to plus perspective\n",
    "        from_board = minus_to_plus(from_board)\n",
    "\n",
    "    # Model expects shape (N, 6, 7, 2). So expand dims.\n",
    "    input_for_model = np.expand_dims(from_board, axis=0)  # (1,6,7,2)\n",
    "    \n",
    "    # Predict probabilities for each column\n",
    "    pred_probs = model.predict(input_for_model, verbose=0)[0]  # (7,)\n",
    "    \n",
    "    # Sort columns by descending probability\n",
    "    columns_ranked = np.argsort(pred_probs)[::-1]  # highest -> lowest\n",
    "    \n",
    "    # Find a legal column among the top predictions\n",
    "    legal_cols = find_legal(board_2d)\n",
    "    for col in columns_ranked:\n",
    "        if col in legal_cols:\n",
    "            return col\n",
    "    \n",
    "    # Fallback: pick a random legal column\n",
    "    if len(legal_cols) > 0:\n",
    "        return random.choice(legal_cols)\n",
    "    else:\n",
    "        return 0  # If no columns are legal, default to column 0\n",
    "\n",
    "def transformer_pick_move(board_2d, model, color='plus'):\n",
    "    \"\"\"\n",
    "    Given a 6x7 board (board_2d) and a trained Transformer model,\n",
    "    pick the column with the highest predicted probability that is legal.\n",
    "    \"\"\"\n",
    "    # Convert board to 6x7x2 representation\n",
    "    from_board = board_to_6x7x2(board_2d)\n",
    "    \n",
    "    if color == 'minus':\n",
    "        # Flip to plus perspective\n",
    "        from_board = minus_to_plus(from_board)\n",
    "\n",
    "    # Model expects shape (N, 6, 7, 2). So expand dims.\n",
    "    input_for_model = np.expand_dims(from_board, axis=0)  # (1,6,7,2)\n",
    "    \n",
    "    # Predict probabilities for each column\n",
    "    pred_probs = model.predict(input_for_model, verbose=0)[0]  # (7,)\n",
    "    \n",
    "    # Sort columns by descending probability\n",
    "    columns_ranked = np.argsort(pred_probs)[::-1]  # highest -> lowest\n",
    "    \n",
    "    # Find a legal column among the top predictions\n",
    "    legal_cols = find_legal(board_2d)\n",
    "    for col in columns_ranked:\n",
    "        if col in legal_cols:\n",
    "            return col\n",
    "    \n",
    "    # Fallback: pick a random legal column\n",
    "    if len(legal_cols) > 0:\n",
    "        return random.choice(legal_cols)\n",
    "    else:\n",
    "        return 0  # If no columns are legal, default to column 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_one_game(model_pick_move, model_type='CNN', mcts_steps_minus=300, verbose=False):\n",
    "    \"\"\"\n",
    "    Let either the CNN or Transformer play as 'plus' against MCTS as 'minus'.\n",
    "    \n",
    "    Parameters:\n",
    "    - model_pick_move: function to pick moves using the model (cnn_pick_move or transformer_pick_move)\n",
    "    - model_type: 'CNN' or 'Transformer' (for reporting purposes)\n",
    "    - mcts_steps_minus: number of MCTS steps for the 'minus' player\n",
    "    - verbose: if True, print each move\n",
    "    \n",
    "    Returns:\n",
    "    - winner: 'plus', 'minus', or 'tie'\n",
    "    - move_count: number of moves made in the game\n",
    "    \"\"\"\n",
    "    board = np.zeros((6,7), dtype=np.float32)\n",
    "    winner = 'nobody'\n",
    "    player = 'plus'\n",
    "    move_count = 0\n",
    "\n",
    "    while winner == 'nobody':\n",
    "        legal = find_legal(board)\n",
    "        if len(legal) == 0:\n",
    "            # Tie\n",
    "            break\n",
    "\n",
    "        if player == 'plus':\n",
    "            col = model_pick_move(board, model=cnn_model if model_type == 'CNN' else transformer_model, color='plus')\n",
    "        else:\n",
    "            col = mcts(board, 'minus', mcts_steps_minus)\n",
    "\n",
    "        board = update_board(board, player, col)\n",
    "        winner = check_for_win(board, col)\n",
    "        move_count += 1\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Move {move_count}, {player}, col={col}\")\n",
    "\n",
    "        # Switch player\n",
    "        player = 'minus' if player == 'plus' else 'plus'\n",
    "\n",
    "    # Determine outcome\n",
    "    if winner == 'nobody' or winner == 'tie':\n",
    "        return 'tie', move_count\n",
    "    elif winner.endswith('plus'):\n",
    "        return 'plus', move_count\n",
    "    elif winner.endswith('minus'):\n",
    "        return 'minus', move_count\n",
    "    else:\n",
    "        return 'tie', move_count  # Default to tie if unclear\n",
    "\n",
    "def test_model_vs_MCTS(model_pick_move, model_type='CNN', num_games=100, mcts_steps_minus=300, verbose=False):\n",
    "    \"\"\"\n",
    "    Play multiple games between the specified model and MCTS.\n",
    "    \n",
    "    Parameters:\n",
    "    - model_pick_move: function to pick moves using the model\n",
    "    - model_type: 'CNN' or 'Transformer'\n",
    "    - num_games: number of games to play\n",
    "    - mcts_steps_minus: number of MCTS steps for the 'minus' player\n",
    "    - verbose: if True, print game outcomes\n",
    "    \n",
    "    Returns:\n",
    "    - results: dict with counts of 'plus_wins', 'minus_wins', 'ties', 'avg_moves'\n",
    "    \"\"\"\n",
    "    plus_wins = 0\n",
    "    minus_wins = 0\n",
    "    ties = 0\n",
    "    total_moves = 0\n",
    "\n",
    "    for g in range(1, num_games + 1):\n",
    "        winner, moves = play_one_game(model_pick_move, model_type, mcts_steps_minus, verbose)\n",
    "        total_moves += moves\n",
    "\n",
    "        if winner == 'plus':\n",
    "            plus_wins += 1\n",
    "        elif winner == 'minus':\n",
    "            minus_wins += 1\n",
    "        else:\n",
    "            ties += 1\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Game {g}: Winner = {winner}, Moves = {moves}\")\n",
    "\n",
    "    avg_moves = total_moves / num_games if num_games > 0 else 0\n",
    "\n",
    "    results = {\n",
    "        'plus_wins': plus_wins,\n",
    "        'minus_wins': minus_wins,\n",
    "        'ties': ties,\n",
    "        'avg_moves': avg_moves\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating CNN vs MCTS...\n",
      "Out of 50 games vs. MCTS(1000 steps):\n",
      "  CNN (plus) wins:  35\n",
      "  MCTS (minus) wins: 14\n",
      "  Ties: 1\n",
      "  Average number of moves per game: 31.6\n",
      "\n",
      "Evaluating Transformer vs MCTS...\n",
      "Out of 50 games vs. MCTS(1000 steps):\n",
      "  Transformer (plus) wins:  37\n",
      "  MCTS (minus) wins:        11\n",
      "  Ties:                     2\n",
      "  Average number of moves per game: 29.6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Define evaluation parameters\n",
    "    num_games = 50\n",
    "    mcts_steps = 1000  # Number of MCTS steps for the 'minus' player\n",
    "\n",
    "    # Evaluate CNN vs MCTS\n",
    "    #print(\"Evaluating CNN vs MCTS...\")\n",
    "    #results_cnn = test_model_vs_MCTS(\n",
    "    #    model_pick_move=cnn_pick_move,      # function to pick CNN moves\n",
    "    #    model_type='CNN',                  # label for logging\n",
    "    #    num_games=num_games,\n",
    "    #    mcts_steps_minus=mcts_steps,\n",
    "    #    verbose=False\n",
    "    #)\n",
    "    #print(f\"Out of {num_games} games vs. MCTS({mcts_steps} steps):\")\n",
    "    #print(f\"  CNN (plus) wins:  {results_cnn['plus_wins']}\")\n",
    "    #print(f\"  MCTS (minus) wins: {results_cnn['minus_wins']}\")\n",
    "    #print(f\"  Ties: {results_cnn['ties']}\")\n",
    "    #print(f\"  Average number of moves per game: {results_cnn['avg_moves']:.1f}\\n\")\n",
    "\n",
    "    # Evaluate Transformer vs MCTS\n",
    "    print(\"Evaluating Transformer vs MCTS...\")\n",
    "    results_transformer = test_model_vs_MCTS(\n",
    "        model_pick_move=transformer_pick_move,  # function to pick Transformer moves\n",
    "        model_type='Transformer',               # label for logging\n",
    "        num_games=num_games,\n",
    "        mcts_steps_minus=mcts_steps,\n",
    "        verbose=False\n",
    "    )\n",
    "    print(f\"Out of {num_games} games vs. MCTS({mcts_steps} steps):\")\n",
    "    print(f\"  Transformer (plus) wins:  {results_transformer['plus_wins']}\")\n",
    "    print(f\"  MCTS (minus) wins:        {results_transformer['minus_wins']}\")\n",
    "    print(f\"  Ties:                     {results_transformer['ties']}\")\n",
    "    print(f\"  Average number of moves per game: {results_transformer['avg_moves']:.1f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
