{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #type: ignore\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from IPython.display import clear_output #type: ignore\n",
    "import tensorflow as tf #type: ignore\n",
    "from tensorflow.keras import layers, models, regularizers #type: ignore\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split #type: ignore\n",
    "import matplotlib.pyplot as plt #type: ignore\n",
    "from joblib import Parallel, delayed  # for parallelism\n",
    "import multiprocessing\n",
    "\n",
    "SEED = 22\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect Four and MCTS Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_board(board_temp,color,column):\n",
    "    board = board_temp.copy()\n",
    "    colsum = abs(board[0,column])+abs(board[1,column])+abs(board[2,column])+abs(board[3,column])+abs(board[4,column])+abs(board[5,column])\n",
    "    row = int(5-colsum)\n",
    "    if row > -0.5:\n",
    "        if color == 'plus':\n",
    "            board[row,column] = 1\n",
    "        else:\n",
    "            board[row,column] = -1\n",
    "    return board\n",
    "    \n",
    "def check_for_win_slow(board):\n",
    "    nrow = board.shape[0]\n",
    "    ncol = board.shape[1]\n",
    "    winner = 'nobody'\n",
    "    for col in range(ncol):\n",
    "        for row in reversed(range(nrow)):\n",
    "            if abs(board[row,col]) < 0.1:\n",
    "                break\n",
    "            # vertical\n",
    "            if row <= (nrow-4):\n",
    "                tempsum = board[row,col]+board[row+1,col]+board[row+2,col]+board[row+3,col]\n",
    "                if tempsum==4:\n",
    "                    winner = 'v-plus'\n",
    "                    return winner\n",
    "                elif tempsum==-4:\n",
    "                    winner = 'v-minus'\n",
    "                    return winner\n",
    "            # horizontal\n",
    "            if col <= (ncol-4):\n",
    "                tempsum = board[row,col]+board[row,col+1]+board[row,col+2]+board[row,col+3]\n",
    "                if tempsum==4:\n",
    "                    winner = 'h-plus'\n",
    "                    return winner\n",
    "                elif tempsum==-4:\n",
    "                    winner = 'h-minus'\n",
    "                    return winner\n",
    "            # diagonal down-right\n",
    "            if (row <= (nrow-4)) and (col <= (ncol-4)):\n",
    "                tempsum = board[row,col]+board[row+1,col+1]+board[row+2,col+2]+board[row+3,col+3]\n",
    "                if tempsum==4:\n",
    "                    winner = 'd-plus'\n",
    "                    return winner\n",
    "                elif tempsum==-4:\n",
    "                    winner = 'd-minus'\n",
    "                    return winner\n",
    "            # diagonal down-left\n",
    "            if (row <= (nrow-4)) and (col >= 3):\n",
    "                tempsum = board[row,col]+board[row+1,col-1]+board[row+2,col-2]+board[row+3,col-3]\n",
    "                if tempsum==4:\n",
    "                    winner = 'd-plus'\n",
    "                    return winner\n",
    "                elif tempsum==-4:\n",
    "                    winner = 'd-minus'\n",
    "                    return winner\n",
    "    return winner\n",
    "\n",
    "def check_for_win(board,col):\n",
    "    nrow = 6\n",
    "    # figure out what row was just placed\n",
    "    colsum = abs(board[0,col])+abs(board[1,col])+abs(board[2,col])+abs(board[3,col])+abs(board[4,col])+abs(board[5,col])\n",
    "    row = int(6-colsum)\n",
    "    # vertical check\n",
    "    if row+3<6:\n",
    "        vert = board[row,col] + board[row+1,col] + board[row+2,col] + board[row+3,col]\n",
    "        if vert == 4:\n",
    "            return 'v-plus'\n",
    "        elif vert == -4:\n",
    "            return 'v-minus'\n",
    "    # horizontal checks (there are several)\n",
    "    # segment 0-3\n",
    "    if col+3<7:\n",
    "        hor = board[row,col] + board[row,col+1] + board[row,col+2] + board[row,col+3]\n",
    "        if hor == 4:\n",
    "            return 'h-plus'\n",
    "        elif hor == -4:\n",
    "            return 'h-minus'\n",
    "    # segment -1..+2\n",
    "    if col-1>=0 and col+2<7:\n",
    "        hor = board[row,col-1] + board[row,col] + board[row,col+1] + board[row,col+2]\n",
    "        if hor == 4:\n",
    "            return 'h-plus'\n",
    "        elif hor == -4:\n",
    "            return 'h-minus'\n",
    "    # segment -2..+1\n",
    "    if col-2>=0 and col+1<7:\n",
    "        hor = board[row,col-2] + board[row,col-1] + board[row,col] + board[row,col+1]\n",
    "        if hor == 4:\n",
    "            return 'h-plus'\n",
    "        elif hor == -4:\n",
    "            return 'h-minus'\n",
    "    # segment -3..0\n",
    "    if col-3>=0:\n",
    "        hor = board[row,col-3] + board[row,col-2] + board[row,col-1] + board[row,col]\n",
    "        if hor == 4:\n",
    "            return 'h-plus'\n",
    "        elif hor == -4:\n",
    "            return 'h-minus'\n",
    "    # diagonals down-right\n",
    "    if row < 3 and col < 4:\n",
    "        DR = board[row,col] + board[row+1,col+1] + board[row+2,col+2] + board[row+3,col+3]\n",
    "        if DR == 4:\n",
    "            return 'd-plus'\n",
    "        elif DR == -4:\n",
    "            return 'd-minus'\n",
    "    if row-1>=0 and col-1>=0 and row+2<6 and col+2<7:\n",
    "        DR = board[row-1,col-1] + board[row,col] + board[row+1,col+1] + board[row+2,col+2]\n",
    "        if DR == 4:\n",
    "            return 'd-plus'\n",
    "        elif DR == -4:\n",
    "            return 'd-minus'\n",
    "    if row-2>=0 and col-2>=0 and row+1<6 and col+1<7:\n",
    "        DR = board[row-2,col-2] + board[row-1,col-1] + board[row,col] + board[row+1,col+1]\n",
    "        if DR == 4:\n",
    "            return 'd-plus'\n",
    "        elif DR == -4:\n",
    "            return 'd-minus'\n",
    "    if row-3>=0 and col-3>=0:\n",
    "        DR = board[row-3,col-3] + board[row-2,col-2] + board[row-1,col-1] + board[row,col]\n",
    "        if DR == 4:\n",
    "            return 'd-plus'\n",
    "        elif DR == -4:\n",
    "            return 'd-minus'\n",
    "    # diagonals down-left\n",
    "    if row+3<6 and col-3>=0:\n",
    "        DL = board[row,col] + board[row+1,col-1] + board[row+2,col-2] + board[row+3,col-3]\n",
    "        if DL == 4:\n",
    "            return 'd-plus'\n",
    "        elif DL == -4:\n",
    "            return 'd-minus'\n",
    "    if row-1>=0 and col+1<7 and row+2<6 and col-2>=0:\n",
    "        DL = board[row-1,col+1] + board[row,col] + board[row+1,col-1] + board[row+2,col-2]\n",
    "        if DL == 4:\n",
    "            return 'd-plus'\n",
    "        elif DL == -4:\n",
    "            return 'd-minus'\n",
    "    if row-2>=0 and col+2<7 and row+1<6 and col-1>=0:\n",
    "        DL = board[row-2,col+2] + board[row-1,col+1] + board[row,col] + board[row+1,col-1]\n",
    "        if DL == 4:\n",
    "            return 'd-plus'\n",
    "        elif DL == -4:\n",
    "            return 'd-minus'\n",
    "    if row-3>=0 and col+3<7:\n",
    "        DL = board[row-3,col+3] + board[row-2,col+2] + board[row-1,col+1] + board[row,col]\n",
    "        if DL == 4:\n",
    "            return 'd-plus'\n",
    "        elif DL == -4:\n",
    "            return 'd-minus'\n",
    "    return 'nobody'\n",
    "\n",
    "def find_legal(board):\n",
    "    return [i for i in range(7) if abs(board[0,i]) < 0.1]\n",
    "\n",
    "def look_for_win(board_,color):\n",
    "    board_ = board_.copy()\n",
    "    legal = find_legal(board_)\n",
    "    winner_col = -1\n",
    "    for m in legal:\n",
    "        bt = update_board(board_.copy(),color,m)\n",
    "        wi = check_for_win(bt,m)\n",
    "        if wi[2:] == color:\n",
    "            winner_col = m\n",
    "            break\n",
    "    return winner_col\n",
    "\n",
    "def find_all_nonlosers(board,color):\n",
    "    if color == 'plus':\n",
    "        opp = 'minus'\n",
    "    else:\n",
    "        opp = 'plus'\n",
    "    legal = find_legal(board)\n",
    "    poss_boards = [update_board(board,color,l) for l in legal]\n",
    "    poss_legal = [find_legal(b) for b in poss_boards]\n",
    "    allowed = []\n",
    "    for i in range(len(legal)):\n",
    "        # if the opponent can immediately win after we move in col=legal[i], skip it\n",
    "        wins = [j for j in poss_legal[i] \n",
    "                if check_for_win(update_board(poss_boards[i],opp,j),j) != 'nobody']\n",
    "        if len(wins) == 0:\n",
    "            allowed.append(legal[i])\n",
    "    return allowed\n",
    "\n",
    "def back_prop(winner,path,color0,md):\n",
    "    for i, board_tuple in enumerate(path):\n",
    "        md[board_tuple][0] += 1\n",
    "        if winner[2] == color0[0]:\n",
    "            if i % 2 == 1:\n",
    "                md[board_tuple][1] += 1\n",
    "            else:\n",
    "                md[board_tuple][1] -= 1\n",
    "        elif winner[2] == 'e':\n",
    "            # tie => no change\n",
    "            pass\n",
    "        else:\n",
    "            if i % 2 == 1:\n",
    "                md[board_tuple][1] -= 1\n",
    "            else:\n",
    "                md[board_tuple][1] += 1\n",
    "\n",
    "def rollout(board,next_player):\n",
    "    winner = 'nobody'\n",
    "    player = next_player\n",
    "    while winner == 'nobody':\n",
    "        legal = find_legal(board)\n",
    "        if len(legal) == 0:\n",
    "            return 'tie'\n",
    "        move = random.choice(legal)\n",
    "        board = update_board(board,player,move)\n",
    "        winner = check_for_win(board,move)\n",
    "        # switch player\n",
    "        if player == 'plus':\n",
    "            player = 'minus'\n",
    "        else:\n",
    "            player = 'plus'\n",
    "    return winner\n",
    "        \n",
    "def mcts(board_temp,color0,nsteps):\n",
    "    # Traditional MCTS, plus small improvements:\n",
    "    board = board_temp.copy()\n",
    "    # 1. If there's an immediate winning move, use it\n",
    "    win_col = look_for_win(board,color0)\n",
    "    if win_col != -1:\n",
    "        return win_col\n",
    "    # 2. Look for any moves that avoid an immediate losing position\n",
    "    legal0 = find_all_nonlosers(board,color0)\n",
    "    if len(legal0) == 0:\n",
    "        # if no way to avoid opponent's immediate threat, use all legal moves\n",
    "        legal0 = find_legal(board)\n",
    "    \n",
    "    mcts_dict = {tuple(board.ravel()):[0,0]}\n",
    "    for _ in range(nsteps):\n",
    "        color = color0\n",
    "        winner = 'nobody'\n",
    "        board_mcts = board.copy()\n",
    "        path = [tuple(board_mcts.ravel())]\n",
    "        \n",
    "        while winner == 'nobody':\n",
    "            legal = find_legal(board_mcts)\n",
    "            if len(legal) == 0:\n",
    "                winner = 'tie'\n",
    "                back_prop(winner,path,color0,mcts_dict)\n",
    "                break\n",
    "            # list of next possible boards\n",
    "            board_list = []\n",
    "            for col in legal:\n",
    "                b_next = update_board(board_mcts,color,col)\n",
    "                board_list.append(tuple(b_next.ravel()))\n",
    "                if tuple(b_next.ravel()) not in mcts_dict:\n",
    "                    mcts_dict[tuple(b_next.ravel())] = [0,0]\n",
    "            \n",
    "            # UCB1 \n",
    "            ucb1 = np.zeros(len(legal))\n",
    "            for i, bl in enumerate(board_list):\n",
    "                num_sims, total_value = mcts_dict[bl]\n",
    "                if num_sims == 0:\n",
    "                    # large priority for unvisited\n",
    "                    ucb1[i] = 10 * nsteps\n",
    "                else:\n",
    "                    parent_sims = mcts_dict[path[-1]][0]\n",
    "                    avg_val = total_value / num_sims\n",
    "                    explore = np.sqrt(np.log(parent_sims)/num_sims)\n",
    "                    ucb1[i] = avg_val + 2*explore\n",
    "            \n",
    "            chosen = np.argmax(ucb1)\n",
    "            board_mcts = update_board(board_mcts,color,legal[chosen])\n",
    "            path.append(tuple(board_mcts.ravel()))\n",
    "            # check winner\n",
    "            winner = check_for_win(board_mcts,legal[chosen])\n",
    "            if winner[2] == color[0]:\n",
    "                back_prop(winner,path,color0,mcts_dict)\n",
    "                break\n",
    "            \n",
    "            # switch player\n",
    "            color = 'minus' if (color=='plus') else 'plus'\n",
    "            \n",
    "            # if the new board has never been visited, do a rollout\n",
    "            if mcts_dict[tuple(board_mcts.ravel())][0] == 0:\n",
    "                winner_roll = rollout(board_mcts,color)\n",
    "                back_prop(winner_roll,path,color0,mcts_dict)\n",
    "                break\n",
    "    \n",
    "    # pick the move with best average reward\n",
    "    best_col = -1\n",
    "    max_score = -np.inf\n",
    "    for col in legal0:\n",
    "        new_board = tuple(update_board(board,color0,col).ravel())\n",
    "        num_sims, total_val = mcts_dict[new_board]\n",
    "        if num_sims == 0:\n",
    "            # means we never visited it\n",
    "            score = -np.inf\n",
    "        else:\n",
    "            score = total_val/num_sims\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            best_col = col\n",
    "\n",
    "    return best_col\n",
    "\n",
    "\n",
    "def board_to_6x7x2(board_2d):\n",
    "    \"\"\"\n",
    "    Convert a 6x7 board with +1, -1, 0 \n",
    "    into a 6x7x2 one-hot style representation:\n",
    "       channel 0 => +1 positions\n",
    "       channel 1 => -1 positions\n",
    "    \"\"\"\n",
    "    X = np.zeros((6,7,2), dtype=np.float32)\n",
    "    for i in range(6):\n",
    "        for j in range(7):\n",
    "            if board_2d[i,j] == 1:\n",
    "                X[i,j,0] = 1\n",
    "            elif board_2d[i,j] == -1:\n",
    "                X[i,j,1] = 1\n",
    "    return X\n",
    "\n",
    "def minus_to_plus(board_6x7x2):\n",
    "    \"\"\"\n",
    "    Flip a (6,7,2) board from 'minus perspective' to 'plus perspective'\n",
    "    by swapping channels 0 and 1.\n",
    "      channel 0 => +1 squares\n",
    "      channel 1 => -1 squares\n",
    "    If originally channel 1 was the 'minus' squares, \n",
    "    after swap, that becomes the 'plus' squares, etc.\n",
    "    \"\"\"\n",
    "    flipped = board_6x7x2.copy()\n",
    "    flipped[..., 0], flipped[..., 1] = board_6x7x2[..., 1], board_6x7x2[..., 0]\n",
    "    return flipped\n",
    "\n",
    "def add_symmetric_flips(board_6x7x2, best_move):\n",
    "    \"\"\"\n",
    "    Given a (6,7,2) board and an integer best_move in [0..6],\n",
    "    return a list of:\n",
    "      [(original_board_6x7x2, best_move),\n",
    "       (flipped_board_6x7x2, flipped_move)].\n",
    "    The flipped version is mirrored left-to-right (column j -> 6-j).\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    \n",
    "    # 1) Original\n",
    "    out.append((board_6x7x2, best_move))\n",
    "    \n",
    "    # 2) Flipped left-right\n",
    "    flipped_board = board_6x7x2[:, ::-1, :].copy()\n",
    "    flipped_col = 6 - best_move\n",
    "    out.append((flipped_board, flipped_col))\n",
    "    \n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_one_game(\n",
    "    plus_mcts_steps=800, \n",
    "    minus_mcts_steps=800,\n",
    "    random_openings=2\n",
    "):\n",
    "    \"\"\"\n",
    "    Play one full game between plus & minus, each side using MCTS.\n",
    "    - random_openings => number of random moves each side does at the start.\n",
    "    - We'll capture BOTH plus and minus moves. \n",
    "      For minus, we flip the board to plus perspective before storing.\n",
    "    - We do NOT store random moves. \n",
    "    - Return a list of (board_6x7x2, best_move_col) for all MCTS-chosen moves \n",
    "      from the plus perspective.\n",
    "    \"\"\"\n",
    "    data_this_game = []\n",
    "    board = np.zeros((6,7), dtype=np.float32)\n",
    "    winner = 'nobody'\n",
    "    player = 'plus'\n",
    "    move_count = 0\n",
    "    \n",
    "    while winner == 'nobody':\n",
    "        legal = find_legal(board)\n",
    "        if len(legal) == 0:\n",
    "            break  # tie\n",
    "\n",
    "        # Possibly do a random move in the opening\n",
    "        use_random = False\n",
    "        if move_count < 2*random_openings:\n",
    "            # e.g. first X moves in the entire game: random for plus & minus\n",
    "            use_random = True\n",
    "\n",
    "        if use_random:\n",
    "            col = random.choice(legal)\n",
    "        else:\n",
    "            # MCTS to pick best move\n",
    "            if player == 'plus':\n",
    "                col = mcts(board, 'plus', plus_mcts_steps)\n",
    "            else:\n",
    "                col = mcts(board, 'minus', minus_mcts_steps)\n",
    "\n",
    "        old_board = board.copy()  # board before the current move\n",
    "        board = update_board(board, player, col)\n",
    "        winner = check_for_win(board, col)\n",
    "\n",
    "        # Store the data if this move is MCTS-based (not random)\n",
    "        if not use_random:\n",
    "            if player == 'plus':\n",
    "                # plus perspective => straightforward\n",
    "                board_6x7x2 = board_to_6x7x2(old_board)\n",
    "                data_this_game.append((board_6x7x2, col))\n",
    "            else:\n",
    "                # minus perspective => flip channels to get plus perspective\n",
    "                board_6x7x2_minus = board_to_6x7x2(old_board)\n",
    "                board_6x7x2_plus = minus_to_plus(board_6x7x2_minus)\n",
    "                # The chosen column from minus's vantage is the same col index on the grid\n",
    "                data_this_game.append((board_6x7x2_plus, col))\n",
    "\n",
    "        # Switch player\n",
    "        player = 'minus' if (player == 'plus') else 'plus'\n",
    "        move_count += 1\n",
    "    \n",
    "    return data_this_game\n",
    "\n",
    "def play_one_game_random_params():\n",
    "    \"\"\"\n",
    "    Roll random settings:\n",
    "      plus_mcts_steps   in [500..5000]\n",
    "      minus_mcts_steps  in [500..5000]\n",
    "      random_openings   in [1..15]\n",
    "\n",
    "    Then call play_one_game(...) once.\n",
    "    Return the list of (board_6x7x2, best_move).\n",
    "    \"\"\"\n",
    "    plus_mcts = random.randint(500, 5000)\n",
    "    minus_mcts = random.randint(500, 5000)\n",
    "    openings   = random.randint(1, 15)\n",
    "    game_data = play_one_game(\n",
    "        plus_mcts_steps=plus_mcts,\n",
    "        minus_mcts_steps=minus_mcts,\n",
    "        random_openings=openings\n",
    "    )\n",
    "    return game_data  # list of (board_6x7x2, best_move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_build_dataset(num_games=25000):\n",
    "    \"\"\"\n",
    "    Use joblib to run 'play_one_game_random_params()' in parallel.\n",
    "\n",
    "    We store results in a collision dictionary (board -> {move->count}).\n",
    "    Then we do final collision resolution + stacking into X,y.\n",
    "\n",
    "    Returns X, y as np arrays:\n",
    "      X.shape = (N, 6, 7, 2)\n",
    "      y.shape = (N,)\n",
    "    \"\"\"\n",
    "    print(f\"Building dataset with {num_games} games in parallel...\")\n",
    "\n",
    "    # Step 1: run each game in parallel\n",
    "    results = Parallel(n_jobs=-1, backend='loky')(\n",
    "        delayed(play_one_game_random_params)()\n",
    "        for _ in range(num_games)\n",
    "    )\n",
    "\n",
    "    # 'results' is a list of lists. Each sub-list is the (board_6x7x2, best_move) pairs for one game.\n",
    "    # We'll store them with symmetrical flips & collisions.\n",
    "    data_dict = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    print(\"Aggregating results & handling collisions...\")\n",
    "\n",
    "    # Step 2: For each game’s data, do symmetry flips & increment collision dictionary\n",
    "    for game_data in results:\n",
    "        for (board_6x7x2, best_move) in game_data:\n",
    "            # augment\n",
    "            augmented = add_symmetric_flips(board_6x7x2, best_move)\n",
    "            for (b_aug, m_aug) in augmented:\n",
    "                key = b_aug.tobytes()\n",
    "                data_dict[key][m_aug] += 1\n",
    "\n",
    "    # Step 3: collision resolution\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    for key, move_counts in data_dict.items():\n",
    "        best_move = max(move_counts, key=move_counts.get)\n",
    "        arr = np.frombuffer(key, dtype=np.float32).reshape(6,7,2)\n",
    "        X_list.append(arr)\n",
    "        y_list.append(best_move)\n",
    "\n",
    "    X = np.stack(X_list, axis=0)\n",
    "    y = np.array(y_list, dtype=np.int32)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataset with 25000 games in parallel...\n",
      "Aggregating results & handling collisions...\n",
      "Finished building dataset!\n",
      "X shape: (465707, 6, 7, 2)\n",
      "y shape: (465707,)\n",
      "Unique moves in y: [0 1 2 3 4 5 6]\n",
      "Dataset saved to X_dataset_new.ethan2.npy and y_dataset_ethan2.npy.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    NUM_GAMES = 25000  \n",
    "    X, y = parallel_build_dataset(num_games=NUM_GAMES)\n",
    "    print(\"Finished building dataset!\")\n",
    "    print(\"X shape:\", X.shape)  # (N,6,7,2)\n",
    "    print(\"y shape:\", y.shape)\n",
    "    print(\"Unique moves in y:\", np.unique(y))\n",
    "\n",
    "    # Save to disk\n",
    "    np.save(\"X_dataset_ethan2.npy\", X) # change filename as needed\n",
    "    np.save(\"y_dataset_ethan2.npy\", y) # change filename as needed\n",
    "    print(\"Dataset saved to X_dataset_new.ethan2.npy and y_dataset_ethan2.npy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before concatenation:\n",
      "  Dataset 1: (457185, 6, 7, 2) (457185,)\n",
      "  Dataset 2: (465707, 6, 7, 2) (465707,)\n",
      "After concatenation: (922892, 6, 7, 2) (922892,)\n",
      "Saved merged dataset to X_dataset_merged.npy, y_dataset_merged.npy.\n"
     ]
    }
   ],
   "source": [
    "# Append dataset code\n",
    "\n",
    "def append_datasets(file1_X, file1_y, file2_X, file2_y, out_X, out_y):\n",
    "    \"\"\"\n",
    "    Load two Connect4 datasets (X1,y1) and (X2,y2),\n",
    "    concatenate them along axis=0,\n",
    "    then save as (out_X, out_y).\n",
    "    \"\"\"\n",
    "    X1 = np.load(file1_X)\n",
    "    y1 = np.load(file1_y)\n",
    "    X2 = np.load(file2_X)\n",
    "    y2 = np.load(file2_y)\n",
    "\n",
    "    print(\"Before concatenation:\")\n",
    "    print(\"  Dataset 1:\", X1.shape, y1.shape)\n",
    "    print(\"  Dataset 2:\", X2.shape, y2.shape)\n",
    "\n",
    "    X_merged = np.concatenate([X1, X2], axis=0)\n",
    "    y_merged = np.concatenate([y1, y2], axis=0)\n",
    "\n",
    "    print(\"After concatenation:\", X_merged.shape, y_merged.shape)\n",
    "\n",
    "    np.save(out_X, X_merged)\n",
    "    np.save(out_y, y_merged)\n",
    "    print(f\"Saved merged dataset to {out_X}, {out_y}.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    append_datasets(\n",
    "        file1_X=\"X_dataset_ethan.npy\",\n",
    "        file1_y=\"y_dataset_ethan.npy\",\n",
    "        file2_X=\"X_dataset_ethan2.npy\",\n",
    "        file2_y=\"y_dataset_ethan2.npy\",\n",
    "        out_X=\"X_dataset_merged.npy\",\n",
    "        out_y=\"y_dataset_merged.npy\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes:\n",
      "X: (922892, 6, 7, 2)\n",
      "y: (922892,)\n",
      "Unique moves in y: [0 1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "X_file = \"X_dataset_merged.npy\"\n",
    "y_file = \"y_dataset_merged.npy\"\n",
    "\n",
    "X = np.load(X_file)  # shape (N, 6, 7, 2)\n",
    "y = np.load(y_file)  # shape (N,)\n",
    "\n",
    "print(\"Data shapes:\")\n",
    "print(\"X:\", X.shape)\n",
    "print(\"y:\", y.shape)\n",
    "unique_moves = np.unique(y)\n",
    "print(\"Unique moves in y:\", unique_moves)  # should be [0..6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 738313\n",
      "Validation set size: 184579\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.2, \n",
    "    random_state=22, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(\"Training set size:\", X_train.shape[0])\n",
    "print(\"Validation set size:\", X_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAvailable GPUs:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 6, 7, 64)          1216      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 6, 7, 64)         256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 6, 7, 64)          0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 3, 3, 64)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 3, 3, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 3, 3, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 3, 3, 128)         0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 1, 1, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 1, 1, 128)         147584    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 1, 1, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 1, 1, 128)         0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 1, 1, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 1, 1, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              (None, 1, 1, 256)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               131584    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_4 (ReLU)              (None, 512)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_5 (ReLU)              (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7)                 1799      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 787,911\n",
      "Trainable params: 785,223\n",
      "Non-trainable params: 2,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # Block 1\n",
    "    tf.keras.layers.Conv2D(64, (3,3), padding='same', input_shape=(6, 7, 2)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=2),  # (6,7)->(3,4)\n",
    "    \n",
    "    # Block 2\n",
    "    tf.keras.layers.Conv2D(128, (3,3), padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=2),  # (3,4)->(1,2)\n",
    "    \n",
    "    # Block 3\n",
    "    tf.keras.layers.Conv2D(128, (3,3), padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    \n",
    "    # Block 4 (new)\n",
    "    tf.keras.layers.Conv2D(256, (3,3), padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    # Shape = (1,2,256) => total of 512 features after flatten\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    # Dense block\n",
    "    tf.keras.layers.Dense(\n",
    "        512, \n",
    "        kernel_regularizer=tf.keras.regularizers.l2(5e-5)\n",
    "    ),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    tf.keras.layers.Dense(\n",
    "        256, \n",
    "        kernel_regularizer=tf.keras.regularizers.l2(5e-5)\n",
    "    ),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.ReLU(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    # Output\n",
    "    tf.keras.layers.Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "# Start with Adam(1e-4), use ReduceLROnPlateau to dynamically lower it\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception-Style CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Inception_CNN\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 6, 7, 2)]    0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 6, 7, 32)     608         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 6, 7, 32)    128         ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                   (None, 6, 7, 32)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 6, 7, 32)     1056        ['re_lu[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 6, 7, 32)     1056        ['re_lu[0][0]']                  \n",
      "                                                                                                  \n",
      " re_lu_1 (ReLU)                 (None, 6, 7, 32)     0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_2 (ReLU)                 (None, 6, 7, 32)     0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 6, 7, 32)     9248        ['re_lu_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 6, 7, 32)     25632       ['re_lu_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 6, 7, 32)     1056        ['re_lu[0][0]']                  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 6, 7, 96)     0           ['conv2d_2[0][0]',               \n",
      "                                                                  'conv2d_4[0][0]',               \n",
      "                                                                  'conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 6, 7, 96)    384         ['concatenate[0][0]']            \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_3 (ReLU)                 (None, 6, 7, 96)     0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 3, 3, 96)     0           ['re_lu_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 3, 3, 64)     6208        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 3, 3, 64)     6208        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " re_lu_4 (ReLU)                 (None, 3, 3, 64)     0           ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_5 (ReLU)                 (None, 3, 3, 64)     0           ['conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 3, 3, 64)     36928       ['re_lu_4[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 3, 3, 64)     102464      ['re_lu_5[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 3, 3, 64)     6208        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 3, 3, 192)    0           ['conv2d_7[0][0]',               \n",
      "                                                                  'conv2d_9[0][0]',               \n",
      "                                                                  'conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 3, 3, 192)   768         ['concatenate_1[0][0]']          \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_6 (ReLU)                 (None, 3, 3, 192)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 192)         0           ['re_lu_6[0][0]']                \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 192)         768         ['global_average_pooling2d[0][0]'\n",
      " rmalization)                                                    ]                                \n",
      "                                                                                                  \n",
      " re_lu_7 (ReLU)                 (None, 192)          0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          49408       ['re_lu_7[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 256)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 256)         1024        ['dropout[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " re_lu_8 (ReLU)                 (None, 256)          0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 128)          32896       ['re_lu_8[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 128)          0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 7)            903         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 282,951\n",
      "Trainable params: 281,415\n",
      "Non-trainable params: 1,536\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def inception_block(x, filters=64, wd=1e-4):\n",
    "    \"\"\"\n",
    "    A simplified 'Inception-like' block:\n",
    "      Branch A: 1×1 conv -> 3×3 conv\n",
    "      Branch B: 1×1 conv -> 5×5 conv\n",
    "      Branch C: 1×1 conv (just for channel mixing)\n",
    "    Then we concat them along the channel axis, \n",
    "    followed by BatchNorm + ReLU.\n",
    "    \n",
    "    'filters' is the number of output filters *per branch*, \n",
    "    so total output channels ~ 3 * filters after concat.\n",
    "    \"\"\"\n",
    "    # Branch A\n",
    "    branch_a = tf.keras.layers.Conv2D(\n",
    "        filters, kernel_size=1, padding='same',\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(wd)\n",
    "    )(x)\n",
    "    branch_a = tf.keras.layers.ReLU()(branch_a)\n",
    "    branch_a = tf.keras.layers.Conv2D(\n",
    "        filters, kernel_size=3, padding='same',\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(wd)\n",
    "    )(branch_a)\n",
    "    \n",
    "    # Branch B\n",
    "    branch_b = tf.keras.layers.Conv2D(\n",
    "        filters, kernel_size=1, padding='same',\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(wd)\n",
    "    )(x)\n",
    "    branch_b = tf.keras.layers.ReLU()(branch_b)\n",
    "    branch_b = tf.keras.layers.Conv2D(\n",
    "        filters, kernel_size=5, padding='same',\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(wd)\n",
    "    )(branch_b)\n",
    "    \n",
    "    # Branch C (just 1×1)\n",
    "    branch_c = tf.keras.layers.Conv2D(\n",
    "        filters, kernel_size=1, padding='same',\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(wd)\n",
    "    )(x)\n",
    "    \n",
    "    # Concatenate along channel axis\n",
    "    out = tf.keras.layers.Concatenate(axis=-1)([branch_a, branch_b, branch_c])\n",
    "    # Then BN + ReLU\n",
    "    out = tf.keras.layers.BatchNormalization()(out)\n",
    "    out = tf.keras.layers.ReLU()(out)\n",
    "    return out\n",
    "\n",
    "\n",
    "def build_inception_cnn(input_shape=(6, 7, 2),\n",
    "                        wd=5e-5,\n",
    "                        use_global_pool=True):\n",
    "    \"\"\"\n",
    "    A 'pure CNN' using Inception-style blocks, \n",
    "    plus optional global average pooling to handle the small 6x7 board.\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "\n",
    "    # (1) Initial Conv\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        32, (3,3), padding='same',\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(wd)\n",
    "    )(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    # (2) Inception Block #1\n",
    "    x = inception_block(x, filters=32, wd=wd)\n",
    "\n",
    "    # (3) Max Pool to reduce from (6,7) => ~ (3,3)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "\n",
    "    # (4) Inception Block #2\n",
    "    x = inception_block(x, filters=64, wd=wd)\n",
    "\n",
    "    # (5) Do Global pool\n",
    "    if use_global_pool:\n",
    "        # Global Average Pool => shape ~ (batch, channels)\n",
    "        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    else:\n",
    "        # Flatten directly\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "    # (6) Dense block\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = tf.keras.layers.Dense(\n",
    "        256,\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(wd)\n",
    "    )(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = tf.keras.layers.Dense(\n",
    "        128,\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(wd)\n",
    "    )(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "    # (7) Output layer\n",
    "    outputs = tf.keras.layers.Dense(7, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs, name=\"Inception_CNN\")\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = build_inception_cnn(input_shape=(6,7,2), wd=5e-5)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Res-Net Style CNN  - Best Perfomer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 6, 7, 2)]    0           []                               \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 6, 7, 64)     1216        ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 6, 7, 64)    256         ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_13 (ReLU)                (None, 6, 7, 64)     0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_13[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 6, 7, 64)    256         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_14 (ReLU)                (None, 6, 7, 64)     0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_14[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 6, 7, 64)    256         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 6, 7, 64)     0           ['re_lu_13[0][0]',               \n",
      "                                                                  'batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_15 (ReLU)                (None, 6, 7, 64)     0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_15[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 6, 7, 64)    256         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_16 (ReLU)                (None, 6, 7, 64)     0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_16[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 6, 7, 64)    256         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 6, 7, 64)     0           ['re_lu_15[0][0]',               \n",
      "                                                                  'batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_17 (ReLU)                (None, 6, 7, 64)     0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 3, 3, 64)    0           ['re_lu_17[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 3, 3, 128)    8320        ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 3, 3, 128)   512         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_18 (ReLU)                (None, 3, 3, 128)    0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 3, 3, 128)    147584      ['re_lu_18[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 3, 3, 128)   512         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_19 (ReLU)                (None, 3, 3, 128)    0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 3, 3, 128)    147584      ['re_lu_19[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 3, 3, 128)   512         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 3, 3, 128)    0           ['re_lu_18[0][0]',               \n",
      "                                                                  'batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_20 (ReLU)                (None, 3, 3, 128)    0           ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 128)   0           ['re_lu_20[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 1, 1, 256)    33024       ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 1, 1, 256)   1024        ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_21 (ReLU)                (None, 1, 1, 256)    0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 1, 1, 256)    590080      ['re_lu_21[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 1, 1, 256)   1024        ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_22 (ReLU)                (None, 1, 1, 256)    0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 1, 1, 256)    590080      ['re_lu_22[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 1, 1, 256)   1024        ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 1, 1, 256)    0           ['re_lu_21[0][0]',               \n",
      "                                                                  'batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_23 (ReLU)                (None, 1, 1, 256)    0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 256)          0           ['re_lu_23[0][0]']               \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 512)          131584      ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 512)         2048        ['dense_3[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_24 (ReLU)                (None, 512)          0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 512)          0           ['re_lu_24[0][0]']               \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 256)          131328      ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 256)         1024        ['dense_4[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_25 (ReLU)                (None, 256)          0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 256)          0           ['re_lu_25[0][0]']               \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 7)            1799        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,939,271\n",
      "Trainable params: 1,934,791\n",
      "Non-trainable params: 4,480\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def residual_block(x, filters, kernel_size=(3,3), l2_reg=5e-5):\n",
    "    \"\"\"\n",
    "    A basic ResNet-style block:\n",
    "      - 2D Convolution -> BN -> ReLU\n",
    "      - 2D Convolution -> BN\n",
    "      - Skip connection: add the input 'x' to the result\n",
    "      - Final ReLU activation\n",
    "    \"\"\"\n",
    "    # Save the input to add back later\n",
    "    shortcut = x\n",
    "\n",
    "    # First conv\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        filters, kernel_size, padding='same',\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(l2_reg)\n",
    "    )(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    # Second conv\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        filters, kernel_size, padding='same',\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(l2_reg)\n",
    "    )(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    # Add the shortcut (must have same shape)\n",
    "    x = tf.keras.layers.Add()([shortcut, x])\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def build_resnet_cnn(input_shape=(6,7,2), num_classes=7, l2_reg=5e-5, dropout_rate=0.3):\n",
    "    \"\"\"\n",
    "    A deeper ResNet-style CNN for Connect4.\n",
    "    - input_shape: (6,7,2)\n",
    "    - num_classes: 7 (one per column)\n",
    "    - l2_reg: L2 regularization factor\n",
    "    - dropout_rate: dropout ratio in dense layers\n",
    "    \"\"\"\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "\n",
    "    # Initial conv: (like a \"stem\" layer)\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        64, (3,3), padding='same',\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(l2_reg)\n",
    "    )(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    # --- Residual Block 1 (64 filters) ---\n",
    "    x = residual_block(x, filters=64, l2_reg=l2_reg)\n",
    "\n",
    "    # Do a second residual block at same (64) filters\n",
    "    x = residual_block(x, filters=64, l2_reg=l2_reg)\n",
    "\n",
    "    # MaxPool to reduce from (6,7) -> (3,3)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=2)(x)\n",
    "\n",
    "    # --- Residual Block 2 (128 filters) ---\n",
    "    x = tf.keras.layers.Conv2D(128, (1,1), strides=1,  # 1x1 to expand channels\n",
    "                               padding='same',\n",
    "                               kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    x = residual_block(x, filters=128, l2_reg=l2_reg)\n",
    "\n",
    "    # (3,3) -> (1,1) with maxpool\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=2)(x)\n",
    "\n",
    "    # --- Residual Block 3 (256 filters) ---\n",
    "    # 1x1 conv to expand from 128->256 channels\n",
    "    x = tf.keras.layers.Conv2D(256, (1,1), strides=1,\n",
    "                               padding='same',\n",
    "                               kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "    x = residual_block(x, filters=256, l2_reg=l2_reg)\n",
    "\n",
    "    # Flatten\n",
    "    x = tf.keras.layers.Flatten()(x)  # shape ~ (256,)\n",
    "\n",
    "    # Dense block\n",
    "    x = tf.keras.layers.Dense(\n",
    "        512,\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(l2_reg)\n",
    "    )(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(\n",
    "        256,\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(l2_reg)\n",
    "    )(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    # Output\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = build_resnet_cnn(input_shape=(6,7,2), num_classes=7, l2_reg=5e-5, dropout_rate=0.3) # maybe change to 2e-5 and 0.2\n",
    "\n",
    "    # Compile\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.005),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    model.summary()\n",
    "\n",
    "# Need to improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNetSmall\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 6, 7, 2)]    0           []                               \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 6, 7, 64)     1216        ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 6, 7, 64)    256         ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_38 (ReLU)                (None, 6, 7, 64)     0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_38[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 6, 7, 64)    256         ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_39 (ReLU)                (None, 6, 7, 64)     0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_39[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 6, 7, 64)    256         ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 6, 7, 64)     0           ['re_lu_38[0][0]',               \n",
      "                                                                  'batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_40 (ReLU)                (None, 6, 7, 64)     0           ['add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_40[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 6, 7, 64)    256         ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_41 (ReLU)                (None, 6, 7, 64)     0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 6, 7, 64)     36928       ['re_lu_41[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 6, 7, 64)    256         ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 6, 7, 64)     0           ['re_lu_40[0][0]',               \n",
      "                                                                  'batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_42 (ReLU)                (None, 6, 7, 64)     0           ['add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPooling2D)  (None, 3, 3, 64)    0           ['re_lu_42[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 3, 3, 128)    8320        ['max_pooling2d_6[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 3, 3, 128)   512         ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_43 (ReLU)                (None, 3, 3, 128)    0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 3, 3, 128)    147584      ['re_lu_43[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 3, 3, 128)   512         ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_44 (ReLU)                (None, 3, 3, 128)    0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 3, 3, 128)    147584      ['re_lu_44[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 3, 3, 128)   512         ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 3, 3, 128)    0           ['re_lu_43[0][0]',               \n",
      "                                                                  'batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_45 (ReLU)                (None, 3, 3, 128)    0           ['add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 3, 3, 128)    147584      ['re_lu_45[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 3, 3, 128)   512         ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_46 (ReLU)                (None, 3, 3, 128)    0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 3, 3, 128)    147584      ['re_lu_46[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 3, 3, 128)   512         ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 3, 3, 128)    0           ['re_lu_45[0][0]',               \n",
      "                                                                  'batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_47 (ReLU)                (None, 3, 3, 128)    0           ['add_15[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPooling2D)  (None, 1, 1, 128)   0           ['re_lu_47[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 128)          0           ['max_pooling2d_7[0][0]']        \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 512)          66048       ['flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 512)         2048        ['dense_9[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_48 (ReLU)                (None, 512)          0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 512)          0           ['re_lu_48[0][0]']               \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 256)          131328      ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 256)         1024        ['dense_10[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_49 (ReLU)                (None, 256)          0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 256)          0           ['re_lu_49[0][0]']               \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 7)            1799        ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 953,671\n",
      "Trainable params: 950,215\n",
      "Non-trainable params: 3,456\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def residual_block(x, filters, kernel_size=(3,3), l2_reg=2e-5):\n",
    "    \"\"\"\n",
    "    A basic ResNet-style block:\n",
    "      - 1st 3x3 Conv -> BN -> ReLU\n",
    "      - 2nd 3x3 Conv -> BN\n",
    "      - skip connection (add input)\n",
    "      - final ReLU\n",
    "    \"\"\"\n",
    "    shortcut = x\n",
    "\n",
    "    # 1st conv\n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same',\n",
    "                      kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 2nd conv\n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same',\n",
    "                      kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # skip connection\n",
    "    x = layers.Add()([shortcut, x])\n",
    "    x = layers.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "def build_resnet_small(input_shape=(6,7,2), num_classes=7,\n",
    "                       l2_reg=2e-5, dropout_rate=0.2):\n",
    "    \"\"\"\n",
    "    A 'medium-depth' ResNet-like CNN for Connect 4:\n",
    "      - conv(64) 'stem'\n",
    "      - residual block(64) x2\n",
    "      - maxpool\n",
    "      - conv(128,1x1) \n",
    "      - residual block(128) x2\n",
    "      - maxpool\n",
    "      - flatten -> Dense(512)->(BN,ReLU,Dropout)\n",
    "      - Dense(256)->(BN,ReLU,Dropout)\n",
    "      - output(7,softmax)\n",
    "    \"\"\"\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Stem conv\n",
    "    x = layers.Conv2D(64, (3,3), padding='same',\n",
    "                      kernel_regularizer=regularizers.l2(l2_reg))(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 2 res blocks at 64\n",
    "    x = residual_block(x, filters=64, l2_reg=l2_reg)\n",
    "    x = residual_block(x, filters=64, l2_reg=l2_reg)\n",
    "\n",
    "    # pool\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), strides=2)(x)  # shape ~ (3,4,64)\n",
    "\n",
    "    # expand to 128 channels w/ 1x1\n",
    "    x = layers.Conv2D(128, (1,1), padding='same',\n",
    "                      kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 2 res blocks at 128\n",
    "    x = residual_block(x, filters=128, l2_reg=l2_reg)\n",
    "    x = residual_block(x, filters=128, l2_reg=l2_reg)\n",
    "\n",
    "    # pool again\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), strides=2)(x)\n",
    "    # shape ~ (1,2,128) => flatten => 256 features\n",
    "\n",
    "    x = layers.Flatten()(x)  # shape ~ (256,) or so\n",
    "\n",
    "    # Dense block\n",
    "    x = layers.Dense(512, kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    x = layers.Dense(256, kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs, outputs, name=\"ResNetSmall\")\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = build_resnet_small(\n",
    "        input_shape=(6,7,2),\n",
    "        num_classes=7,\n",
    "        l2_reg=2e-5, # 1e-6?\n",
    "        dropout_rate=0.2 # 0.15? \n",
    "    )\n",
    "\n",
    "    # compile\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), # 0.01?\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11537/11537 [==============================] - 97s 8ms/step - loss: 1.2732 - accuracy: 0.5533 - val_loss: 1.1605 - val_accuracy: 0.6048 - lr: 0.0050\n",
      "Epoch 2/100\n",
      "11537/11537 [==============================] - 94s 8ms/step - loss: 1.0739 - accuracy: 0.6264 - val_loss: 1.0309 - val_accuracy: 0.6363 - lr: 0.0050\n",
      "Epoch 3/100\n",
      "11537/11537 [==============================] - 91s 8ms/step - loss: 1.0360 - accuracy: 0.6350 - val_loss: 1.0367 - val_accuracy: 0.6397 - lr: 0.0050\n",
      "Epoch 4/100\n",
      "11537/11537 [==============================] - 91s 8ms/step - loss: 1.0196 - accuracy: 0.6389 - val_loss: 0.9820 - val_accuracy: 0.6486 - lr: 0.0050\n",
      "Epoch 5/100\n",
      "11537/11537 [==============================] - 92s 8ms/step - loss: 1.0089 - accuracy: 0.6415 - val_loss: 1.0240 - val_accuracy: 0.6380 - lr: 0.0050\n",
      "Epoch 6/100\n",
      "11537/11537 [==============================] - 92s 8ms/step - loss: 1.0026 - accuracy: 0.6417 - val_loss: 0.9893 - val_accuracy: 0.6464 - lr: 0.0050\n",
      "Epoch 7/100\n",
      "11533/11537 [============================>.] - ETA: 0s - loss: 0.9964 - accuracy: 0.6430\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "11537/11537 [==============================] - 99s 9ms/step - loss: 0.9964 - accuracy: 0.6429 - val_loss: 0.9951 - val_accuracy: 0.6414 - lr: 0.0050\n",
      "Epoch 8/100\n",
      "11537/11537 [==============================] - 100s 9ms/step - loss: 0.9236 - accuracy: 0.6628 - val_loss: 0.8920 - val_accuracy: 0.6670 - lr: 0.0025\n",
      "Epoch 9/100\n",
      "11537/11537 [==============================] - 100s 9ms/step - loss: 0.9087 - accuracy: 0.6651 - val_loss: 0.8810 - val_accuracy: 0.6707 - lr: 0.0025\n",
      "Epoch 10/100\n",
      "11537/11537 [==============================] - 100s 9ms/step - loss: 0.9045 - accuracy: 0.6665 - val_loss: 0.8830 - val_accuracy: 0.6691 - lr: 0.0025\n",
      "Epoch 11/100\n",
      "11537/11537 [==============================] - 100s 9ms/step - loss: 0.9014 - accuracy: 0.6668 - val_loss: 0.8880 - val_accuracy: 0.6726 - lr: 0.0025\n",
      "Epoch 12/100\n",
      "11537/11537 [==============================] - 100s 9ms/step - loss: 0.8996 - accuracy: 0.6681 - val_loss: 0.8832 - val_accuracy: 0.6679 - lr: 0.0025\n",
      "Epoch 13/100\n",
      "11537/11537 [==============================] - 100s 9ms/step - loss: 0.8987 - accuracy: 0.6682 - val_loss: 0.8833 - val_accuracy: 0.6712 - lr: 0.0025\n",
      "Epoch 14/100\n",
      "11531/11537 [============================>.] - ETA: 0s - loss: 0.8979 - accuracy: 0.6686\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "11537/11537 [==============================] - 100s 9ms/step - loss: 0.8979 - accuracy: 0.6686 - val_loss: 0.8766 - val_accuracy: 0.6707 - lr: 0.0025\n",
      "Epoch 15/100\n",
      "11537/11537 [==============================] - 99s 9ms/step - loss: 0.8544 - accuracy: 0.6819 - val_loss: 0.8302 - val_accuracy: 0.6854 - lr: 0.0012\n",
      "Epoch 16/100\n",
      "11537/11537 [==============================] - 100s 9ms/step - loss: 0.8432 - accuracy: 0.6840 - val_loss: 0.8269 - val_accuracy: 0.6835 - lr: 0.0012\n",
      "Epoch 17/100\n",
      "11537/11537 [==============================] - 99s 9ms/step - loss: 0.8381 - accuracy: 0.6847 - val_loss: 0.8245 - val_accuracy: 0.6852 - lr: 0.0012\n",
      "Epoch 18/100\n",
      "11537/11537 [==============================] - 100s 9ms/step - loss: 0.8360 - accuracy: 0.6847 - val_loss: 0.8220 - val_accuracy: 0.6874 - lr: 0.0012\n",
      "Epoch 19/100\n",
      "11537/11537 [==============================] - 98s 8ms/step - loss: 0.8341 - accuracy: 0.6859 - val_loss: 0.8202 - val_accuracy: 0.6866 - lr: 0.0012\n",
      "Epoch 20/100\n",
      "11537/11537 [==============================] - 95s 8ms/step - loss: 0.8335 - accuracy: 0.6857 - val_loss: 0.8208 - val_accuracy: 0.6867 - lr: 0.0012\n",
      "Epoch 21/100\n",
      "11537/11537 [==============================] - 95s 8ms/step - loss: 0.8317 - accuracy: 0.6859 - val_loss: 0.8148 - val_accuracy: 0.6880 - lr: 0.0012\n",
      "Epoch 22/100\n",
      "11537/11537 [==============================] - 96s 8ms/step - loss: 0.8318 - accuracy: 0.6863 - val_loss: 0.8148 - val_accuracy: 0.6883 - lr: 0.0012\n",
      "Epoch 23/100\n",
      "11537/11537 [==============================] - 95s 8ms/step - loss: 0.8307 - accuracy: 0.6871 - val_loss: 0.8266 - val_accuracy: 0.6850 - lr: 0.0012\n",
      "Epoch 24/100\n",
      "11537/11537 [==============================] - 95s 8ms/step - loss: 0.8305 - accuracy: 0.6864 - val_loss: 0.8203 - val_accuracy: 0.6856 - lr: 0.0012\n",
      "Epoch 25/100\n",
      "11537/11537 [==============================] - 86s 7ms/step - loss: 0.8289 - accuracy: 0.6874 - val_loss: 0.8121 - val_accuracy: 0.6892 - lr: 0.0012\n",
      "Epoch 26/100\n",
      "11537/11537 [==============================] - 90s 8ms/step - loss: 0.8295 - accuracy: 0.6868 - val_loss: 0.8142 - val_accuracy: 0.6904 - lr: 0.0012\n",
      "Epoch 27/100\n",
      "11537/11537 [==============================] - 91s 8ms/step - loss: 0.8287 - accuracy: 0.6876 - val_loss: 0.8244 - val_accuracy: 0.6868 - lr: 0.0012\n",
      "Epoch 28/100\n",
      "11537/11537 [==============================] - 90s 8ms/step - loss: 0.8282 - accuracy: 0.6873 - val_loss: 0.8261 - val_accuracy: 0.6866 - lr: 0.0012\n",
      "Epoch 29/100\n",
      "11532/11537 [============================>.] - ETA: 0s - loss: 0.8280 - accuracy: 0.6872\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "11537/11537 [==============================] - 90s 8ms/step - loss: 0.8279 - accuracy: 0.6872 - val_loss: 0.8182 - val_accuracy: 0.6858 - lr: 0.0012\n",
      "Epoch 30/100\n",
      "11537/11537 [==============================] - 90s 8ms/step - loss: 0.7991 - accuracy: 0.6967 - val_loss: 0.7950 - val_accuracy: 0.6943 - lr: 6.2500e-04\n",
      "Epoch 31/100\n",
      "11537/11537 [==============================] - 90s 8ms/step - loss: 0.7924 - accuracy: 0.6990 - val_loss: 0.7924 - val_accuracy: 0.6957 - lr: 6.2500e-04\n",
      "Epoch 32/100\n",
      "11537/11537 [==============================] - 90s 8ms/step - loss: 0.7891 - accuracy: 0.6992 - val_loss: 0.7876 - val_accuracy: 0.6967 - lr: 6.2500e-04\n",
      "Epoch 33/100\n",
      "11537/11537 [==============================] - 90s 8ms/step - loss: 0.7870 - accuracy: 0.6998 - val_loss: 0.7867 - val_accuracy: 0.6958 - lr: 6.2500e-04\n",
      "Epoch 34/100\n",
      "11537/11537 [==============================] - 89s 8ms/step - loss: 0.7860 - accuracy: 0.7000 - val_loss: 0.7870 - val_accuracy: 0.6947 - lr: 6.2500e-04\n",
      "Epoch 35/100\n",
      "11533/11537 [============================>.] - ETA: 0s - loss: 0.7841 - accuracy: 0.7005\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "11537/11537 [==============================] - 89s 8ms/step - loss: 0.7841 - accuracy: 0.7005 - val_loss: 0.7857 - val_accuracy: 0.6960 - lr: 6.2500e-04\n",
      "Epoch 36/100\n",
      "11537/11537 [==============================] - 95s 8ms/step - loss: 0.7660 - accuracy: 0.7069 - val_loss: 0.7712 - val_accuracy: 0.7016 - lr: 3.1250e-04\n",
      "Epoch 37/100\n",
      "11537/11537 [==============================] - 87s 8ms/step - loss: 0.7613 - accuracy: 0.7081 - val_loss: 0.7733 - val_accuracy: 0.7024 - lr: 3.1250e-04\n",
      "Epoch 38/100\n",
      "11537/11537 [==============================] - 85s 7ms/step - loss: 0.7594 - accuracy: 0.7085 - val_loss: 0.7691 - val_accuracy: 0.7022 - lr: 3.1250e-04\n",
      "Epoch 39/100\n",
      "11537/11537 [==============================] - 85s 7ms/step - loss: 0.7575 - accuracy: 0.7089 - val_loss: 0.7690 - val_accuracy: 0.7006 - lr: 3.1250e-04\n",
      "Epoch 40/100\n",
      "11536/11537 [============================>.] - ETA: 0s - loss: 0.7557 - accuracy: 0.7092\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "11537/11537 [==============================] - 85s 7ms/step - loss: 0.7557 - accuracy: 0.7092 - val_loss: 0.7697 - val_accuracy: 0.7018 - lr: 3.1250e-04\n",
      "Epoch 41/100\n",
      "11537/11537 [==============================] - 85s 7ms/step - loss: 0.7452 - accuracy: 0.7127 - val_loss: 0.7620 - val_accuracy: 0.7047 - lr: 1.5625e-04\n",
      "Epoch 42/100\n",
      "11537/11537 [==============================] - 85s 7ms/step - loss: 0.7421 - accuracy: 0.7140 - val_loss: 0.7605 - val_accuracy: 0.7045 - lr: 1.5625e-04\n",
      "Epoch 43/100\n",
      "11537/11537 [==============================] - 85s 7ms/step - loss: 0.7409 - accuracy: 0.7138 - val_loss: 0.7611 - val_accuracy: 0.7047 - lr: 1.5625e-04\n",
      "Epoch 44/100\n",
      "11537/11537 [==============================] - 85s 7ms/step - loss: 0.7392 - accuracy: 0.7141 - val_loss: 0.7605 - val_accuracy: 0.7053 - lr: 1.5625e-04\n",
      "Epoch 45/100\n",
      "11537/11537 [==============================] - 84s 7ms/step - loss: 0.7386 - accuracy: 0.7148 - val_loss: 0.7603 - val_accuracy: 0.7055 - lr: 1.5625e-04\n",
      "Epoch 46/100\n",
      "11537/11537 [==============================] - 85s 7ms/step - loss: 0.7372 - accuracy: 0.7153 - val_loss: 0.7613 - val_accuracy: 0.7039 - lr: 1.5625e-04\n",
      "Epoch 47/100\n",
      "11537/11537 [==============================] - 85s 7ms/step - loss: 0.7368 - accuracy: 0.7149 - val_loss: 0.7601 - val_accuracy: 0.7050 - lr: 1.5625e-04\n",
      "Epoch 48/100\n",
      "11533/11537 [============================>.] - ETA: 0s - loss: 0.7355 - accuracy: 0.7155\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "11537/11537 [==============================] - 85s 7ms/step - loss: 0.7355 - accuracy: 0.7155 - val_loss: 0.7602 - val_accuracy: 0.7046 - lr: 1.5625e-04\n",
      "Epoch 49/100\n",
      "11537/11537 [==============================] - 85s 7ms/step - loss: 0.7298 - accuracy: 0.7176 - val_loss: 0.7570 - val_accuracy: 0.7049 - lr: 7.8125e-05\n",
      "Epoch 50/100\n",
      "11537/11537 [==============================] - 85s 7ms/step - loss: 0.7276 - accuracy: 0.7177 - val_loss: 0.7570 - val_accuracy: 0.7048 - lr: 7.8125e-05\n",
      "Epoch 51/100\n",
      "11537/11537 [==============================] - 85s 7ms/step - loss: 0.7272 - accuracy: 0.7183 - val_loss: 0.7578 - val_accuracy: 0.7059 - lr: 7.8125e-05\n",
      "Epoch 52/100\n",
      "11537/11537 [==============================] - 86s 7ms/step - loss: 0.7262 - accuracy: 0.7185 - val_loss: 0.7569 - val_accuracy: 0.7052 - lr: 7.8125e-05\n",
      "Epoch 53/100\n",
      "11537/11537 [==============================] - 90s 8ms/step - loss: 0.7257 - accuracy: 0.7187 - val_loss: 0.7575 - val_accuracy: 0.7046 - lr: 7.8125e-05\n",
      "Epoch 54/100\n",
      "11534/11537 [============================>.] - ETA: 0s - loss: 0.7251 - accuracy: 0.7184\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "11537/11537 [==============================] - 89s 8ms/step - loss: 0.7251 - accuracy: 0.7184 - val_loss: 0.7572 - val_accuracy: 0.7055 - lr: 7.8125e-05\n",
      "Epoch 55/100\n",
      "11537/11537 [==============================] - 88s 8ms/step - loss: 0.7214 - accuracy: 0.7198 - val_loss: 0.7559 - val_accuracy: 0.7054 - lr: 3.9062e-05\n",
      "Epoch 56/100\n",
      "11537/11537 [==============================] - 89s 8ms/step - loss: 0.7210 - accuracy: 0.7199 - val_loss: 0.7565 - val_accuracy: 0.7057 - lr: 3.9062e-05\n",
      "Epoch 57/100\n",
      "11534/11537 [============================>.] - ETA: 0s - loss: 0.7199 - accuracy: 0.7202\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "11537/11537 [==============================] - 90s 8ms/step - loss: 0.7199 - accuracy: 0.7202 - val_loss: 0.7564 - val_accuracy: 0.7055 - lr: 3.9062e-05\n",
      "Epoch 58/100\n",
      "11537/11537 [==============================] - 90s 8ms/step - loss: 0.7185 - accuracy: 0.7205 - val_loss: 0.7566 - val_accuracy: 0.7054 - lr: 1.9531e-05\n",
      "Epoch 59/100\n",
      "11537/11537 [==============================] - 90s 8ms/step - loss: 0.7179 - accuracy: 0.7211 - val_loss: 0.7568 - val_accuracy: 0.7056 - lr: 1.9531e-05\n",
      "Epoch 60/100\n",
      "11532/11537 [============================>.] - ETA: 0s - loss: 0.7174 - accuracy: 0.7214\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 9.765624781721272e-06.\n",
      "11537/11537 [==============================] - 90s 8ms/step - loss: 0.7174 - accuracy: 0.7214 - val_loss: 0.7568 - val_accuracy: 0.7055 - lr: 1.9531e-05\n",
      "Epoch 61/100\n",
      "11537/11537 [==============================] - 90s 8ms/step - loss: 0.7166 - accuracy: 0.7218 - val_loss: 0.7561 - val_accuracy: 0.7055 - lr: 9.7656e-06\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 64\n",
    "\n",
    "# Early stopping if val_accuracy doesn’t improve for 7 epochs\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Reduce learning rate by factor of 0.5 if val_accuracy doesn’t improve for 3 epochs\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 70.59%   (loss=0.7579)\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(f\"Validation accuracy: {val_acc*100:.2f}%   (loss={val_loss:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to cnn_connect4.h5.\n"
     ]
    }
   ],
   "source": [
    "model.save(\"cnn_connect4.h5\")\n",
    "print(\"Model saved to cnn_connect4.h5.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Plot loss\n",
    "axs[0].plot(history.history['loss'], label='train_loss')\n",
    "axs[0].plot(history.history['val_loss'], label='val_loss')\n",
    "axs[0].set_title(\"Loss\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "# Plot accuracy\n",
    "axs[1].plot(history.history['accuracy'], label='train_acc')\n",
    "axs[1].plot(history.history['val_accuracy'], label='val_acc')\n",
    "axs[1].set_title(\"Accuracy\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].set_ylabel(\"Accuracy\")\n",
    "axs[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Testing vs MCTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_pick_move(board_2d, model, color='plus'):\n",
    "    \"\"\"\n",
    "    Given a 6x7 board (board_2d) and a trained Keras model,\n",
    "    pick the column with highest predicted probability (from the CNN)\n",
    "    that is also legal.\n",
    "    \n",
    "    If 'color' == 'minus', we flip channels so the CNN sees \"plus perspective.\"\n",
    "    That means channel 0 => squares of +1, channel 1 => squares of -1.\n",
    "    \n",
    "    Return: int column in [0..6].\n",
    "    \"\"\"\n",
    "    # Convert board to 6x7x2 representation\n",
    "    from_board = board_to_6x7x2(board_2d)\n",
    "    \n",
    "    if color == 'minus':\n",
    "        # Flip minus -> plus perspective\n",
    "        from_board = minus_to_plus(from_board)\n",
    "\n",
    "    # Model expects shape (N, 6, 7, 2). So expand dims.\n",
    "    input_for_model = np.expand_dims(from_board, axis=0)  # (1,6,7,2)\n",
    "    \n",
    "    # Predict probabilities for each column\n",
    "    # shape: (1,7)\n",
    "    pred_probs = model.predict(input_for_model, verbose=0)[0]  # (7,)\n",
    "\n",
    "    # Sort columns by descending probability\n",
    "    columns_ranked = np.argsort(pred_probs)[::-1]  # highest -> lowest\n",
    "\n",
    "    # Find a legal column among the top predictions\n",
    "    legal_cols = find_legal(board_2d)\n",
    "    for col in columns_ranked:\n",
    "        if col in legal_cols:\n",
    "            return col\n",
    "\n",
    "    # Fallback: if something weird happened (all top columns were illegal),\n",
    "    # pick a random legal column\n",
    "    if len(legal_cols) > 0:\n",
    "        return random.choice(legal_cols)\n",
    "    else:\n",
    "        return 0  # if no columns are legal, game is effectively a tie/loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_one_game_CNN_vs_MCTS(model, mcts_steps_minus=300, verbose=False):\n",
    "    \"\"\"\n",
    "    Let the CNN play as 'plus' and MCTS play as 'minus' with mcts_steps_minus.\n",
    "    Returns: winner (str), number_of_moves\n",
    "             where winner is in { 'nobody', 'v-plus', 'v-minus', 'h-plus', ... etc. }\n",
    "    \"\"\"\n",
    "    board = np.zeros((6,7), dtype=np.float32)\n",
    "    winner = 'nobody'\n",
    "    player = 'plus'\n",
    "    move_count = 0\n",
    "\n",
    "    while winner == 'nobody':\n",
    "        legal = find_legal(board)\n",
    "        if len(legal) == 0:\n",
    "            # tie\n",
    "            break\n",
    "\n",
    "        if player == 'plus':\n",
    "            col = cnn_pick_move(board, model, color='plus')\n",
    "        else:\n",
    "            col = mcts(board, 'minus', mcts_steps_minus)\n",
    "\n",
    "        board = update_board(board, player, col)\n",
    "        winner = check_for_win(board, col)\n",
    "        \n",
    "        move_count += 1\n",
    "        \n",
    "        if player == 'plus':\n",
    "            player = 'minus'\n",
    "        else:\n",
    "            player = 'plus'\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Move {move_count}, {player}, col={col}\")\n",
    "\n",
    "    return winner, move_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_CNN_vs_MCTS(model, num_games=100, mcts_steps_minus=300, verbose=False):\n",
    "    \"\"\"\n",
    "    Play 'num_games' between:\n",
    "      - CNN as 'plus'\n",
    "      - MCTS as 'minus' with mcts_steps_minus\n",
    "    Track how many times plus wins, minus wins, or tie.\n",
    "    Also track average length of game (moves).\n",
    "    \n",
    "    Returns: \n",
    "      plus_wins, minus_wins, ties, avg_moves\n",
    "    \"\"\"\n",
    "    plus_wins = 0\n",
    "    minus_wins = 0\n",
    "    ties = 0\n",
    "    total_moves = 0\n",
    "\n",
    "    for g in range(num_games):\n",
    "        winner, moves = play_one_game_CNN_vs_MCTS(\n",
    "            model,\n",
    "            mcts_steps_minus=mcts_steps_minus,\n",
    "            verbose=verbose\n",
    "        )\n",
    "        total_moves += moves\n",
    "\n",
    "        if winner == 'nobody' or winner == 'tie':\n",
    "            ties += 1\n",
    "        elif winner.endswith('plus'):\n",
    "            plus_wins += 1\n",
    "        elif winner.endswith('minus'):\n",
    "            minus_wins += 1\n",
    "        else:\n",
    "            if winner[-4:] == 'plus':\n",
    "                plus_wins += 1\n",
    "            else:\n",
    "                minus_wins += 1\n",
    "    \n",
    "    avg_moves = total_moves / num_games if num_games > 0 else 0\n",
    "    \n",
    "    return plus_wins, minus_wins, ties, avg_moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 50 games vs. MCTS(1000 steps):\n",
      "  CNN (plus) wins:  32\n",
      "  MCTS (minus) wins: 16\n",
      "  Ties: 2\n",
      "  Average number of moves per game: 30.6\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # model = tf.keras.models.load_model(\"cnn_connect4.h5\")\n",
    "    \n",
    "    num_games = 50\n",
    "    mcts_steps = 1000  # how many MCTS steps minus uses\n",
    "\n",
    "    pw, mw, ts, am = test_CNN_vs_MCTS(model, num_games=num_games, mcts_steps_minus=mcts_steps, verbose=False)\n",
    "    \n",
    "    print(f\"Out of {num_games} games vs. MCTS({mcts_steps} steps):\")\n",
    "    print(f\"  CNN (plus) wins:  {pw}\")\n",
    "    print(f\"  MCTS (minus) wins: {mw}\")\n",
    "    print(f\"  Ties: {ts}\")\n",
    "    print(f\"  Average number of moves per game: {am:.1f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
